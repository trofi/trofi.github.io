<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>mitigating bufferbloat</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <link rel="stylesheet" type="text/css" href="../css/code.css" />
        <link rel="stylesheet" type="text/css" href="../css/skylighting.css" />

        <link rel="alternate" type="application/atom+xml" href="../feed/atom.xml" title="Atom 1.0" />
        <link rel="alternate" type="application/rss+xml" href="../feed/rss.xml" title="RSS 2.0" />
        <link rel="shortcut icon" href="../images/favicon.ico" />
    </head>
    <body>
        <div id="navigation">
            <a href="../">home</a>
            <a href="../blog.html">blog</a>
            <a href="../log.html">log</a>
            <a href="../feed/atom.xml">atom</a>
            <a href="../feed/rss.xml">rss</a>
            <a href="../about.html">about</a>
            <a href="../contact.html">contact</a>
        </div>

        <div id="content">
            <h1>mitigating bufferbloat</h1>
            
                <div class="info">April 26, 2020</div>
            

            <h2 id="tldr">Tl;DR</h2>
<p>When I upload something large from my laptop my network latency
increases from 10 <strong>milliseconds</strong> up to 2-4 <strong>seconds</strong>. That makes
remote <code>ssh</code>, audio, video and even browsing quite a challenging task. I
avoid latency increase and network congestion by aggressively throttling
all my devices with this simple command from <a href="https://www.bufferbloat.net/projects/codel/wiki/Cake/">CAKE
howto</a>:</p>
<pre><code># tc qdisc del dev wl0 root
# tc qdisc add dev wl0 root cake bandwidth 1mbit conservative</code></pre>
<p>Done! Now I almost never notice latency increase even if I upload A Lot
of stuff.</p>
<h2 id="more-words">More words</h2>
<p>If you are experiencing severe networking lags (<code>10x</code> latency
increase) when network is congested then you probably experience a
<a href="https://www.bufferbloat.net/projects/"><code>bufferbloat</code> effect</a> where
networking devices keep your packets in their large software/hardware
queues.
These queues can hide anywhere: in your own networking card(!), in your
Wifi router, somewhere in the middle of The Internet. It is a bug in
the implementation of those devices.
Excessive buffering usually happens on a last mile of your device
connected to <code>ISP</code>. <code>ISP</code>s usually have a lot more bandwidth and
smarter devices to avoid that effect.</p>
<h2 id="observing-bufferbloat">Observing <code>bufferbloat</code></h2>
<p>Before doing anything about it let’s check if we have a problem:</p>
<pre><code>$ ping 8.8.8.8
64 bytes from 8.8.8.8: icmp_seq=1 ttl=54 time=8.53 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=54 time=18.1 ms
64 bytes from 8.8.8.8: icmp_seq=3 ttl=54 time=9.47 ms
64 bytes from 8.8.8.8: icmp_seq=4 ttl=54 time=14.1 ms
...</code></pre>
<p>In a second terminal I start an upload:</p>
<pre><code>$ scp /boot/vmlinuz slyfox@guppy.ia64.dev.gentoo.org:/tmp/my-kernel
vmlinuz 99% 7968KB 119.1KB/s   00:00 ETA</code></pre>
<p>Back in the first terminal:</p>
<pre><code>...
64 bytes from 8.8.8.8: icmp_seq=100 ttl=54 time=116 ms
64 bytes from 8.8.8.8: icmp_seq=101 ttl=54 time=141 ms
64 bytes from 8.8.8.8: icmp_seq=102 ttl=54 time=192 ms
64 bytes from 8.8.8.8: icmp_seq=103 ttl=54 time=188 ms
64 bytes from 8.8.8.8: icmp_seq=104 ttl=54 time=182 ms
64 bytes from 8.8.8.8: icmp_seq=105 ttl=54 time=218 ms
64 bytes from 8.8.8.8: icmp_seq=166 ttl=54 time=223 ms
64 bytes from 8.8.8.8: icmp_seq=167 ttl=54 time=230 ms
64 bytes from 8.8.8.8: icmp_seq=168 ttl=54 time=232 ms
64 bytes from 8.8.8.8: icmp_seq=169 ttl=54 time=8.66 ms &lt;--- recovered
64 bytes from 8.8.8.8: icmp_seq=170 ttl=54 time=9.21 ms
64 bytes from 8.8.8.8: icmp_seq=171 ttl=54 time=8.79 ms
64 bytes from 8.8.8.8: icmp_seq=172 ttl=54 time=9.02 ms
64 bytes from 8.8.8.8: icmp_seq=173 ttl=54 time=10.2 ms</code></pre>
<p>You can notice where upload started and finished just by looking at the
ping latency output.
There is a nice interactive website where you can profile your network
in a slightly more rigorous way: <a href="https://www.dslreports.com/speedtest" class="uri">https://www.dslreports.com/speedtest</a>
My profile on default system:
<a href="https://www.dslreports.com/speedtest/62838367" class="uri">https://www.dslreports.com/speedtest/62838367</a></p>
<p>We can see a bunch of things outright:</p>
<ul>
<li><code>16.5 mbit/s</code> download and <code>0.96 mbit/s</code> upload speed</li>
<li><code>26ms</code> of idle latency (to closest test server perhaps)</li>
<li>latency increases a bit when I congest network with download:
<code>26ms</code> -&gt; <code>70ms</code> (<code>100ms</code> worst case)</li>
<li>latency increases A Lot when I congest network with upload:
<code>26ms</code> -&gt; <code>~1s</code> (<code>~2.6s</code> worst case)</li>
</ul>
<p>These were my defaults during first test:</p>
<pre><code>$ tc qdisc show dev wl0
qdisc mq 0: root
qdisc fq_codel 0: parent :4 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn
qdisc fq_codel 0: parent :3 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn
qdisc fq_codel 0: parent :2 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn
qdisc fq_codel 0: parent :1 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn</code></pre>
<p>Now let’s artificially limit egress (outgoing) bandwidth:</p>
<pre><code># tc qdisc del dev wl0 root
# tc qdisc add dev wl0 root cake bandwidth 1mbit conservative</code></pre>
<p>and retest again: <a href="https://www.dslreports.com/speedtest/62838672" class="uri">https://www.dslreports.com/speedtest/62838672</a></p>
<p>Things changed:</p>
<ul>
<li>Speeds decreased slightly: <code>16.1 mbit/s</code> upload, <code>0.811 mbit/s</code> download.
Mostly because I set <code>conservative</code> keyword to account for worst
encapsulation overhead. You can experiment with more fine-grained
values, but I don’t mind the result.</li>
<li>Download congestion can still impact latency increase. For some reason
it’s more pronounced now: <code>140ms</code> worst.</li>
<li>Upload congestion has almost no effect on latency! Average is <code>34ms</code>,
worst is <code>70ms</code>!</li>
</ul>
<p>Now let’s also try artificially limiting ingress:</p>
<pre><code>#### egress as before
# tc qdisc del dev wl0 root
# tc qdisc add dev wl0 root cake bandwidth 1mbit conservative

#### ingress, a bit kludgy
# ip link add name ifb4wl0 type ifb
# tc qdisc del dev wl0 ingress
# tc qdisc add dev wl0 handle ffff: ingress
# tc qdisc del dev ifb4wl0 root
# tc qdisc add dev ifb4wl0 root cake bandwidth 16mbit conservative
# ip link set ifb4wl0 up
# tc filter add dev wl0 parent ffff: protocol all prio 10 u32 match u32 0 0 flowid 1:1 action mirred egress redirect dev ifb4wl0</code></pre>
<p>and retest again: <a href="https://www.dslreports.com/speedtest/62838933" class="uri">https://www.dslreports.com/speedtest/62838933</a></p>
<ul>
<li>Speeds decreased even more: <code>11.27 mbit/s</code> upload, <code>0.766 mbit/s</code>
download. I think the drastic drops upset TCP and it can’t recover
faster.</li>
<li>Download congestion did not become any better. That might be a sign of
<code>bufferbloat</code> on ISP side.</li>
<li>Upload congestion is still good.</li>
</ul>
<p>If you rerun the test you will notice that numbers will change from run
to run in order of 10-20% (or more). This will not allow you to
fine-tune the setup but is good enough to observe the effect.</p>
<h2 id="more-fine-grained-testing">More fine-grained testing</h2>
<p>To get better numbers bufferbloat.net project suggests using
<a href="https://flent.org/intro.html#quick-start"><code>flent</code></a> command line tool.</p>
<p>For that you will need a peer host to talk to. I’m picking
<code>guppy.ia64.dev.gentoo.org</code> <code>140ms</code> (half a globe) away from me.
Here is the run on default <code>qdisc</code>:</p>
<pre><code>#### remotely
guppy / # netserver -D

#### locally
localhost # tc qdisc show dev wl0
qdisc mq 0: root
qdisc fq_codel 0: parent :4 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn
qdisc fq_codel 0: parent :3 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn
qdisc fq_codel 0: parent :2 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn
qdisc fq_codel 0: parent :1 limit 10240p flows 1024 quantum 1514 target 5.0ms interval 100.0ms memory_limit 32Mb ecn

localhost # flent rrul -p all_scaled -l 60 -H guppy.ia64.dev.gentoo.org -t def-to-guppy -o def-filename.png
Started Flent 1.0.1 using Python 3.6.10.
Starting rrul test. Expected run time: 70 seconds.</code></pre>
<p><a href="../posts.data/217-bufferbloat/def-filename.png"><img src="../posts.data/217-bufferbloat/def-filename.png" alt="image" /></a></p>
<p>There are 3 graphs:</p>
<ul>
<li>download speed: jumps around <code>2.5-5 mbit/s</code>.</li>
<li>uplaod speed: very unstable, hard to say anything :)</li>
<li>latency graph: almost always <code>750ms</code>, sometimes touches <code>500ms</code></li>
</ul>
<p>Here is the run with <code>cake</code> both on ingress and egress:</p>
<pre><code>#### remotely
guppy / # netserver -D

#### locally
localhost # tc qdisc show dev wl0
qdisc cake 800f: root refcnt 5 bandwidth 1Mbit diffserv3 triple-isolate nonat nowash no-ack-filter split-gso rtt 100.0ms atm overhead 48
qdisc ingress ffff: parent ffff:fff1 ----------------

localhost # flent rrul -p all_scaled -l 60 -H guppy.ia64.dev.gentoo.org -t cake-to-guppy -o cake-filename.png
Started Flent 1.0.1 using Python 3.6.10.
Starting rrul test. Expected run time: 70 seconds.</code></pre>
<p><a href="../posts.data/217-bufferbloat/cake-filename.png"><img src="../posts.data/217-bufferbloat/cake-filename.png" alt="image" /></a></p>
<p>3 graphs again:</p>
<ul>
<li>download speed: jumps around <code>2-3 mbit/s</code>.</li>
<li>uplaod speed: looks like <code>0.1mbit/s</code>?</li>
<li>latency graph: most of the time <code>170ms</code>, sometimes spikes up to <code>300ms</code></li>
</ul>
<p>Even though data is still quite noisy we can see that latency is lower
in the second case.
Picking closer host and running test for longer time might yield more
precise data.
Now you can tweak many more parameters to see what changes for better or
worse: TCP congestion algorithms (I use <code>bbr</code>), many tweaks on <code>man tc-cake</code>’s side and many more.
I suggest skimming through more resources at
<a href="https://www.bufferbloat.net/projects/" class="uri">https://www.bufferbloat.net/projects/</a> if you are interested in the
topic.</p>
<h2 id="final-test">Final test</h2>
<p>Let’s get back to our original test (with ingress/egress <code>cake</code>
enabled this time):</p>
<pre><code>$ ping 8.8.8.8
64 bytes from 8.8.8.8: icmp_seq=1 ttl=54 time=9.31 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=54 time=9.20 ms
64 bytes from 8.8.8.8: icmp_seq=3 ttl=54 time=8.37 ms
64 bytes from 8.8.8.8: icmp_seq=4 ttl=54 time=10.6 ms
...</code></pre>
<p>In a second terminal start uploader:</p>
<pre><code>$ scp /boot/vmlinuz slyfox@guppy.ia64.dev.gentoo.org:/tmp/my-kernel
vmlinuz 99% 7968KB 104.6KB/s   00:00 ETA
...</code></pre>
<p>Back in the first terminal:</p>
<pre><code>...
64 bytes from 8.8.8.8: icmp_seq=178 ttl=54 time=16.5 ms
64 bytes from 8.8.8.8: icmp_seq=179 ttl=54 time=14.8 ms
64 bytes from 8.8.8.8: icmp_seq=180 ttl=54 time=15.4 ms
64 bytes from 8.8.8.8: icmp_seq=181 ttl=54 time=10.0 ms
64 bytes from 8.8.8.8: icmp_seq=182 ttl=54 time=20.3 ms
64 bytes from 8.8.8.8: icmp_seq=183 ttl=54 time=9.16 ms
64 bytes from 8.8.8.8: icmp_seq=184 ttl=54 time=9.71 ms
64 bytes from 8.8.8.8: icmp_seq=185 ttl=54 time=17.5 ms
64 bytes from 8.8.8.8: icmp_seq=186 ttl=54 time=13.0 ms
64 bytes from 8.8.8.8: icmp_seq=224 ttl=54 time=19.9 ms
64 bytes from 8.8.8.8: icmp_seq=225 ttl=54 time=42.3 ms
64 bytes from 8.8.8.8: icmp_seq=226 ttl=54 time=13.3 ms
64 bytes from 8.8.8.8: icmp_seq=227 ttl=54 time=8.39 ms
64 bytes from 8.8.8.8: icmp_seq=230 ttl=54 time=11.4 ms
64 bytes from 8.8.8.8: icmp_seq=231 ttl=54 time=8.84 ms &lt;--- recovered
64 bytes from 8.8.8.8: icmp_seq=232 ttl=54 time=8.63 ms
64 bytes from 8.8.8.8: icmp_seq=233 ttl=54 time=8.49 ms</code></pre>
<p>Latency increased a bit from <code>10ms</code> to <code>~20ms</code>. But it does not get to
<code>300ms</code>. Yay!</p>
<p>Have fun!</p>
        </div>
    </body>
</html>
