<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>trofi - All posts</title>
        <link>https://trofi.github.io</link>
        <description><![CDATA[trofi's blog]]></description>
        <atom:link href="https://trofi.github.io/feed/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Thu, 01 May 2025 00:00:00 UT</lastBuildDate>
        <item>
    <title>Zero Hydra Failures towards 25.05 NixOS release</title>
    <link>https://trofi.github.io/posts/334-Zero-Hydra-Failures-towards-25.05-NixOS-release.html</link>
    <description><![CDATA[<p>It’s May 1 and that means <code>NixOS-25.05</code> is almost
<a href="https://github.com/NixOS/nixpkgs/issues/390768">there</a>. Today the
release entered <a href="https://github.com/NixOS/nixpkgs/issues/390768"><code>ZHF</code> phase</a>
(<code>Zero Hydra Failures</code>) where the main focus
is to squash as many build failures as possible before the release.</p>
<p>It’s a good time to fix easy build failures or remove long broken
packages. <a href="https://github.com/NixOS/nixpkgs/issues/390768" class="uri">https://github.com/NixOS/nixpkgs/issues/390768</a> contains
detailed step-by-step to identify interesting packages.</p>
<h2 id="an-example-package-fix">an example package fix</h2>
<p>I usually try to fix at least one package during <code>ZHF</code>. This time I
picked <a href="https://hydra.nixos.org/build/294989234"><code>hheretic</code></a>. The
failure does not look too cryptic:</p>
<pre><code>...
checking for OpenGL support... no
configure: error: *** OpenGL not found!</code></pre>
<p>To get a bit more detail into it I usually use <code>nix develop</code>:</p>
<pre><code>$ nix develop -f. hheretic
$$ genericBuild
checking for OpenGL support... no
configure: error: *** OpenGL not found!
...
Running phase: buildPhase
no Makefile or custom buildPhase, doing nothing
...</code></pre>
<p>Here I ran <code>genericBuild</code> to start a build process similar to what a
<code>nix build -f. hheretic</code> would do.</p>
<p>I got expected error (and a bit of extra stuff). Now I can peek at
<code>config.log</code> to check why <code>OpenGL</code> was not detected:</p>
<pre><code>$ cat config.log
...
configure:5413: checking for OpenGL support
configure:5429: gcc -o conftest  -Wall -O2 -ffast-math -fomit-frame-pointer   conftest.c -lm  -Lno -lGL -lGLU &gt;&amp;5
conftest.c:30:10: fatal error: GL/gl.h: No such file or directory
   30 | #include &lt;GL/gl.h&gt;
      |          ^~~~~~~~~
compilation terminated.</code></pre>
<p>The compiler does not see <code>GL/gl.h</code> header: a missing dependency. The
first thing I tried was this patch:</p>
<pre class="diff"><code>--- a/pkgs/by-name/hh/hheretic/package.nix
+++ b/pkgs/by-name/hh/hheretic/package.nix
@@ -4,6 +4,8 @@
   fetchFromGitHub,
   SDL,
   SDL_mixer,
+  libGL,
+  libGLU,
   autoreconfHook,
   gitUpdater,
 }:
@@ -27,6 +29,8 @@ stdenv.mkDerivation (finalAttrs: {
   buildInputs = [
     SDL
     SDL_mixer
+    libGL
+    libGLU
   ];

   strictDeps = true;</code></pre>
<p>Running <code>nix build -f. hheretic</code> against it makes the package build
successfully. THe change is proposed as a
<a href="https://github.com/NixOS/nixpkgs/pull/403458">PR#403458</a> now.</p>
<p>As a bonus let’s figure out when the package broke. In the
<a href="https://hydra.nixos.org/job/nixos/trunk-combined/nixpkgs.hheretic.x86_64-linux">history tab</a>
we can see that:</p>
<ul>
<li><a href="https://hydra.nixos.org/build/292311010" class="uri">https://hydra.nixos.org/build/292311010</a> was the last successful build</li>
<li><a href="https://hydra.nixos.org/build/293013734" class="uri">https://hydra.nixos.org/build/293013734</a> was the first failing build</li>
</ul>
<p>Both links have <code>Inputs</code> tab where we can extract <code>nixpkgs</code> commits that
correspond to the build. That is enough for bisection:</p>
<pre><code>$ git clone https://github.com/NixOS/nixpkgs
$ cd nixpkgs/
$ git bisect start 81b934af6399c868c693a945415bd59771f41718 316f79657ec153b51bee287fb1fb016b104af9ef
    Bisecting: 2949 revisions left to test after this (roughly 12 steps)
    [8490862820028f5c371ac0a7fde471990ff6ad80] evcc: 0.200.9 -&gt; 0.201.0 (#390530)
$ git bisect run nix build -f. hheretic
running 'nix' 'build' '-f.' 'hheretic'
Bisecting: 1476 revisions left to test after this (roughly 11 steps)
...
Bisecting: 0 revisions left to test after this (roughly 1 step)
[e24f567a68111784e81cdda85e3784dd977f2ef8] Merge master into staging-next
running 'nix' 'build' '-f.' 'hheretic'
e47403cf2a2c76ae218bbf519c538b0ed419fa5f is the first bad commit
commit e47403cf2a2c76ae218bbf519c538b0ed419fa5f
Date:   Tue Mar 11 09:41:21 2025 +0100

    SDL: point alias to SDL_compat

 pkgs/top-level/all-packages.nix | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
bisect found first bad commit</code></pre>
<p>Looking at <a href="https://github.com/NixOS/nixpkgs/commit/e47403cf2a2c76ae218bbf519c538b0ed419fa5f" class="uri">https://github.com/NixOS/nixpkgs/commit/e47403cf2a2c76ae218bbf519c538b0ed419fa5f</a>
the <code>GitHub</code> UI says it corresponds to
<a href="https://github.com/NixOS/nixpkgs/pull/389106">PR#389106</a>.</p>
<p>Added
<a href="https://github.com/NixOS/nixpkgs/pull/389106#issuecomment-2845845704">the comment</a>
there to get attention of relevant authors.</p>
<h2 id="parting-words">parting words</h2>
<p><code>ZHF</code> event is a good way to contribute to <code>nixpkgs</code>. If you never did
but were waiting for an occasion it’s a good one to try!</p>
<p>Have fun!</p>]]></description>
    <pubDate>Thu, 01 May 2025 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/334-Zero-Hydra-Failures-towards-25.05-NixOS-release.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>To chromium</title>
    <link>https://trofi.github.io/posts/333-to-chromium.html</link>
    <description><![CDATA[<h2 id="tldr">Tl;DR</h2>
<p>I switched from <code>firefox</code> to <code>chromium</code> as a primary web browser on my
desktop.</p>
<h2 id="on-firefox">On <code>firefox</code></h2>
<p>I was a happy <code>firefox</code> since it’s <code>1.5</code> release. Internet says it was
released in 2005. This made a 20-year run for me. The web changed so
much since then. Adobe Flash went away and web 2.0 <code>javascript</code>-heavy
applications took it’s place. At some point I had to start using content
filtering extensions to be able to browse the web.</p>
<p><code>firefox</code> was able to keep up with the times most of the time. It felt
like at some point UI became too sluggish. Subjectively <code>quantum</code> 2017
release made it snappy again.</p>
<p>Fast forward to 2025 <code>firefox</code> mostly meets my needs, but there are a
few performance warts I don’t know how to deal with:</p>
<ul>
<li>Some of web-based instance messengers are very slow in <code>firefox</code>: when
I switch to the tab it freezes the whole of <code>firefox</code> for a few
seconds (it happens every time I switch to a tab, not just for the
first time).</li>
<li>Branch selection (drop-down menu) at pull request creation time on
<code>github</code> is visibly slow on repositories with many branches (<code>200+</code>
in <code>nixpkgs</code>).</li>
<li><code>firefox</code> startup time on mostly empty user profiles on HDDs are very
slow: about tens of seconds.</li>
</ul>
<p>Over past few years I have encountered a few widespread bugs in <code>firefox</code>:</p>
<ul>
<li><code>100%</code> CPU usage on <code>HTTP3</code>: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1749914" class="uri">https://bugzilla.mozilla.org/show_bug.cgi?id=1749914</a></li>
<li><code>tab crashes due to LLVM bug</code>: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1741454" class="uri">https://bugzilla.mozilla.org/show_bug.cgi?id=1741454</a></li>
</ul>
<h2 id="on-chrome">On <code>chrome</code></h2>
<p>I already used <code>chrome</code> at work for about 10 years. And 3 years ago I
started using <code>chrome</code> on a <code>chromebook</code> laptop for some of personal
things. But for a personal desktop my strong preference prefer is not to
use proprietary software.</p>
<p>With a recent shift to AI and advertising at Mozilla I wondered what are
the alternatives to <code>firefox</code> there are if I should give <code>chromium</code> a
proper try.</p>
<h2 id="on-chromium">On <code>chromium</code></h2>
<p>After about 2 months using <code>chromium</code> I should say that it is very
pleasant to use. Subjectively fonts look a bit better in <code>chromium</code> and
most performance hiccups I encountered in <code>firefox</code> disappeared (but a
new one appeared, mentioned below).</p>
<p>Helper pages like <code>chrome://about</code>, <code>chrome://flags</code> and <code>chrome://gpu</code>
are a reasonable substitute for <code>firefox</code>’s <code>about:config</code>.</p>
<p>I also discovered a few bugs/warts/known-issues as well:</p>
<ul>
<li><p><code>wayland</code> backend is not enabled by default and needs either a flag
like <code>--enable-features=UseOzonePlatform --ozone-platform=wayland</code> or
an option selected at
<code>chrome://flags &gt; Preferred Ozone platform &gt; Wayland</code>.</p>
<p>While it’s a one-off setup it feels like <code>wayland</code> might not be the
primary target for <code>linux</code> desktops.</p></li>
<li><p><code>pdf</code> viewer is quite a bit slower than in <code>firefox</code>. 350-paged doc
make <code>chromium</code> visibly struggle to scroll around, might be a known
<a href="https://issues.chromium.org/issues/345117890" class="uri">https://issues.chromium.org/issues/345117890</a>.</p>
<p>I have to fall back to local viewers for larger docs.</p></li>
<li><p><code>chromium</code> syncs on disk somewhat frequently. There is a 15-years old
<a href="https://issues.chromium.org/issues/41198599" class="uri">https://issues.chromium.org/issues/41198599</a> that mentions it’s all
the actions user does are synced on dusk time to time. I don’t think
it’s a real problem for modern SSDs, but still it feel quite wasteful.</p></li>
<li><p><code>sway</code> sometimes crashes completely when I visit certain utility
provider sites with a message like:</p>
<pre><code>00:00:25.696 [sway/sway_text_node.c:110] cairo_image_surface_create failed: invalid value (typically too big) for the size of the input (surface, pattern, etc.)
00:00:25.696 [sway/sway_text_node.c:110] cairo_image_surface_create failed: invalid value (typically too big) for the size of the input (surface, pattern, etc.)
sway: render/pass.c:23: wlr_render_pass_add_texture: Assertion `box-&gt;x &gt;= 0 &amp;&amp; box-&gt;y &gt;= 0 &amp;&amp; box-&gt;x + box-&gt;width &lt;= options-&gt;texture-&gt;width &amp;&amp; box-&gt;y + box-&gt;height &lt;= options-&gt;texture-&gt;height' failed.</code></pre>
<p>There is a bunch of open bugs with related error messages. I looks
like those are usually <code>sway</code> or <code>wlroots</code> robustness bugs. <code>chromium</code>
is probably also at fault here trying to create surfaces of
unreasonable dimensions.</p>
<p>Installing <code>sway</code> and <code>wlroots</code> from <code>git</code> <code>master</code> fixed all crashes
for me.</p></li>
</ul>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 20 Apr 2025 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/333-to-chromium.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc-15 bugs, pile 2</title>
    <link>https://trofi.github.io/posts/332-gcc-15-bugs-pile-2.html</link>
    <description><![CDATA[<p>8 more months have passed since my previous
<a href="https://trofi.github.io/posts/323-gcc-15-bugs-pile-1.html">pile report</a>. <code>gcc-15</code> was
<a href="https://gcc.gnu.org/pipermail/gcc/2025-April/245943.html">branched off</a>
from <code>master</code> and will receive only regression fixes. <code>master</code> is called
<code>gcc-16</code> now.</p>
<p>It’s a good time to look at the compiler bugs I encountered.</p>
<h2 id="summary">summary</h2>
<p>I got about 30 of those:</p>
<ul>
<li><a href="https://gcc.gnu.org/PR116516"><code>rtl-optimization/116516</code></a>: ICE on
<code>linux-6.10</code> due to inability to handle some address calculation
expressions.</li>
<li><a href="https://gcc.gnu.org/PR116797"><code>middle-end/116516</code></a>: ICE on
<code>libvpx-1.14.1</code> due to a vectorizer bug that tried to access outside
array boundary.</li>
<li><a href="https://gcc.gnu.org/PR116814"><code>middle-end/116814</code></a>: ICE on
<code>libjack2-1.9.22</code>i due to <code>gcc</code>’s inability to generate code for
saturated subtraction</li>
<li><a href="https://gcc.gnu.org/PR116817"><code>tree-optimization/116817</code></a>: ICE on
<code>libajantv2-16.2</code> <code>gcc</code>’s vectorizer broke on a loop invariant</li>
<li><a href="https://gcc.gnu.org/PR116857"><code>libstdc++/116857</code></a>: <code>mingw32</code> build
failure, was exposed after re-enabling most warnings on <code>gcc</code> headers.</li>
<li><a href="https://gcc.gnu.org/PR116880"><code>c++/116880</code></a>: <code>co_await</code> use-after-free
on <code>nix-2.24.8</code> code. A <code>gcc</code> bug in coroutine lifetime management.</li>
<li><a href="https://gcc.gnu.org/PR116911"><code>c++/116911</code></a>: <code>qt5.qtbase</code> build
failure due to <code>gcc</code> regression in assigning external linkage to local
variables.</li>
<li><a href="https://gcc.gnu.org/PR117039"><code>bootstrap/117039</code></a>: <code>-Werror=</code> <code>libcpp</code>
<code>gcc</code> buld failure due to format string problems.</li>
<li><a href="https://gcc.gnu.org/PR117114"><code>c++/117114</code></a>: <code>-Woverloaded-virtual</code>
false positives due to a <code>gcc</code> in how it tracks methods in case of
multiple inheritance.</li>
<li><a href="https://gcc.gnu.org/PR117141"><code>middle-end/117141</code></a>: duplicate pattern
definitions for subtraction-with-saturation primitive. A build warning.</li>
<li><a href="https://gcc.gnu.org/PR117177"><code>c/117177</code></a>: wrong code on global arrays
used by <code>python-3.12.7</code> and others. <code>gcc</code> generated invalid bytes that
represent the array.</li>
<li><a href="https://gcc.gnu.org/PR117190"><code>c/117190</code></a>: ICE on <code>linux-6.11.3</code>,
another case of <code>gcc</code>’s inability to generate static const arrays
similar to the previous entry.</li>
<li><a href="https://gcc.gnu.org/PR117194"><code>target/117194</code></a>: wrong code on
<code>highway-1.2.0</code> in vectorizer code. <code>gcc</code> used incorrect order of
operands in <code>ANDN</code> primitive.</li>
<li><a href="https://gcc.gnu.org/PR117220"><code>libstdc++/117220</code></a>: <code>stl_iterator</code> and
<code>clang</code> incompatibility: <code>gcc</code> allows slightly different mix of
<code>[[..]]</code> and <code>__attribute((..))</code> style of attributes ordering than
<code>clang</code>.</li>
<li><a href="https://gcc.gnu.org/PR117288"><code>lto/117288</code></a>: <code>lto</code> ICE on <code>wolfssl</code>,
constant arrays are not handled by <code>gcc</code>. This time in <code>LTO</code> bytecode.</li>
<li><a href="https://gcc.gnu.org/PR117306"><code>tree-optimization/117306</code></a>: <code>-O3</code>
vectorizer ICE on <code>netpbm-11.8.0</code> of certain <code>bool</code> calculation patterns.</li>
<li><a href="https://gcc.gnu.org/PR117378"><code>middle-end/117378</code></a>: <code>waybar</code> ICE on
<code>c++</code> due to a <code>gcc</code> bug in expansion of ternary operators.</li>
<li><a href="https://gcc.gnu.org/PR117476"><code>rtl-optimization/117476</code></a>: wrong code
on <code>grep</code> and <code>libgcrypt</code> in a code that handles zero-extension.</li>
<li><a href="https://gcc.gnu.org/PR117496"><code>middle-end/117496</code></a>: infinite recursion
on <code>cdrkit</code> due to <code>a | b</code> pattern generating still foldable result.</li>
<li><a href="https://gcc.gnu.org/PR117843"><code>bootstrap/117843</code></a>: fortran bootstrap
build failure (<code>-Werror</code>). A missing enum entry handling.</li>
<li><a href="https://gcc.gnu.org/PR117980"><code>c++/117980</code></a>: ICE on <code>nix-2.25.2</code> where
<code>gcc</code> transformation broke the type of underlying expression.</li>
<li><a href="https://gcc.gnu.org/PR118124"><code>c++/118124</code></a>: ICE on <code>nss</code>, <code>c++</code>
constant arrays were not handled in <code>initializer_list&lt;...&gt;</code>.</li>
<li><a href="https://gcc.gnu.org/PR118168"><code>preprocessor/118168</code></a>: slow <code>mypy</code>
compilation on <code>-Wmisleading-indentation</code>. <code>gcc</code> parsed the whole file
multiple times to resolve locations.</li>
<li><a href="https://gcc.gnu.org/PR118205"><code>tree-optimization/118205</code></a>: <code>libdeflate</code>
wrong code, fails <code>libtiff</code> tests due to a <code>gcc</code> bug in handling
certain form of <code>PHI</code> modes.</li>
<li><a href="https://gcc.gnu.org/PR118409"><code>tree-optimization/118409</code></a>: <code>gas</code> is
compiled incorrectly due to <code>gcc</code> bug in handling <code>xor</code> on sub-byte
bit fields.</li>
<li><a href="https://gcc.gnu.org/PR118856"><code>c++/118856</code></a>: <code>mesonlsp-4.3.7</code> ICE
and wrong code due to too early temporary destruction for arrays.</li>
<li><a href="https://gcc.gnu.org/PR119138"><code>c++/119138</code></a>: <code>mingw32</code> bootstrap
failure due to a <code>gcc</code> regression in attribute tracking for pointers.</li>
<li><a href="https://gcc.gnu.org/PR119226"><code>middle-end/119226</code></a>: <code>vifm-0.14</code> ICE on
<code>strcspn()</code> due to a bad folding recently added to <code>gcc</code> just for this
function.</li>
<li><a href="https://gcc.gnu.org/PR119278"><code>analyzer/119278</code></a>: <code>gnutls</code> <code>-fanalyzer</code>
ICE due to lack of handling of a new type for static const arrays.</li>
<li><a href="https://gcc.gnu.org/PR119428"><code>target/119428</code></a>: <code>e2fsprogs-1.47.2</code>
wrong code on bit reset due to a wrong <code>btr</code> pattern.</li>
<li><a href="https://gcc.gnu.org/PR119646"><code>c++/119428</code></a>: <code>lix</code> ICE on coroutine
code where coroutine types and values cause <code>gcc</code> to fail to handle
more complicated (but allowed by standard) cases.</li>
</ul>
<h2 id="fun-bugs">fun bugs</h2>
<h3 id="e2fsprogs-bug"><code>e2fsprogs</code> bug</h3>
<p>The <a href="https://gcc.gnu.org/PR119428"><code>e2fsprogs bug</code></a> was an interesting
case of wrong code. This was enough to trigger it:</p>
<pre class="c"><code>// $ cat bug.c
__attribute__((noipa, optimize(1)))
void bug_o1(unsigned int nr, void * addr)
{
        unsigned char   *ADDR = (unsigned char *) addr;

        ADDR += nr &gt;&gt; 3;
        *ADDR &amp;= (unsigned char) ~(1 &lt;&lt; (nr &amp; 0x07));
}

__attribute__((noipa, optimize(2)))
void bug_o2(unsigned int nr, void * addr)
{
        unsigned char   *ADDR = (unsigned char *) addr;

        ADDR += nr &gt;&gt; 3;
        *ADDR &amp;= (unsigned char) ~(1 &lt;&lt; (nr &amp; 0x07));
}

int main() {
  void * bmo1 = __builtin_malloc(1024);
  void * bmo2 = __builtin_malloc(1024);
  for (unsigned bno = 0; bno &lt; 1024 * 8; ++bno) {
    __builtin_memset(bmo1, 0xff, 1024);
    __builtin_memset(bmo2, 0xff, 1024);
    bug_o1(bno, bmo1);
    bug_o2(bno, bmo2);
    if (__builtin_memcmp(bmo1, bmo2, 1024) != 0)
      __builtin_trap();
  }
}</code></pre>
<p>Crashing as:</p>
<pre><code>$ gcc bug.c -o bug -O0 &amp;&amp; ./bug
Illegal instruction (core dumped)</code></pre>
<p>The <code>gcc</code> <a href="https://gcc.gnu.org/cgit/gcc/commit/?id=584b346a4c7a6e6e77da6dc80968401a3c08161d">fix</a>
amends mask calculation as:</p>
<pre class="diff"><code>--- a/gcc/config/i386/i386.md
+++ b/gcc/config/i386/i386.md
@@ -18168,7 +18168,8 @@
  [(set (match_dup 4) (match_dup 1))
   (set (match_dup 0)
        (any_rotate:SWI (match_dup 4)
-		       (subreg:QI (match_dup 2) 0)))]
+		       (subreg:QI
+			 (and:SI (match_dup 2) (match_dup 3)) 0)))]
  &quot;operands[4] = gen_reg_rtx (&lt;MODE&gt;mode);&quot;)
 
 (define_insn_and_split &quot;*&lt;insn&gt;&lt;mode&gt;3_mask_1&quot;
@@ -18202,7 +18203,8 @@
   == GET_MODE_BITSIZE (&lt;MODE&gt;mode) - 1&quot;
  [(set (match_dup 4) (match_dup 1))
   (set (match_dup 0)
-       (any_rotate:SWI (match_dup 4) (match_dup 2)))]
+       (any_rotate:SWI (match_dup 4)
+		       (and:QI (match_dup 2) (match_dup 3))))]
  &quot;operands[4] = gen_reg_rtx (&lt;MODE&gt;mode);&quot;)
 
 (define_insn_and_split &quot;*&lt;insn&gt;&lt;mode&gt;3_add&quot;</code></pre>
<p>Here <code>gcc</code> incorrectly compiled <code>bug_o2()</code> into a single <code>btr</code>
instruction. <code>gcc</code> assumed <code>btr</code> performs a typical 8-bit mask on
register operand like other instructions do. But in case of <code>btr</code> it’s
a 3/4/5-bit mask (for 8/16/32-bit offsets).</p>
<h3 id="mesonlsp-bug"><code>mesonlsp</code> bug</h3>
<p>The <a href="https://gcc.gnu.org/PR118856"><code>mesonlsp</code> bug</a> was also interesting.
There seemingly trivial code:</p>
<pre class="cpp"><code>// $ cat bug.cpp
#include &lt;string&gt;
#include &lt;vector&gt;

int main(){
  for (const auto &amp;vec : std::vector&lt;std::vector&lt;std::string&gt;&gt;{
           {&quot;aaa&quot;},
       }) {
  }
}</code></pre>
<p>crashed at runtime:</p>
<pre><code># ok
$ g++ bug.cpp -o bug -fsanitize=address
$ ./bug

# bad:
$ g++ bug.cpp -o bug -fsanitize=address -std=c++23
$ ./bug

=================================================================
==3828042==ERROR: AddressSanitizer: heap-use-after-free on address 0x7ba90dbe0040 at pc 0x000000404279 bp 0x7ffd9db5c110 sp 0x7ffd9db5c108
READ of size 8 at 0x7ba90dbe0040 thread T0
    #0 0x000000404278 in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_data() const (bug+0x404278)
...

0x7ba90dbe0040 is located 0 bytes inside of 32-byte region [0x7ba90dbe0040,0x7ba90dbe0060)
freed by thread T0 here:
    #0 0x7f790f1180c8 in operator delete(void*, unsigned long) (/&lt;&lt;NIX&gt;&gt;/gcc-15.0.1-lib/lib/libasan.so.8+0x1180c8)
    #1 0x000000406a4b in std::__new_allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;::deallocate(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;*, unsigned long) (bug+0x406a4b)
...

previously allocated by thread T0 here:
    #0 0x7f790f1171a8 in operator new(unsigned long) (/&lt;&lt;NIX&gt;&gt;/gcc-15.0.1-lib/lib/libasan.so.8+0x1171a8)
    #1 0x000000404c9f in std::__new_allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;::allocate(unsigned long, void const*) (bug+0x404c9f)
...

SUMMARY: AddressSanitizer: heap-use-after-free (bug+0x404278) in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_data() const
Shadow bytes around the buggy address:
  0x7ba90dbdfd80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x7ba90dbdfe00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x7ba90dbdfe80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x7ba90dbdff00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
  0x7ba90dbdff80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
=&gt;0x7ba90dbe0000: fa fa 00 00 00 fa fa fa[fd]fd fd fd fa fa fd fd
  0x7ba90dbe0080: fd fa fa fa fd fd fd fd fa fa fa fa fa fa fa fa
  0x7ba90dbe0100: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x7ba90dbe0180: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x7ba90dbe0200: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x7ba90dbe0280: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
==3828042==ABORTING</code></pre>
<p>It’s a use-after-free bug. Caused by the <code>gcc</code> bugs in temporary
variables lifetime tracking. The <code>gcc</code> fixes
(<a href="https://gcc.gnu.org/cgit/gcc/commit/?id=e96e1bb69c7b46db18e747ee379a62681bc8c82d">one</a>,
<a href="https://gcc.gnu.org/cgit/gcc/commit/?id=720c8f685210af9fc9c31810e224751102f1481e">two</a>)
are not very small, thus I’ll not post them here.</p>
<h2 id="histograms">histograms</h2>
<p>As usual what are the subsystems we found the bugs in?</p>
<ul>
<li><code>c++</code>: 8</li>
<li><code>middle-end</code>: 6</li>
<li><code>tree-optimization</code>: 4</li>
<li><code>bootstrap</code>: 2</li>
<li><code>c</code>: 2</li>
<li><code>libstdc++</code>: 2</li>
<li><code>lto</code>: 2</li>
<li><code>rtl-optimization</code>: 2</li>
<li><code>target</code>: 2</li>
<li><code>analyzer</code>: 1</li>
<li><code>preprocessor</code>: 1</li>
</ul>
<p>Surprisingly this time <code>c++</code> is at the top of the list. It feels like
coroutine related bugs pushed the needle. Otherwise <code>middle-end</code> and
<code>tree-optimization</code> that follow are expected.</p>
<h2 id="parting-words">parting words</h2>
<p>Of the bugs above it looks like I reported only 18 of those while 13
were already reported by others.</p>
<p>Optimised handling of global constant arrays (<code>#embed</code>-style code) caused
numerous bugs in various subsystems from compiler crashes to wrong code.</p>
<p>The most disruptive change probably is the switch to
<a href="https://trofi.github.io/posts/326-gcc-15-switched-to-c23.html"><code>c23</code></a>.</p>
<p>Past month was very quiet from <code>gcc</code> bugs view. <code>gcc-15</code> is in a good
shape to be released.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 19 Apr 2025 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/332-gcc-15-bugs-pile-2.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>Trying out helix editor</title>
    <link>https://trofi.github.io/posts/331-trying-out-helix-editor.html</link>
    <description><![CDATA[<p>This is another February story about text editors similar to the
<a href="https://trofi.github.io/posts/277-from-mcedit-to-vim.html"><code>vim</code> one</a>. You might want to
ignore this one as well :)</p>
<h2 id="tldr">Tl;DR</h2>
<p><code>helix</code> is a nice program: I switched to it from <code>vim</code> as a default text
editor. If you never heard of <code>helix</code> editor and are <code>vim</code> or <code>nvim</code>
user I suggest you to have a look at it. <code>hx --tutor</code> is short and yet
it covers a few cool things. <a href="https://helix-editor.com/" class="uri">https://helix-editor.com/</a> has a nice
<code>asciinema</code> intro into how it looks like.</p>
<h2 id="background">Background</h2>
<p>I am a happy 2 years old <code>vim</code> user with a simple
<a href="https://github.com/trofi/home/blob/master/.vimrc"><code>~/.vimrc</code> config</a>.
Strong <code>vim</code> features for me are:</p>
<ul>
<li>startup speed</li>
<li>UI speed</li>
<li>basic spell checking</li>
<li>syntax highlighting for many languages</li>
<li>tab/space whitespace highlighting</li>
<li>configurable color scheme (ideally a blue one)</li>
<li><code>emacs</code>-style page scrolling and line editing when in insert mode</li>
</ul>
<p>I still manage to use <code>vim</code> without any external plugins.</p>
<p>The weak <code>vim</code> points for me are:</p>
<ul>
<li><code>vim</code>-specific configuration language (I don’t know how to read anything
beyond trivial <code>set</code> assignments)</li>
<li><code>vim</code>-specific regex language extensions (<code>:h /magic</code>)</li>
<li>lack of language server protocol support (<code>LSP</code>) support without
external plugins</li>
<li>defaults keep compatibility with old versions of <code>vim</code> which sometimes
don’t make sense to me as a new user</li>
<li>it’s written in an ancient form of <code>C</code> which is known to trigger some
ubiquitous safety checks and have to disable them like
<a href="https://github.com/vim/vim/issues/5581"><code>-D_FORTIFY_SOURCE=1</code> hack</a></li>
<li>“backwards” model of many actions in normal mode</li>
</ul>
<p>To expand a bit on “backwards” model here is a simple example: in <code>vim</code>
the key sequence <code>df&lt;</code> will delete (<code>d</code>) everything from current
position to <code>&lt;</code> symbol inclusive. But you will not see what exactly
<code>vim</code> is about to delete until you press <code>&lt;</code>. Would be nice to see what
<code>f&lt;</code> selects first and only then press <code>d</code> with more confidence. As a
result I rarely use such shortcuts despite them being very convenient
for a common editing use case. <code>vim</code>’s very own <code>vf&lt;d</code> command sequence
is a lot more intuitive to what I would expect, but that requires switch
to a visual mode (prefixed <code>v</code>).</p>
<h2 id="a-fun-problem">A fun problem</h2>
<p>From time to time I use <code>vim</code> to write <code>markdown</code> files (such as this
blog post). I like pasting code snippets here and there for better
illustration. Once day I idly wondered if <code>vim</code> could be taught to
support syntax highlighting of the code snippets within the <code>markdown</code>
files:</p>
<pre class="markdown"><code># Would it not be magic if it just worked?

An example `c` snippet within `markdown`:

```c
// What's up here with the highlight?
int like_this_one(long long);
```</code></pre>
<p><code>vim</code> does not do any special highlighting in a <code>c</code> block.</p>
<p>Many days later I encountered a mastodon thread that mentioned <code>vim</code>’s
proposal to use <code>TextMate</code> grammar
<a href="https://github.com/vim/vim/issues/9087">Issue#9087</a>. It discussed
various options of different highlighter engines, their pros, cons, and
what <code>vim</code> should use longer term.</p>
<p><a href="https://tree-sitter.github.io/tree-sitter/"><code>Tree-sitter</code></a> was
specifically mentioned multiple times there as The Solution to all
the highlighting problems an editor could have. It’s a long discussion
with many branches.</p>
<p>From there I learned about (and started using) a few <code>tree-sitter</code> based
programs, like <a href="https://github.com/sharkdp/bat"><code>bat</code></a>,
<a href="https://difftastic.wilfred.me.uk/"><code>difftastic</code></a> and
<a href="https://helix-editor.com/"><code>helix</code></a>.</p>
<p><code>helix</code> editor was mentioned as one of <code>tree-sitter</code> users. I heard
about <code>helix</code> before from my friend. At the time I just started my <code>vim</code>
journey and I did not give <code>helix</code> a serious try.</p>
<p>But this time I felt I was able to compare both.</p>
<h2 id="my-setup">My setup</h2>
<p>I got <code>helix</code> up and running to the state I could use it by default in
2 short evenings. After that I did a few incremental tweaks. My whole
configuration right now is one page long:</p>
<pre class="toml"><code># $ cat config.toml
[editor]
auto-pairs = false
bufferline = &quot;always&quot;
rulers = [73]
true-color = true # TMUX term does not always agree

[editor.statusline]
# added &quot;file-type&quot;, &quot;position-percentage&quot;
right = [&quot;file-type&quot;, &quot;diagnostics&quot;, &quot;selections&quot;, &quot;register&quot;, &quot;position&quot;, &quot;position-percentage&quot;, &quot;file-encoding&quot;]

[editor.whitespace.render]
space = &quot;all&quot;
tab = &quot;all&quot;
nbsp = &quot;all&quot;
nnbsp = &quot;all&quot;

[editor.whitespace.characters]
tab = &quot;&gt;&quot;
tabpad = &quot;-&quot;

[keys.insert]
C-c = &quot;normal_mode&quot;
C-up = [&quot;scroll_up&quot;, &quot;move_visual_line_up&quot;]
C-down = [&quot;scroll_down&quot;, &quot;move_visual_line_down&quot;]

[keys.normal]
C-c = &quot;normal_mode&quot;
C-up = [&quot;scroll_up&quot;, &quot;move_visual_line_up&quot;]
C-down = [&quot;scroll_down&quot;, &quot;move_visual_line_down&quot;]
ins = [&quot;insert_mode&quot;]

[keys.select]
C-c = &quot;normal_mode&quot;
C-up = [&quot;scroll_up&quot;, &quot;move_visual_line_up&quot;]
C-down = [&quot;scroll_down&quot;, &quot;move_visual_line_down&quot;]</code></pre>
<p>On top of that I enabled a few language servers not configured in
<code>helix</code> by default:</p>
<pre class="toml"><code># $ cat languages.toml

# spell checker
[language-server.harper-ls]
command = &quot;harper-ls&quot;
args = [&quot;--stdio&quot;]

[[language]]
name = &quot;markdown&quot;
language-servers = [&quot;marksman&quot;, &quot;harper-ls&quot;]
auto-format = false

[language-server.rust-analyzer.config]
check.command = &quot;clippy&quot;</code></pre>
<h2 id="niceties">Niceties</h2>
<p>I was surprised to discover how much <code>helix</code> already provides without
much extra configuration:</p>
<ul>
<li>24-bit colors in the terminal emulator (I use <code>alacritty</code> most of the
time and I appreciate finer grained colors)</li>
<li>a ton of pre-configure <code>LSP</code> servers: <code>hx --health</code> reports 273 lines</li>
<li>helpful pop-ups when prefix keys are pressed, like <code>&lt;space&gt;</code>, <code>:</code>, or
<code>m</code></li>
<li><code>tree-sitter</code>-based syntax highlighting makes highlighting more
consistent across languages</li>
</ul>
<h3 id="toml-configuration-language"><code>toml</code> configuration language</h3>
<p>I grew to like <code>toml</code> compared to other custom <code>.ini</code>-like formats.
Custom configurations are sometimes not general enough. For example in
<code>nix.conf</code> config there is no way (to my knowledge) to add a trailing
whitespace to:</p>
<pre class="ini"><code>bash-prompt-suffix = dev&gt;</code></pre>
<p><code>toml</code> on the other hand is more predictable in this regard. It is quite
common and expressive enough to encode simple arrays and strings with
any contents.</p>
<p>I’m a bit afraid of the configurations that are programming languages.
It’s not too bad for me when they are general-purpose languages with
good error messages, well understood semantics, and present
introspection for available options and helpers.</p>
<h3 id="color-themes-can-be-set-in-rgb">Color themes can be set in <code>RGB</code></h3>
<p>Using full <code>RGB</code> range to define color elements is great. <code>helix</code> comes
with a nice dark default theme suitable for long editing sessions.</p>
<p>The only caveat of a default theme is that some colors are not unique
for cases where it matters. For example to work around a bug in default
theme I needed to pick a different color for secondary selection:</p>
<pre class="toml"><code># $ cat themes/sf.toml
inherits = &quot;default&quot;

# workaround https://github.com/helix-editor/helix/issues/12601
&quot;ui.selection&quot; = { bg = &quot;#540020&quot; }
&quot;ui.selection.primary&quot; = { bg = &quot;#540099&quot; }</code></pre>
<p>Using <code>RGB</code> is so much better than picking a pre-defined color. I did
not know I need it until I tried :)</p>
<h3 id="selection-and-multi-selection-feels-intuitive">Selection and multi-selection feels intuitive</h3>
<p><code>helix</code> does show what navigation commands select before I about to do
an action. An example would be <code>vim</code>’s <code>df"</code> sequence compared to
<code>helix</code>’s <code>f"d</code> sequence. Before pressing <code>d</code> I am more confident what
it is about to delete.</p>
<p>After using <code>helix</code> for a while I am actually more comfortable using
<code>vim</code>’s <code>f</code> / <code>t</code> (and similar) navigation commands because I understand
better what they actually do.</p>
<p>Multi-selection is also very natural: you create a bunch of cursors
based on you search (<code>s</code> command) in your selection (or by extending a
column with <code>C</code> command) and start modifying text interactively at each
active cursor at the same time. In multi-selection mode it’s more
natural to use navigation commands like <code>f</code>, <code>t</code> and <code>w</code> to do bulk
edits. In <code>vim</code> I used to use arrow keys more and did not see much use
for more complex navigation commands. But now once I’m used to then I’m
using them in <code>vim</code> as well.</p>
<h3 id="ide-experience-is-unexpectedly-good">IDE experience is unexpectedly good</h3>
<p>The <code>LSP</code>s provide you a navigation, hints, symbol search and so much
more. It’s so easy to explore new and existing projects for various
cross-references. Before jumping into the target you can look at the bit
of context in preview and it might be enough for a thing you are
looking for!</p>
<p>Even in this post <code>&lt;space&gt;s</code> (symbol lookup) provides a Table Of
Contents output with a preview.</p>
<p>For development projects <code>&lt;space&gt;f</code> provides you a file picker with a
fuzzy search. Now I have to rely a lot less on mashing <code>&lt;TAB&gt;</code> in the
shell to get to a file I want to edit. I even installed <code>fzf</code> to emulate
similar fuzzy search experience when I need it in <code>bash</code> to pass a file
to other programs.</p>
<p>To make <code>clangd</code> to work (a <code>C</code> or <code>C++</code> LSP) one needs
a <code>compile_commands.json</code> file. <code>meson</code>-based projects just create it
unconditionally, <code>cmake</code>-based projects do it after
<code>-DCMAKE_EXPORT_COMPILE_COMMANDS=YES</code> option is enabled and for
<code>autotools</code>-based projects there is a
<a href="https://github.com/rizsotto/Bear"><code>bear</code></a> hack to wrap <code>make</code> and
extract the commands after the build.</p>
<p><code>bear</code> is not able to handle projects like <code>gcc</code> where local <code>gcc</code> is
used to compile most of the code. But smaller ones work good enough.</p>
<p><a href="https://github.com/helix-editor/helix/wiki/Language-Server-Configurations" class="uri">https://github.com/helix-editor/helix/wiki/Language-Server-Configurations</a>
has tips for many more language servers.</p>
<h2 id="snags">Snags</h2>
<p>Over past month of <code>helix</code> use as a default editor I encountered a few
limitations I had to work around or just accept the limitation.</p>
<h3 id="trailing-whitespace-highlighting-minor">Trailing whitespace highlighting (minor)</h3>
<p>Whitespace highlighting is a bit blunt: I would prefer spaces to be
highlighted only in trailing context while highlighting tabs everywhere.
<a href="https://github.com/helix-editor/helix/issues/2719" class="uri">https://github.com/helix-editor/helix/issues/2719</a>.</p>
<p>But it’s not a big deal. I need to be careful to copy text into clipboard
buffer not with a mouse selection but via <code>&lt;space&gt;y</code></p>
<h3 id="spell-checking-minor">Spell checking (minor)</h3>
<p>I was surprised to see that <code>helix</code> does not yet have spell checking
integration and was afraid I could not use it as I make huge amount of
typos and rely on <code>aspell</code> so much. The integration is tracked by
<a href="https://github.com/helix-editor/helix/issues/11660" class="uri">https://github.com/helix-editor/helix/issues/11660</a>.</p>
<p>But luckily there are a few language servers that do implement spell
checking. I’m using <code>harper</code> as:</p>
<pre class="toml"><code>[language-server.harper-ls]
command = &quot;harper-ls&quot;
args = [&quot;--stdio&quot;]</code></pre>
<p>It works reasonably well for English but does not support anything else.
Having an <code>LSP</code> based on something like <code>aspell</code> would be nice.</p>
<h3 id="default-theme-colors-minor">Default theme colors (minor)</h3>
<p><code>helix</code> tutorial has section that demonstrates primary and secondary
selections via <code>(</code> and <code>)</code> navigation. But the colors of both selection
types are identical in the default theme. That was very confusing. The
issue is 2.5 years old:
<a href="https://github.com/helix-editor/helix/issues/12601" class="uri">https://github.com/helix-editor/helix/issues/12601</a>.</p>
<p>Luckily the workaround is trivial: you can modify default theme just
for selection distinct colors:</p>
<pre class="toml"><code>inherits = &quot;default&quot;

&quot;ui.selection&quot; = { bg = &quot;#540020&quot; }
&quot;ui.selection.primary&quot; = { bg = &quot;#540099&quot; }</code></pre>
<h3 id="saving-last-cursor-position-in-the-file">Saving last cursor position in the file</h3>
<p>I like the save/restore of the file cursor in edited file. It was a
default <code>vim</code> setting. <code>helix</code> does not have an equivalent yet:
<a href="https://github.com/helix-editor/helix/issues/1133" class="uri">https://github.com/helix-editor/helix/issues/1133</a></p>
<h3 id="buffer-search-only-highlights-current-search-not-all">Buffer search only highlights current search, not all</h3>
<p>In <code>vim</code> I was using <code>set hlsearch</code> option to highlight (and keep
highlighted) all the occurrences that match the search. Not just the
current one. <code>helix</code> is yet to implement it:
<a href="https://github.com/helix-editor/helix/issues/1733" class="uri">https://github.com/helix-editor/helix/issues/1733</a>.</p>
<h3 id="generic-autocomplete">Generic autocomplete</h3>
<p>I like autocompletion of arbitrary words in a text file.
So far <code>helix</code> only ever does <code>LSP</code> autocompletion.</p>
<p><a href="https://github.com/helix-editor/helix/issues/1063" class="uri">https://github.com/helix-editor/helix/issues/1063</a> tracks the addition
of a simple keyword-based completer.</p>
<h2 id="parting-words">Parting words</h2>
<p><code>helix</code> feels like a good modern <code>vim</code> successor for my use cases. It’s
extensive use of <code>RGB</code> colors and unicode characters gives a look and
feel of a program beyond a terminal application. A ton of pre-configured
<code>LSP</code>s makes it a nice lightweight code navigator on par with IDE
experience.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 15 Feb 2025 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/331-trying-out-helix-editor.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>Another Nix Expression Language non-determinism example</title>
    <link>https://trofi.github.io/posts/330-another-nix-language-nondeterminism-example.html</link>
    <description><![CDATA[<p>Today I found another source of non-determinism in <code>nix expression language</code>.
This time it’s a
<a href="https://github.com/NixOS/nix/issues/12106"><code>builtins.sort</code></a> primitive!</p>
<p>How do you break <code>sort</code>?</p>
<p>Compared to the
<a href="https://trofi.github.io/posts/292-nix-language-nondeterminism-example.html">previous non-determinism instance</a>
this case of non-determinism breaking <code>sort</code> is not as arcane.</p>
<h2 id="a-working-sort-example">a working <code>sort</code> example</h2>
<p>Before triggering the problematic condition let’s look at a working sort:</p>
<pre><code>$ nix repl
nix-repl&gt; builtins.sort builtins.lessThan [ 4 3 2 1 ]
[
  1
  2
  3
  4
]

nix-repl&gt; builtins.sort (a: b: a &lt; b) [ 4 3 2 1 ]
[
  1
  2
  3
  4
]</code></pre>
<p>All nice and good: we pass the comparison predicate and get some result
back. In the first case we are passing a builtin comparator. In the
second case we write a lambda that implements <code>&lt;</code>. Nothing fancy.</p>
<p>Normally <code>sort</code> function expects a bunch of properties from the passed
predicate, like
<a href="https://en.wikipedia.org/wiki/Weak_ordering#Strict_weak_orderings">“strict weak ordering”</a>
to return something that looks sorted.</p>
<h2 id="suspicious-sort-call">suspicious <code>sort</code> call</h2>
<p>But what happens if we pass a predicate that does not satisfy that
property? On vanilla <code>nix</code> that would be:</p>
<pre><code>nix-repl&gt; builtins.sort (a: b: true) [ 4 3 1 2 ]
[ 2 1 3 4 ]</code></pre>
<p>The result is not sensible, but at least it did not crash. All good?</p>
<p><strong>Quiz question:</strong> Is this returned order guaranteed to be the same across <code>nix</code> implementations
on different platforms?</p>
<h2 id="triggering-the-non-determinism">triggering the non-determinism</h2>
<p>Today I tried to build <code>nix</code> package with <code>gcc</code> <code>STL</code>
<a href="https://gcc.gnu.org/onlinedocs/libstdc++/manual/debug_mode_using.html#debug_mode.using.mode">debugging enabled</a>. In theory it’s simple: you pass <code>-D_GLIBCXX_DEBUG</code> via
<code>CXXFLAGS</code> and you get your debugging for free.</p>
<p>I was chasing an unrelated <code>nix</code> memory corruption bug and did just that.
I hoped for a simple case like the past <a href="https://github.com/NixOS/nix/pull/8825">PR#8825</a>.</p>
<p>To my surprise <code>nixpkgs</code> evaluation started triggering <code>libstdc++</code>
assertions. For the above “suspicious sort” example the execution was:</p>
<pre><code>$ nix eval --expr 'builtins.sort (a: b: true) [ 4 3 2 1 ]

/nix/store/L89IQC7AM6I60Y8VK507ZWRZXF0WCD3V-gcc-14-20241116/include/c++/14-20241116/bits/stl_algo.h:5027:
In function:
    void std::stable_sort(_RAIter, _RAIter, _Compare) [with _RAIter =
    nix::Value**; _Compare = nix::prim_sort(EvalState&amp;, PosIdx, Value**,
    Value&amp;)::&lt;lambda(nix::Value*, nix::Value*)&gt;]

Error: comparison doesn't meet irreflexive requirements, assert(!(a &lt; a)).

Objects involved in the operation:
    instance &quot;functor&quot; @ 0x7ffd7d2fdb00 {
      type = nix::prim_sort(nix::EvalState&amp;, nix::PosIdx, nix::Value**, nix::Value&amp;)::{lambda(nix::Value*, nix::Value*)#1};
    }
    iterator::value_type &quot;ordered type&quot;  {
      type = nix::Value*;
    }
Aborted (core dumped)</code></pre>
<p>Uh-oh. A crash where there was none before. Note how <code>libstdc++</code> tells us
that our comparator is not expected to return <code>true</code> for <code>a &lt; a</code>.</p>
<h2 id="builtins.sort-implementation"><code>builtins.sort</code> implementation</h2>
<p>Looking at the <code>nix</code> implementation around the crash it reveals that
<code>nix</code> uses <code>std::stable_sort</code> to implement <code>builtins.sort</code>
(<a href="https://github.com/NixOS/nix/blob/bff9296ab997269d703c5222b7e17d67a107aeed/src/libexpr/primops.cc#L3642">link</a>) with no predicate validation:</p>
<pre class="cpp"><code>static void prim_sort(EvalState &amp; state, const PosIdx pos, Value * * args, Value &amp; v)
{
    state.forceList(*args[1], pos, &quot;while evaluating the second argument passed to builtins.sort&quot;);

    auto len = args[1]-&gt;listSize();
    if (len == 0) {
        v = *args[1];
        return;
    }

    state.forceFunction(*args[0], pos, &quot;while evaluating the first argument passed to builtins.sort&quot;);

    auto list = state.buildList(len);
    for (const auto &amp; [n, v] : enumerate(list))
        state.forceValue(*(v = args[1]-&gt;listElems()[n]), pos);

    auto comparator = [&amp;](Value * a, Value * b) {
        /* Optimization: if the comparator is lessThan, bypass
           callFunction. */
        if (args[0]-&gt;isPrimOp()) {
            auto ptr = args[0]-&gt;primOp()-&gt;fun.target&lt;decltype(&amp;prim_lessThan)&gt;();
            if (ptr &amp;&amp; *ptr == prim_lessThan)
                return CompareValues(state, noPos, &quot;while evaluating the ordering function passed to builtins.sort&quot;)(a, b);
        }

        Value * vs[] = {a, b};
        Value vBool;
        state.callFunction(*args[0], vs, vBool, noPos);
        return state.forceBool(vBool, pos, &quot;while evaluating the return value of the sorting function passed to builtins.sort&quot;);
    };

    /* FIXME: std::sort can segfault if the comparator is not a strict
       weak ordering. What to do? std::stable_sort() seems more
       resilient, but no guarantees... */
    std::stable_sort(list.begin(), list.end(), comparator);

    v.mkList(list);
}</code></pre>
<p>Here <code>comparator()</code> calls user-supplied function written in
<code>nix expression language</code> directly (if we ignore a performance special
case) into <code>std::stable_sort()</code>. The comment suggests that <code>std::sort()</code>
was already crashing here.</p>
<p>This means that today <code>builtins.sort</code> semantics are following <code>c++</code>’s
<code>std::stable_sort()</code> along with it’s undefined behaviours and
instability for non-conformant <code>comparator()</code> predicate.</p>
<h2 id="tracking-down-bad-predicates">tracking down bad predicates</h2>
<p><code>nixpkgs</code> is a vast code base. It’s quite hard to figure out which part
of <code>nix expression language</code> code triggers this condition from a <code>C++</code>
stack trace. I added the following hack into local <code>nix</code> to convert
those violations into nix-level exceptions:</p>
<pre class="diff"><code>--- a/src/libexpr/primops.cc
+++ b/src/libexpr/primops.cc
@@ -3633,6 +3633,24 @@ static void prim_sort(EvalState &amp; state, const PosIdx pos, Value * * args, Value
                 return CompareValues(state, noPos, &quot;while evaluating the ordering function passed to builtins.sort&quot;)(a, b);
         }

+        /* Validate basic ordering requirements for comparator: */
+        {
+            Value * vs[] = {a, a};
+            Value vBool;
+            state.callFunction(*args[0], vs, vBool, noPos);
+            bool br = state.forceBool(vBool, pos, &quot;while evaluating the return value of the sorting function passed to builtins.sort&quot;);
+            if (br)
+                state.error&lt;EvalError&gt;(&quot;!(a &lt; a) assert failed&quot;).atPos(pos).debugThrow();
+        }
+        {
+            Value * vs[] = {b, b};
+            Value vBool;
+            state.callFunction(*args[0], vs, vBool, noPos);
+            bool br = state.forceBool(vBool, pos, &quot;while evaluating the return value of the sorting function passed to builtins.sort&quot;);
+            if (br)
+                state.error&lt;EvalError&gt;(&quot;!(b &lt; b) assert failed&quot;).atPos(pos).debugThrow();
+        }
+
         Value * vs[] = {a, b};
         Value vBool;
         state.callFunction(*args[0], vs, vBool, noPos);</code></pre>
<p>Here before calling the <code>compare(a,b)</code> against two different list
elements we are making sure that <code>compare(a,a)</code> and <code>compare(b,b)</code> does
not return <code>true</code>.</p>
<p>And now the error is a bit less intimidating:</p>
<pre><code>nix-repl&gt; builtins.sort (a: b: true) [ 4 3 2 1 ]
error:
       … while calling the 'sort' builtin
         at «string»:1:1:
            1| builtins.sort (a: b: true) [ 4 3 2 1 ]
             | ^

       error: !(a &lt; a) assert failed</code></pre>
<p>On a <code>nixpkgs</code> input the evaluation now fails as:</p>
<pre><code>$ nix-instantiate -A colmapWithCuda --show-trace
error:
       … while calling a functor (an attribute set with a '__functor' attribute)
         at pkgs/top-level/all-packages.nix:5843:20:
         5842|   colmap = libsForQt5.callPackage ../applications/science/misc/colmap { inherit (config) cudaSupport; };
         5843|   colmapWithCuda = colmap.override { cudaSupport = true; };
             |                    ^
         5844|
...
         at pkgs/development/cuda-modules/generic-builders/multiplex.nix:88:17:
           87|   # perSystemReleases :: List Package
           88|   allReleases = lib.pipe releaseSets [
             |                 ^
           89|     (lib.attrValues)</code></pre>
<p>This points us at
<a href="https://github.com/NixOS/nixpkgs/blob/1557114798a3951db0794379f26b68a5fdf68b12/pkgs/development/cuda-modules/generic-builders/multiplex.nix#L83"><code>cuda-modules/generic-builders/multiplex.nix</code></a>:</p>
<pre class="nix"><code>  preferable =
    p1: p2: (isSupported p2 -&gt; isSupported p1) &amp;&amp; (strings.versionAtLeast p1.version p2.version);

  # ...

  newest = builtins.head (builtins.sort preferable allReleases);</code></pre>
<p>Can you quickly say if <code>preferable</code> satisfies <code>lessThan</code> requirements?</p>
<p><code>left &gt;= right</code> is generally problematic for sorts:</p>
<pre><code>nix-repl&gt; builtins.sort (a: b: a &gt;= b) [ 4 3 3 1 ]
error:
       … while calling the 'sort' builtin
         at «string»:1:1:
            1| builtins.sort (a: b: a &gt;= b) [ 4 3 3 1 ]
             | ^

       error: !(a &lt; a) assert failed</code></pre>
<p>To make the comparator stricter it should contain strict inequality,
like <code>b &lt; a</code> or <code>!(a &gt;= b)</code>:</p>
<pre><code>nix-repl&gt; builtins.sort (a: b: b &lt; a) [ 4 3 3 1 ]
[
  4
  3
  3
  1
]

nix-repl&gt; builtins.sort (a: b: !(b &gt;= a)) [ 4 3 3 1 ]
[
  4
  3
  3
  1
]</code></pre>
<p>I proposed a seemingly trivial change as <a href="https://github.com/NixOS/nixpkgs/pull/368366">PR#368366</a>:</p>
<pre class="diff"><code>--- a/pkgs/development/cuda-modules/generic-builders/multiplex.nix
+++ b/pkgs/development/cuda-modules/generic-builders/multiplex.nix
@@ -81,7 +81,7 @@ let
   redistArch = flags.getRedistArch hostPlatform.system;

   preferable =
-    p1: p2: (isSupported p2 -&gt; isSupported p1) &amp;&amp; (strings.versionAtLeast p1.version p2.version);
+    p1: p2: (isSupported p2 -&gt; isSupported p1) &amp;&amp; (strings.versionOlder p2.version p1.version);

   # All the supported packages we can build for our platform.
   # perSystemReleases :: List Package
</code></pre>
<p>I’m not sure it’s correct.</p>
<p><code>cuda-modules</code> is not the only <code>sort</code> <code>lessThan</code> property violation. Next
failure is a <code>stan</code> package:</p>
<pre><code>$ nix build --no-link -f. cmdstan --show-trace
...
       … while calling the 'sort' builtin
         at pkgs/build-support/coq/meta-fetch/default.nix:115:55:
          114|     if (isString x &amp;&amp; match &quot;^/.*&quot; x == null) then
          115|       findFirst (v: versions.majorMinor v == x) null (sort versionAtLeast (attrNames release))
             |                                                       ^
          116|     else

       error: !(a &lt; a) assert failed</code></pre>
<p>Here you can already see that the pattern is suspiciously similar:
<code>sort versionAtLeast</code> probably does not do what it’s expected to do.</p>
<p>Proposed a similar fix as <a href="https://github.com/NixOS/nixpkgs/pull/368429">PR#368429</a>.</p>
<p>Other packages affected:</p>
<ul>
<li><code>mathematica</code>: <a href="https://github.com/NixOS/nixpkgs/pull/368433">PR#368433</a></li>
</ul>
<p>More stuff to fix!</p>
<h2 id="parting-words">Parting words</h2>
<p><code>nix expression language</code> used in <code>nix</code> package manager is of
minimalistic kind: it does not have much syntax sugar
hoping to reach high performance and predictability of the evaluation.
And it it manages to surprise me time and time again where I have to
debug both <code>nix expression language</code> and it’s underlying <code>c++</code>
implementation.</p>
<p>Sorting is tricky if you allow a user-supplied sorting predicate.</p>
<p><code>nixpkgs</code> has a few more sorting predicate violations that needs to be
fixed. I found at least <a href="https://github.com/NixOS/nixpkgs/pull/368366"><code>cuda</code></a>,
<a href="https://github.com/NixOS/nixpkgs/pull/368429"><code>coq</code></a> and
<a href="https://github.com/NixOS/nixpkgs/pull/368433"><code>mathematica</code></a>.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Thu, 26 Dec 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/330-another-nix-language-nondeterminism-example.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>Rebasing past reformats</title>
    <link>https://trofi.github.io/posts/329-rebasing-past-reformats.html</link>
    <description><![CDATA[<h2 id="tldr">TL;DR</h2>
<p>Did you ever have to deal with a huge list of conflicts on rebase caused
by automatic reformatting of an upstream code base?</p>
<p>If you got into a similar situation you might be able to automatically
recreate your changes with <code>git filter-branch --tree-filter</code> and a
<code>git commit --allow-empty</code> trick.</p>
<h2 id="story-mode">story mode</h2>
<p>I have local fork of <code>staging</code> branch of
<a href="https://github.com/NixOS/nixpkgs/"><code>nixpkgs</code></a> <code>git</code> repository to do
various tests against experimental upstream packages (like <code>gcc</code> from
<code>master</code> branch) or experimental <code>nix</code> features (like <code>ca-derivations</code>).</p>
<p>I have about 350 patches in the fork. I sync this forked branch about
daily against the upstream <code>nixpkgs/staging</code>. Most of the time
<code>git pull --rebase</code> is enough and no conflicts are there. Once a month
there is one or two files to tweak. Not a big deal.</p>
<p>A few days ago <code>nixpkgs</code> landed a partial source code reformatting
patch as <a href="https://github.com/NixOS/nixpkgs/pull/322537">PR#322537</a>. It
automatically re-indents ~21000 <code>.nix</code> files in the repository with a
<code>nixfmt</code> tool. My <code>git pull --rebase</code> generated conflicts on first few
patches against my branch. I aborted it with <code>git rebase --abort</code>.</p>
<p>I would not be able to manually solve such a huge list of commits and I
wondered if I could somehow regenerate my patches against the indented
source.</p>
<p>In theory rebasing past such change should be a mechanical operation: I
have the source tree before the patch and after the patch. All I need to
do is to autoformat both <code>before</code> and <code>after</code> trees and then <code>diff</code>
them.</p>
<p>I managed to do it with help of <code>git commit --allow-empty</code> and
<code>git filter-branch --tree-filter</code>.</p>
<p>Here are my exact commands used:</p>
<h3 id="actual-commands">actual commands</h3>
<p>Here is the step-by-step I did to rebase my local <code>staging</code> branch past
the source reformatting
<a href="https://github.com/NixOS/nixpkgs/commit/667d42c00d566e091e6b9a19b365099315d0e611"><code>667d42c00d566e091e6b9a19b365099315d0e611</code> commit</a>
to avoid conflicts:</p>
<ol type="1">
<li><p>Create an empty commit (to absorb initial formatting later):</p>
<pre><code>$ git commit --allow-empty -m &quot;EMPTY commit: will absorb relevant formatting changes&quot;</code></pre></li>
<li><p>Move the last empty commit in the patch queue to the beginning of
the patch queue:</p>
<pre><code>$ git rebase -i --keep-base</code></pre>
<p>In the edit menu move the
<code>"EMPTY commit: will absorb relevant formatting changes"</code> entry from
last line of the list to the first line.</p></li>
<li><p>Get files in the branch affected by the formatting change:</p>
<p>The formatting change is <code>667d42c00d566e091e6b9a19b365099315d0e611</code>.</p>
<pre><code>$ FORMATTED_FILES=$(git diff --name-only \
    667d42c00d566e091e6b9a19b365099315d0e611^..667d42c00d566e091e6b9a19b365099315d0e611 \
    -- $(git diff --name-only origin/staging...staging) | tr $'\n' ' ')</code></pre>
<p>This will populate <code>FORMATTED_FILES</code> shell variable with affected
files.</p></li>
<li><p>Reformat the <code>$FORMATTED_FILES</code> files:</p>
<pre><code>$ FILTER_BRANCH_SQUELCH_WARNING=1 git filter-branch \
  --tree-filter &quot;nixfmt $FORMATTED_FILES&quot; -- $(git merge-base origin/staging staging)..
...
Rewrite 6fc0a951e9b7a7e3f80628ca0a6c4c9f54fd2dd6 (56/327) (65 seconds passed, remaining 314 predicted)
...
Rewrite c20df82da66da6521f355af508bfedc047cffa64 (326/326) (1183 seconds passed, remaining 0 predicted)
Ref 'refs/heads/staging' was rewritten</code></pre>
<p>This command will populate our empty commit with reformatting changes
and rebase the rest of commits against it without manual intervention.</p></li>
<li><p>Rebase past the formatting as usual:</p>
<pre><code>$ git rebase -i</code></pre>
<p>Here <code>git rebase -i</code> will tell you that the first commit became empty.
You can either skip or commit an empty one. I skipped it with
<code>git rebase --skip</code>.</p></li>
</ol>
<p>Done!</p>
<p>Once I executed the above I got just one trivial conflict unrelated to
reformatting.</p>
<h2 id="parting-words">parting words</h2>
<p><code>git filter-branch --tree-filter</code> is a great tool to mangle the
repository! But before using it make sure you back you local tree: it’s
very easy to get it to “destroy” all your work (<code>git reflog</code> will still
be able to save your past commits).</p>
<p>It took <code>git filter-branch --tree-filter</code> about 5 minutes to rebase
<code>326</code> commits that touch ~200 files. My understanding is that most time
is spent on <code>nixfmt</code> utility itself and not on <code>git</code> operations.
<code>nixfmt</code> is not very fast: it takes about a minute to reformat the whole
of <code>nixpkgs</code> (~300MB of <code>.nix</code> files).</p>
<p><code>nixpkgs</code> plans for reformat event more sources in future. I will likely
be using this tip a few more times.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Thu, 12 Dec 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/329-rebasing-past-reformats.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>C union initialization and gcc-15</title>
    <link>https://trofi.github.io/posts/328-c-union-init-and-gcc-15.html</link>
    <description><![CDATA[<h2 id="a-contrived-example">a contrived example</h2>
<p>Let’s start from a quiz. What do you think will this program print:</p>
<pre class="c"><code>#include &lt;stdio.h&gt;

__attribute__((noipa)) static void use_stack(void) {
    volatile int foo[] = { 0x40, 0x41, 0x42, 0x43, };
}

__attribute__((noipa)) static int do_it(void) {
    // use 'volatile' to inhibit constant propagation
    volatile union {
        int dummy;
        struct { int fs[4]; } s;
    } v = { 0 };
    return v.s.fs[3];
}

int main(void) {
    use_stack();
    int r = do_it();
    printf(&quot;v.s:\n&quot;);
    printf(&quot;  .fs[3] = %#08x\n&quot;, r);
}</code></pre>
<p>The program initializes <code>v</code> union with <code>{ 0 }</code>. Which should be an
equivalent of <code>v.dummy = 0;</code>. Then the program accesses <code>v.s.fs[3]</code>.
That element does not overlap in memory with <code>v.dummy</code>. What should it
do?</p>
<p>One of the possible answers is: <code>v.s.fs[3]</code> is a garbage value.</p>
<p>Let’s try to run it on <code>gcc-14</code>:</p>
<pre><code>$ gcc-14 a.c -o a -O2 &amp;&amp; ./a
v.s:
  .fs[3] = 00000000</code></pre>
<p>The value is all zeros. Is it a coincidence? <code>valgrind</code> does not
complain either. Let’s have a peek at the disassembly dump:</p>
<pre class="asm"><code>; $ objdump --no-addresses --no-show-raw-insn -d a
&lt;use_stack&gt;:
        movdqa 0xea8(%rip),%xmm0 ; load the constant from memory
        movaps %xmm0,-0x18(%rsp) ; store the constant on stack
        ret
        xchg   %ax,%ax

&lt;do_it&gt;:
        pxor   %xmm0,%xmm0       ; zero-initialize 16 bytes
        movaps %xmm0,-0x18(%rsp) ; store all 16 bytes of zeros on stack
        mov    -0xc(%rsp),%eax   ; read 32-bits of zeros (part of 16-byte
                                 ; zeroing one line above)
        ret</code></pre>
<p><code>gcc-14</code> implements <code>v = { 0 };</code> as a 128-bit (16-byte)
zero initialization of <code>sizeof(v)</code> via
<code>pxor %xmm0,%xmm0; movaps %xmm0,-0x18(%rsp)</code>.</p>
<p>How about <code>gcc-15</code>?</p>
<pre><code>$ gcc a.c -o a -O2 &amp;&amp; ./a
v.s:
  .fs[3] = 0x000043</code></pre>
<p>Whoops. That that is clearly uninitialized value left after <code>use_stack()</code>
execution. <code>valigrind</code> is also not happy about it:</p>
<pre><code>$ valgrind --quiet --track-origins=yes ./a
v.s:
Use of uninitialised value of size 8
   at 0x48B954A: _itoa_word (in ...-glibc-2.40-36/lib/libc.so.6)
   by 0x48C43EB: __printf_buffer (in ...-glibc-2.40-36/lib/libc.so.6)
   by 0x48C6300: __vfprintf_internal (in ...-glibc-2.40-36/lib/libc.so.6)
   by 0x48BA71E: printf (in ...-glibc-2.40-36/lib/libc.so.6)
   by 0x401074: main (a.c:20)
 Uninitialised value was created by a stack allocation
   at 0x401190: do_it (a.c:12)</code></pre>
<p>Disassembly:</p>
<pre><code>; $ objdump --no-addresses --no-show-raw-insn -d a
&lt;use_stack&gt;:
        movabs $0x4100000040,%rax ; load 64-bit part 1
        movabs $0x4300000042,%rdx ; load 64-bit part 2
        mov    %rax,-0x18(%rsp)   ; store part 1 on stack
        mov    %rdx,-0x10(%rsp)   ; store part 2 on stack
        ret
        nop

&lt;do_it&gt;:
        movl   $0x0,-0x18(%rsp)   ; zero-initialize first 32 bits of a union
        mov    -0xc(%rsp),%eax    ; read uninitialized 32-bit value at 12-byte
                                  ; offset from a union start
        ret</code></pre>
<p><code>gcc-15</code> implements <code>v = { 0 }</code> as a single 32-bit store as if it was
<code>v.dummy = 0;</code> and leaves the rest of the union intact.</p>
<p>Is it a bug?</p>
<p><code>gcc-15</code> intentionally changed the zeroing behaviour to do less in
<a href="https://gcc.gnu.org/PR116416"><code>PR116416</code></a> with
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=0547dbb725b6d8e878a79e28a2e171eafcfbc1aa">this commit</a>
to generate more optimal code.</p>
<p>Fun fact: the patch also adds a <code>-fzero-init-padding-bits=unions</code>
option to enable the old behaviour.</p>
<h2 id="the-real-bug">the real bug</h2>
<p>The above example might sound theoretical, but I extracted it from an
<code>mbedtls</code> test suite failure. After a recent <code>gcc-15</code> update the tests
are now failing as:</p>
<pre><code>The following tests FAILED:
        91 - psa_crypto-suite (Failed)
       113 - psa_crypto_storage_format.v0-suite (Failed)</code></pre>
<p>I initially thought it’s a compiler bug related to arithmetics. But
exploring the failing test I found the following pattern:</p>
<pre class="c"><code>// at tests/src/psa_exercise_key.c:
  psa_mac_operation_t operation = PSA_MAC_OPERATION_INIT;

// library/psa_crypto.c:

  if (operation.hash_ctx.id != 0) { return error; }
  //...

// include/psa/crypto_struct.h:
  #define PSA_MAC_OPERATION_INIT { 0, 0, 0, { 0 } }

// include/psa/crypto.h:
  typedef struct psa_mac_operation_s psa_mac_operation_t;

// include/psa/crypto_struct.h:
  struct psa_mac_operation_s {
    unsigned int id;
    uint8_t mac_size;
    unsigned int is_sign : 1;
    psa_driver_mac_context_t ctx;
  };

// include/psa/crypto_driver_contexts_composites.h:
  typedef union {
    unsigned dummy; /* Make sure this union is always non-empty */
    mbedtls_psa_mac_operation_t mbedtls_ctx;
  } psa_driver_mac_context_t;

// include/psa/crypto_builtin_composites.h:
  typedef struct {
    psa_algorithm_t alg;
    union {
        unsigned dummy; /* Make the union non-empty even with no supported algorithms. */
        mbedtls_psa_hmac_operation_t hmac;
        mbedtls_cipher_context_t cmac;
    } ctx;
  } mbedtls_psa_mac_operation_t;

// include/psa/crypto_builtin_composites.h
  typedef struct {
    /** The HMAC algorithm in use */
    psa_algorithm_t alg;
    /** The hash context. */
    struct psa_hash_operation_s hash_ctx;
    /** The HMAC part of the context. */
    uint8_t opad[PSA_HMAC_MAX_HASH_BLOCK_SIZE];
  } mbedtls_psa_hmac_operation_t;

// include/psa/crypto_types.h
  typedef uint32_t psa_algorithm_t;

// include/psa/crypto_struct.h
  struct psa_hash_operation_s {
    /** Unique ID indicating which driver got assigned to do the
     * operation. Since driver contexts are driver-specific, swapping
     * drivers halfway through the operation is not supported.
     * ID values are auto-generated in psa_driver_wrappers.h.
     * ID value zero means the context is not valid or not assigned to
     * any driver (i.e. the driver context is not active, in use). */
    unsigned int id;
    psa_driver_hash_context_t ctx;
  };</code></pre>
<p>It’s quite a bit of indirection, but if we compress it into a single
<code>struct</code> definition and remove irrelevant bits we will get something
like that:</p>
<pre class="c"><code>  struct {
    unsigned int id; // initialized below
    uint8_t mac_size; // initialized below
    unsigned int is_sign : 1; // initialized below
    union {
      unsigned dummy; // initialized below
      struct {
        uint32_t alg; // initialized below, alias of `dummy`

        // anything below is NOT initialized

        union {
          unsigned dummy;
          struct {
              uint32_t alg;
              struct {
                  unsigned int id; // &lt;- we are about to use this field
                  psa_driver_hash_context_t ctx;
              } hash_ctx;
              uint8_t opad[PSA_HMAC_MAX_HASH_BLOCK_SIZE];
          } hmac;
          // ..
       } mbedtls_ctx;
    } ctx;
  } operation = {
    0, // id
    0, // mac_size
    0, // is_sign
    { 0 } // ctx.dummy
  };

  if (operation.hash_ctx.id != 0) { return error; }</code></pre>
<p><code>valgrind</code> complains about the use of an uninitialized value as:</p>
<pre><code>$ valgrind --track-origins=yes --trace-children=yes --num-callers=50 --track-fds=yes --leak-check=full --show-reachable=yes --malloc-fill=0xE1 --free-fill=0xF1 tests/test_suite_psa_crypto
...
==2758824== Conditional jump or move depends on uninitialised value(s)
==2758824==    at 0x483C6B: psa_hash_setup (psa_crypto.c:2298)
==2758824==    by 0x490ADA: psa_hmac_setup_internal (psa_crypto_mac.c:90)
==2758824==    by 0x490ADA: psa_mac_setup (psa_crypto_mac.c:299)
==2758824==    by 0x48412C: psa_driver_wrapper_mac_sign_setup (psa_crypto_driver_wrappers.h:2297)
==2758824==    by 0x48412C: psa_mac_setup (psa_crypto.c:2619)
==2758824==    by 0x4083BC: test_mac_key_policy (test_suite_psa_crypto.function:2192)
==2758824==    by 0x408877: test_mac_key_policy_wrapper (test_suite_psa_crypto.function:2264)
==2758824==    by 0x429F4E: dispatch_test (main_test.function:170)
==2758824==    by 0x42A813: execute_tests (host_test.function:676)
==2758824==    by 0x40247A: main (main_test.function:263)
==2758824==  Uninitialised value was created by a stack allocation
==2758824==    at 0x40822C: test_mac_key_policy (test_suite_psa_crypto.function:2167)</code></pre>
<p>Unfortunately I don’t think there is a simple fix for that (apart from
enabling new <code>-fzero-init-padding-bits=unions</code> compiler flag if it’s
supported.</p>
<p>I filed the issue upstream as
<a href="https://github.com/Mbed-TLS/mbedtls/issues/9814">Issue #9814</a> hoping to
get some guidance.</p>
<h2 id="parting-words">parting words</h2>
<p><code>gcc-15</code> will be more efficient at handling partial union initialization.</p>
<p>It will likely be at expense of exposing real code bugs like the
<a href="https://github.com/Mbed-TLS/mbedtls/issues/9814"><code>mbedtls</code></a> one to the
users. It’s a bit scary to discover it in security library first.</p>
<p>At least <code>valgrind</code> is able to detect trivial cases of uninitialized
use of partially initialized unions.</p>
<p><code>gcc-15</code> also provides <code>-fzero-init-padding-bits=unions</code> to flip the old
behaviour back on. This will allow nailing down bugs using a single
compiler version instead of comparing to <code>gcc-14</code>.</p>
<p>I suspect <code>gcc</code> historically zero-initialized the whole enums to be
closer to incomplete <code>struct</code> initialization
<a href="https://en.cppreference.com/w/c/language/struct_initialization">rule</a>.
But now it causes performance problems if the union branches are
different in size.</p>
<p>I suspect we’ll see a few more projects affected by this change.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 01 Dec 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/328-c-union-init-and-gcc-15.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>ski 1.5.0 is out</title>
    <link>https://trofi.github.io/posts/327-ski-1.5.0-is-out.html</link>
    <description><![CDATA[<p>TL;DR: <a href="https://github.com/trofi/ski/releases/tag/v1.5.0"><code>ski-1.5.0</code></a> is
available for download!</p>
<p>It’s primarily a maintenance release that completely removes <code>motif</code> and
<code>gtk</code> backends, fixes building against <code>C23</code> toolchains and adds a small
<code>-initramfs</code> option to supply separate initramfs file to be used along
with emulated kernel.</p>
<p><a href="https://trofi.github.io/posts/255-ski-1.4.0-is-out.html"><code>1.4.0</code></a> announcement has a few hints
on how to run it.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 23 Nov 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/327-ski-1.5.0-is-out.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc-15 switched to C23</title>
    <link>https://trofi.github.io/posts/326-gcc-15-switched-to-c23.html</link>
    <description><![CDATA[<h2 id="tldr">Tl;DR</h2>
<p>In November <code>gcc</code>
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=55e3bd376b2214e200fa76d12b67ff259b06c212">merged</a>
the switch from <code>C17</code> (<code>-std=gnu17</code>) to <code>C23</code> (<code>-std=c23</code>) language
standard used by default for <code>C</code> code.</p>
<p>This will cause quite a few build breakages in projects written in
C. A few example fixes:</p>
<ul>
<li><a href="https://github.com/libffi/libffi/pull/861/files"><code>libffi</code></a>: optional
<code>va_start</code> parameter.</li>
<li><a href="https://github.com/vapier/ncompress/pull/40/files"><code>ncompress</code></a>:
<code>void foo()</code> changed the meaning to <code>void foo(void)</code>.</li>
<li><a href="https://lore.kernel.org/ell/20241117001814.2149181-1-slyich@gmail.com/T/#t"><code>ell</code></a>
<code>bool</code>, <code>true</code> and <code>false</code> are new keywords. And specifically <code>false</code>
is not equals to <code>0</code> or <code>NULL</code>.</li>
</ul>
<h2 id="more-words">more words</h2>
<p><code>C23</code> has a few high-visibility breaking changes compared to <code>C17</code>.</p>
<h3 id="bool-true-and-false-are-unconditionally-predefined"><code>bool</code>, <code>true</code>, and <code>false</code> are unconditionally predefined</h3>
<p><code>true</code> and <code>false</code> are now predefined constants (instead of being a
part of <code>&lt;stdbool.h&gt;</code> macros and <code>typedef</code>s). Thus code like below does
not compile any more:</p>
<pre class="c"><code>enum { false = 0; }
typedef int bool;</code></pre>
<p>Error messages:</p>
<pre><code>$ printf 'enum { false = 0 };' | gcc -std=c17 -c -x c -
$ printf 'enum { false = 0 };' | gcc -c -x c -
&lt;stdin&gt;:1:8: error: expected identifier before 'false'

$ printf 'typedef int bool;' | gcc -std=c17 -c -x c -
$ printf 'typedef int bool;' | gcc -c -x c -
&lt;stdin&gt;:1:13: error: two or more data types in declaration specifiers
&lt;stdin&gt;:1:1: warning: useless type name in empty declaration</code></pre>
<p>The fix is usually to use <code>&lt;stdbool.h&gt;</code> or avoid name collisions.</p>
<p>Example affected project is <code>linux</code>.</p>
<h3 id="partially-defined-int-function-prototypes-are-just-int-void-now">partially defined <code>int (*)()</code> function prototypes are just <code>int (*)(void)</code> now</h3>
<p>This one is trickier to fix when intentionally used. <code>C</code> happened to
allow the following code:</p>
<pre class="c"><code>// $ cat a.c
typedef void (*PF)();

static int f0(void)  { return 42; }
static int f1(int a) { return 42 + a; }

int main() {
    PF pf;

    // 0-argument function pointer
    pf = f0;
    pf();

    // 1-argument function pointer
    pf = f1;
    pf(42);

    // 3-argument function pointer: an odd one, but happens to work
    pf(42,42,42);
}</code></pre>
<p>But not any more:</p>
<pre><code>$ gcc -std=c17 -c a.c
$ gcc -c a.c
a.c: In function 'main':
a.c:15:8: error: assignment to 'PF' {aka 'int (*)(void)'} from incompatible pointer type 'int (*)(int)' [-Wincompatible-pointer-types]
   15 |     pf = f1;
      |        ^
a.c:16:5: error: too many arguments to function 'pf'
   16 |     pf(42);
      |     ^~
a.c:19:5: error: too many arguments to function 'pf'
   19 |     pf(42,42,42);
      |     ^~</code></pre>
<p>This hack is used at least in <code>ski</code>, <code>ghc</code> and <code>ncompress</code>. But more
frequently it’s use is an accident (<code>ell</code>, <code>iwd</code>, <code>bash</code> and a few others).</p>
<h2 id="parting-words">parting words</h2>
<p>Quick quiz: the above changes look like they tickle some very obscure
case. How many packages are affected on a typical desktop system? What
would be your guess? 1? 5? 100? 1000?</p>
<p>So far on my system (~2000 installed packages) I observed the failures
of the following projects:</p>
<ul>
<li><code>linux</code></li>
<li><code>speechd</code></li>
<li><code>vde2</code></li>
<li><code>sane-backends</code></li>
<li><code>timidity</code></li>
<li><code>neovim</code></li>
<li><code>bluez</code></li>
<li><code>samba</code></li>
<li><code>weechat</code></li>
<li><code>iwd</code></li>
<li><code>protobuf</code></li>
<li><code>netpbm</code></li>
<li><code>mariadb-connector-c</code></li>
<li><code>liblqr1</code></li>
<li><code>sqlite-odbc-driver</code></li>
<li><code>python:typed-ast</code></li>
<li><code>python2</code></li>
<li><code>perl:XS-Parse-Keyword</code></li>
<li><code>pgpdump</code></li>
<li><code>ell</code></li>
<li><code>SDL-1</code></li>
<li><code>ruby-3.1</code></li>
<li><code>dnsmasq</code></li>
<li><code>ghc</code></li>
<li><code>gnupg</code></li>
<li><code>ghostscript</code></li>
<li><code>procmail</code></li>
<li><code>jq</code></li>
<li><code>libsndfile</code></li>
<li><code>ppp</code></li>
<li><code>time</code></li>
<li><code>postfi</code>x</li>
<li><code>mcpp</code></li>
<li><code>xmlrpc-c</code></li>
<li><code>unifdef</code></li>
<li><code>hotdoc</code></li>
<li><code>mypy</code></li>
<li><code>rustc</code></li>
<li><code>xorg:libXt</code></li>
<li><code>rsync</code></li>
<li><code>oniguruma</code></li>
<li><code>ltrace</code></li>
<li><code>sudo</code></li>
<li><code>lsof</code></li>
<li><code>lv</code></li>
<li><code>dbus-glib</code></li>
<li><code>argyllcms</code></li>
<li><code>valgrind</code></li>
<li><code>postgresql-14</code></li>
<li><code>gdb</code></li>
<li><code>git</code></li>
<li><code>ncompress</code></li>
<li><code>w3m</code></li>
<li><code>freeglut</code></li>
<li><code>xcur2png</code></li>
<li><code>vifm</code></li>
<li><code>p11-kit</code></li>
<li><code>cyrus-sasl</code></li>
<li><code>xvidcore</code></li>
<li><code>guile</code></li>
<li><code>editline</code></li>
<li><code>e2fsprogs</code></li>
<li><code>gsm</code></li>
<li><code>libconfig</code></li>
<li><code>db</code></li>
<li><code>libtirpc</code></li>
<li><code>nghttp2</code></li>
<li><code>libkrb5</code></li>
<li><code>libgpg-error</code></li>
<li><code>cpio</code></li>
<li><code>sharutils</code></li>
<li><code>gpm</code></li>
<li><code>expect</code></li>
<li><code>ncurses</code></li>
<li><code>yasm</code></li>
<li><code>texinfo-6.7</code></li>
<li><code>gettext</code></li>
<li><code>unzip</code></li>
<li><code>gdbm</code></li>
<li><code>m4</code></li>
<li><code>binutils</code></li>
<li><code>ed</code></li>
<li><code>gmp</code></li>
<li><code>bash</code></li>
</ul>
<p>That’s more than 80 packages, or about 4% of all the packages I have.</p>
<p>Looks like <code>gcc-15</code> will be a disruptive release (just like <code>gcc-14</code>)
that will require quite a few projects to adapt to new requirements
(either by fixing code or by slapping <code>-std=gnu17</code> as a requirement).</p>
<p>Most of the breakages above are not yet fixed upstream. These can be
good first contribution fixes if you are thinking of making one.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 17 Nov 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/326-gcc-15-switched-to-c23.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>Zero Hydra Failures towards 24.11 NixOS release</title>
    <link>https://trofi.github.io/posts/325-Zero-Hydra-Failures-towards-24.11-NixOS-release.html</link>
    <description><![CDATA[<p><code>ZHF</code> (or Zero Hydra Failures) is the time when most build failures are
squashed before final <code>NixOS-24.11</code> release
(see <a href="https://github.com/NixOS/nixpkgs/issues/352882">full release schedule</a>).</p>
<p>To follow the tradition let’s fix one bug for <code>ZHF</code>.</p>
<p>I picked <a href="https://hydra.nixos.org/build/276690936"><code>xorg.libAppleWM</code></a> build
failure. It’s not a very popular package.</p>
<p>The failure looks trivial:</p>
<pre><code>make[2]: Entering directory '/build/libapplewm-be972ebc3a97292e7d2b2350eff55ae12df99a42/src'
  CC       applewm.lo
gcc: error: unrecognized command-line option '-iframeworkwithsysroot'</code></pre>
<p>The build was happening for <code>x86_64-linux</code> target. While this package
is <code>MacOS</code>-specific: it uses Darwin APIs and links to it’s libraries
directly. No reason to try to build it on <code>x86_64-linux</code>.</p>
<p>The fix is to constrain the package to <code>darwin</code> targets (the default
platforms for <code>xorg</code> packages is <code>unix</code>):</p>
<pre class="diff"><code>--- a/pkgs/servers/x11/xorg/overrides.nix
+++ b/pkgs/servers/x11/xorg/overrides.nix
@@ -171,6 +171,9 @@ self: super:
   libAppleWM = super.libAppleWM.overrideAttrs (attrs: {
     nativeBuildInputs = attrs.nativeBuildInputs ++ [ autoreconfHook ];
     buildInputs =  attrs.buildInputs ++ [ xorg.utilmacros ];
+    meta = attrs.meta // {
+      platforms = lib.platforms.darwin;
+    };
   });

   libXau = super.libXau.overrideAttrs (attrs: {</code></pre>
<p>This fix is now known as
<a href="https://github.com/NixOS/nixpkgs/pull/353618">PR#353618</a>.</p>
<h2 id="parting-words">Parting words</h2>
<p>I picked very lazy example of a broken package.
<a href="https://github.com/NixOS/nixpkgs/issues/352882" class="uri">https://github.com/NixOS/nixpkgs/issues/352882</a> contains more links and
hints on how to find and fix known breakages.</p>
<p>As usual contributing towards <code>ZHF</code> is very easy. Give it a try!</p>
<p>Have fun!</p>]]></description>
    <pubDate>Mon, 04 Nov 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/325-Zero-Hydra-Failures-towards-24.11-NixOS-release.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>xmms2 0.9.4 is out</title>
    <link>https://trofi.github.io/posts/324-xmms2-0.9.4-is-out.html</link>
    <description><![CDATA[<p>Tl;DR: <code>xmms2-0.9.4</code> is out and you can get it at
<a href="https://github.com/xmms2/xmms2-devel/releases/tag/0.9.4" class="uri">https://github.com/xmms2/xmms2-devel/releases/tag/0.9.4</a>!</p>
<p><a href="https://github.com/xmms2"><code>xmms2</code></a> is still a music player
daemon with various plugins to support stream decoding and
transformation. See
<a href="https://trofi.github.io/posts/244-xmms2-0.9.1-is-out.html">older announcement</a> on how to
get started with <code>xmms2</code>.</p>
<h2 id="highlights">Highlights</h2>
<p>It’s a small maintenance release. The only notable change is support for
<code>ffmpeg-7</code> as a build dependency.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Mon, 07 Oct 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/324-xmms2-0.9.4-is-out.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc-15 bugs, pile 1</title>
    <link>https://trofi.github.io/posts/323-gcc-15-bugs-pile-1.html</link>
    <description><![CDATA[<p>About 4 months have passed since <code>gcc-14.1.0</code> release. Around the same
time <code>gcc-15</code> development has started and a few major changes were
merged into the <code>master</code> development branch.</p>
<h2 id="summary">summary</h2>
<p>This time I waited to collect about 20 bug reports I encountered:</p>
<ul>
<li><a href="https://gcc.gnu.org/PR114933">c++/114933</a>: <code>mcfgthread-1.6.1</code>
typecheck failure. Ended up being <code>mcfgthread</code> bug caused by stronger
<code>gcc</code> checks.</li>
<li><a href="https://gcc.gnu.org/PR114872">tree-optimization/114872</a>: <code>sagemath</code>
<code>SIGSEGV</code>ed due to broken assumptions around <code>setjmp()</code> / <code>longjmp()</code>.
Not a <code>gcc</code>bug either.</li>
<li><a href="https://gcc.gnu.org/PR115115">target/115115</a>: <code>highway-1.0.7</code> test
suite expected too specific <code>_mm_cvttps_epi32()</code> semantics. A <code>gcc-12</code>
regression!</li>
<li><a href="https://gcc.gnu.org/PR115146">target/115146</a>: <code>highway-1.0.7</code> test
suite exposed <code>gcc-15</code> bug in vectoring <code>bswap16()</code>-like code.</li>
<li><a href="https://gcc.gnu.org/PR115227">tree-optimization/115227</a>: <code>libepoxy</code>,
<code>p11-kit</code> and <code>doxygen</code> can’t fit in RAM of 32-bit <code>gcc</code> due to memory
leak in value range propagation subsystem.</li>
<li><a href="https://gcc.gnu.org/PR115397">target/115397</a>: <code>numpy</code> ICE for <code>-m32</code>:
<code>gcc</code> code generator generated a constant pool memory reference and
crashed in instruction selection.</li>
<li><a href="https://gcc.gnu.org/PR115403">c++/115403</a>: <code>highway</code> build failure
due to wrong scope handling of <code>#pragma GCC target</code> by <code>gcc</code>.</li>
<li><a href="https://gcc.gnu.org/PR115602">tree-optimization/115602</a>:
<code>liblapack-3.12.0</code> ICE in <code>slp</code> pass. <code>gcc</code> generated a self-reference
cycle after applying code subexpression elimination.</li>
<li><a href="https://gcc.gnu.org/PR115655">bootstrap/115655</a>: <code>gcc</code> bootstrap
failure on <code>-Werror=unused-function</code>.</li>
<li><a href="https://gcc.gnu.org/PR115797">libstdc++/115797</a>: <code>gcc</code> failed to
compile <code>extern "C" { #include &lt;math.h&gt; }</code> code. <code>&lt;math.h&gt;</code> was fixed
to survive such imports.</li>
<li><a href="https://gcc.gnu.org/PR115863">middle-end/115863</a>: wrong code on
<code>zlib</code> when handling saturated logic. A bug in truncation handling.</li>
<li><a href="https://gcc.gnu.org/PR115916">rtl-optimization/115916</a>: wrong code on
<code>highway</code>. Bad arithmetic shift <code>ubsan</code>-related fix in <code>gcc</code>’s own code.</li>
<li><a href="https://gcc.gnu.org/PR115961">middle-end/115961</a>: wrong code on <code>llvm</code>,
bad bitfield truncation handling for sub-byte bitfield sizes. Saturated
truncation arithmetics handling was applied too broadly.</li>
<li><a href="https://gcc.gnu.org/PR115991">tree-optimization/115991</a>: ICE on
<code>linux-6.10</code>. Caused by too broad acceptance of sub-register use in an
instruction. ENded up selecting invalid instructions.</li>
<li><a href="https://gcc.gnu.org/PR116037">rtl-optimization/116037</a>: <code>python3</code>
hangup due to an <code>-fext-dce</code> bug.</li>
<li><a href="https://gcc.gnu.org/PR116200">rtl-optimization/116200</a>: crash during
<code>gcc</code> bootstrap, wrong code on <code>libgcrypt</code>. A bug in RTL constant pool
handling.</li>
<li><a href="https://gcc.gnu.org/PR116353">rtl-optimization/116353</a>: ICE on
<code>glibc-2.39</code>. Another RTL bug where <code>gcc</code> instruction selector was
presented with invalid value reference.</li>
<li><a href="https://gcc.gnu.org/PR116411">middle-end/116411</a>: ICE on
<code>readline-8.2p13</code>. Conditional operation was incorrectly optimized for
some of builtin functions used in branches.</li>
<li><a href="https://gcc.gnu.org/PR116412">tree-optimization/116412</a>: ICE on
<code>openblas-0.3.28</code>. Similar to the above: conditional operation was
incorrectly optimized for complex types.</li>
</ul>
<h2 id="fun-bug">fun bug</h2>
<p>The <a href="https://gcc.gnu.org/PR115863"><code>zlib</code> bug</a> is probably the most
unusual one. Due to a typo in newly introduced set of optimizations
<code>gcc</code> managed to convert <code>a &gt; b ? b : a</code> type of expressions into an
equivalent of <code>b &gt; a ? b : a</code>. But it only does it for <code>b = INT_MAX</code>
type of arguments (case of saturation).</p>
<p>As a result it only broke <code>zlib</code> test suite as it specifically tests for
out of range access to cause <code>SIGSEGV</code>s. For well-behaved inputs it never
caused any problems. The <code>gcc</code> fix
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=aae535f3a870659d1f002f82bd585de0bcec7905">was trivial</a>:</p>
<pre class="diff"><code>--- a/gcc/config/i386/i386.md
+++ b/gcc/config/i386/i386.md
@@ -9990,7 +9990,7 @@
   rtx sat = force_reg (DImode, GEN_INT (GET_MODE_MASK (&lt;MODE&gt;mode)));
   rtx dst;

-  emit_insn (gen_cmpdi_1 (op1, sat));
+  emit_insn (gen_cmpdi_1 (sat, op1));

   if (TARGET_CMOVE)
     {
@@ -10026,7 +10026,7 @@
   rtx sat = force_reg (SImode, GEN_INT (GET_MODE_MASK (&lt;MODE&gt;mode)));
   rtx dst;

-  emit_insn (gen_cmpsi_1 (op1, sat));
+  emit_insn (gen_cmpsi_1 (sat, op1));

   if (TARGET_CMOVE)
     {
@@ -10062,7 +10062,7 @@
   rtx sat = force_reg (HImode, GEN_INT (GET_MODE_MASK (QImode)));
   rtx dst;

-  emit_insn (gen_cmphi_1 (op1, sat));
+  emit_insn (gen_cmphi_1 (sat, op1));

   if (TARGET_CMOVE)
     {</code></pre>
<p>We swap argument order to restore original intent.</p>
<h2 id="histograms">histograms</h2>
<p>Where did most <code>gcc</code> bugs come from?</p>
<ul>
<li><code>tree-optimization</code>: 4</li>
<li><code>rtl-optimization</code>: 4</li>
<li><code>middle-end</code>: 3</li>
<li><code>target</code>: 3</li>
<li><code>c++</code>: 1</li>
<li><code>bootstrap</code>: 1</li>
<li><code>libstdc++</code>: 1</li>
</ul>
<p>As usual <code>tree-optimization</code> is at the top of subsystem causing troubles.
But this time <code>rtl-optimization</code> got close to it as well.</p>
<p><code>highway</code> managed to yield us 4 new bugs while <code>llvm</code> got us just one
new bug.</p>
<h2 id="parting-words">parting words</h2>
<p><code>gcc-15</code> got a few very nice optimizations (and bugs) related to
saturated truncation, zero/sign-extension elimination, constant folding
in RTL.</p>
<p>I saw at least 5 bugs related to wrong code generation (and
also slowly reducing another one in the background). <code>middl-end</code> ones
were easy to reduce and explore, <code>RTL</code> ones were very elusive.</p>
<p>The most disruptive change is probably a removal of <code>#include &lt;cstdint&gt;</code>
from one of <code>libstdc++</code> headers. That requires quite a few upstream
fixes to add missing headers (<a href="https://github.com/google/cppdap/pull/133">cppdap</a>,
<a href="https://github.com/google/woff2/pull/176">woff2</a>,
<a href="https://github.com/silnrsi/graphite/pull/91">graphite</a>,
<a href="https://github.com/KhronosGroup/glslang/pull/3684">glslang</a>,
<a href="https://github.com/widelands/widelands/pull/6522">widelands</a>,
<a href="https://github.com/wesnoth/wesnoth/pull/9250">wesnoth</a> and many others).</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 25 Aug 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/323-gcc-15-bugs-pile-1.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc-15 template checking improvements</title>
    <link>https://trofi.github.io/posts/322-gcc-15-template-checking-improvements.html</link>
    <description><![CDATA[<h2 id="tldr">Tl;DR</h2>
<p>On 18 Jul <code>gcc</code>
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=313afcfdabeab3e6705ac0bd1273627075be0023">merged</a>
extended correctness checks for template functions. This will cause some
incorrect unused code to fail to compile. Consider fixing or deleting
the code. I saw at least two projects affected by it:</p>
<ul>
<li><a href="https://github.com/GNUAspell/aspell/pull/650"><code>aspell</code></a></li>
<li><a href="https://sourceforge.net/p/mjpeg/patches/63/"><code>mjpegtools</code></a></li>
</ul>
<h2 id="more-words">more words</h2>
<p><code>c++</code> is a complex language with a type system that does static checking.
Most of the time checking the type correctness is easy by both human and
the compiler. But sometimes it’s less trivial. Namespaces and function
arguments can bring various declarations into the scope. Template code
splits a single definition point into two: template definition point
and template instantiation.</p>
<p>Let’s look at a simple example:</p>
<pre class="cpp"><code>template &lt;typename T&gt; struct S {
    int foo(void) { return bar(); }
};

int bar() { return 42; }

int main() {
    S&lt;int&gt; v;
    return v.foo();
}</code></pre>
<p>This fails to build on all recent <code>gcc</code> as:</p>
<pre><code>$ g++ -c a.cc
a.cc: In member function 'int S&lt;T&gt;::foo()':
a.cc:2:28: error: there are no arguments to 'bar' that depend on a
  template parameter, so a declaration of 'bar' must be available [-fpermissive]
    2 |     int foo(void) { return bar(); }
      |                            ^~~
a.cc:2:28: note: (if you use '-fpermissive', G++ will accept your code,
  but allowing the use of an undeclared name is deprecated)</code></pre>
<p><code>gcc</code> really wants <code>bar</code> to be visible at the template instantiation
time. But what is we don’t call <code>foo</code> at all?</p>
<pre class="cpp"><code>template &lt;typename T&gt; struct S {
    int foo(void) { return bar(); }
};

int main() {}</code></pre>
<p>Still fails the same:</p>
<pre><code>$ g++ -c a.cc
a.cc: In member function 'int S&lt;T&gt;::foo()':
a.cc:2:28: error: there are no arguments to 'bar' that depend on a
  template parameter, so a declaration of 'bar' must be available [-fpermissive]
    2 |     int foo(void) { return bar(); }
      |                            ^~~
a.cc:2:28: note: (if you use '-fpermissive', G++ will accept your code,
  but allowing the use of an undeclared name is deprecated)</code></pre>
<p>That is neat: even if you never try to instantiate a function <code>gcc</code>
still tries to do basic checks on it.</p>
<p>But what if we call <code>foo()</code> via <code>this</code> pointer explicitly?</p>
<pre class="cpp"><code>template &lt;typename T&gt; struct S {
    int foo(void) { return this-&gt;bar(); }
};

int main() {}</code></pre>
<p>Is it valid <code>c++</code>?</p>
<p><code>gcc-14</code> says it’s fine:</p>
<pre><code>$ g++-14 -c a.cc
&lt;ok&gt;</code></pre>
<p>Is there a way to somehow make <code>bar()</code> available via <code>this</code>? Maybe, via
inheritance? Apparently, no. <code>gcc-15</code> now flags the code above as
unconditionally invalid:</p>
<pre><code>$ g++-15 -c a.cc
a.cc: In member function 'int S&lt;T&gt;::foo()':
a.cc:2:34: error: 'struct S&lt;T&gt;' has no member named 'bar'
    2 |     int foo(void) { return this-&gt;bar(); }
      |                                  ^~~</code></pre>
<p>To get it to work you need something like a
<a href="https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern#Static_polymorphism"><code>CRTP</code></a>
pattern:</p>
<pre class="cpp"><code>// Assume Derived::bar() will be provided.
template &lt;typename Derived&gt; struct S {
    int foo(void) { return static_cast&lt;Derived*&gt;(this)-&gt;bar(); }
};

int main() {}</code></pre>
<p>Interestingly the above problem pops up time to time in real projects in
template code that was not tried after refactors. One such example is an
<a href="https://github.com/GNUAspell/aspell/pull/650"><code>aspell</code> bug</a>:</p>
<pre class="cpp"><code>  template&lt;class Parms&gt;
  void VectorHashTable&lt;Parms&gt;::recalc_size() {
    size_ = 0;
    for (iterator i = begin(); i != this-&gt;e; ++i, ++this-&gt;_size);
  }</code></pre>
<p><code>gcc-14</code> built it just fine. <code>gcc-15</code> started rejecting the build as:</p>
<pre><code>In file included from modules/speller/default/readonly_ws.cpp:51:
modules/speller/default/vector_hash-t.hpp:
  In member function 'void aspeller::VectorHashTable&lt;Parms&gt;::recalc_size()':
modules/speller/default/vector_hash-t.hpp:186:43:
  error: 'class aspeller::VectorHashTable&lt;Parms&gt;' has no member named 'e'
  186 |     for (iterator i = begin(); i != this-&gt;e; ++i, ++this-&gt;_size);
      |                                           ^
modules/speller/default/vector_hash-t.hpp:186:59:
  error: 'class aspeller::VectorHashTable&lt;Parms&gt;' has no member named '_size'; did you mean 'size'?
  186 |     for (iterator i = begin(); i != this-&gt;e; ++i, ++this-&gt;_size);
      |                                                           ^~~~~
      |                                                           size</code></pre>
<p><code>VectorHashTable</code> does not contain <code>_size</code> field, but it does contain
<code>size_</code> (used just a line before). <code>e</code> field is not a thing either.</p>
<p>The change is simple:</p>
<pre class="diff"><code>--- a/modules/speller/default/vector_hash-t.hpp
+++ b/modules/speller/default/vector_hash-t.hpp
@@ -183,7 +183,7 @@ namespace aspeller {
   template&lt;class Parms&gt;
   void VectorHashTable&lt;Parms&gt;::recalc_size() {
     size_ = 0;
-    for (iterator i = begin(); i != this-&gt;e; ++i, ++this-&gt;_size);
+    for (iterator i = begin(), e = end(); i != e; ++i, ++size_);
   }

 }</code></pre>
<p>Or you could also delete the function if it was broken like that for a
while.</p>
<p>Another example is <a href="https://sourceforge.net/p/mjpeg/patches/63/"><code>mjpegtools</code> bug</a>:</p>
<pre class="cpp"><code>// The commented-out method prototypes are methods to be implemented by
// subclasses.  Not all methods have to be implemented, depending on
// whether it's appropriate for the subclass, but that may impact how
// widely the subclass may be used.
template &lt;class INDEX, class SIZE&gt;
class Region2D
{
  public:
    // ...

    template &lt;class REGION, class REGION_O, class REGION_TEMP&gt;
    void UnionDebug (Status_t &amp;a_reStatus,
        REGION_O &amp;a_rOther, REGION_TEMP &amp;a_rTemp);

    // bool DoesContainPoint (INDEX a_tnY, INDEX a_tnX);

    // ...
}

template &lt;class INDEX, class SIZE&gt;
template &lt;class REGION, class REGION_TEMP&gt;
void
Region2D&lt;INDEX,SIZE&gt;::UnionDebug (Status_t &amp;a_reStatus, INDEX a_tnY,
    INDEX a_tnXStart, INDEX a_tnXEnd, REGION_TEMP &amp;a_rTemp)
{
    // ...
            if (!((rHere.m_tnY == a_tnY
                &amp;&amp; (tnX &gt;= a_tnXStart &amp;&amp; tnX &lt; a_tnXEnd))
            || this-&gt;DoesContainPoint (rHere.m_tnY, tnX)))
                goto error;
    // ...
}</code></pre>
<p>Here <code>mjpegtools</code> assumes that <code>DoesContainPoint</code> should come from
derived type. But modern <code>c++</code> just does allow it to be defined like that:</p>
<pre><code>In file included from SetRegion2D.hh:12,
                 from MotionSearcher.hh:15,
                 from newdenoise.cc:19:
Region2D.hh: In member function 'void Region2D&lt;INDEX, SIZE&gt;::UnionDebug(Status_t&amp;, INDEX, INDEX, INDEX, REGION_TEMP&amp;)':
Region2D.hh:439:34: error: 'class Region2D&lt;INDEX, SIZE&gt;' has no member named 'DoesContainPoint'
  439 |                         || this-&gt;DoesContainPoint (rHere.m_tnY, tnX)))
      |                                  ^~~~~~~~~~~~~~~~</code></pre>
<p>The <a href="https://sourceforge.net/p/mjpeg/Code/3513/">fix</a> just deleted these
unusable functions. An alternative fix would need to look closer to a
<code>CRTP</code> tweak in our contrived example. But it’s a bit more invasive change.</p>
<h2 id="parting-words">parting words</h2>
<p><code>gcc-15</code> will reject more invalid unusable <code>c++</code> code in uninstantiated
templates. The simplest code change might be to just delete broken code.
More involved fix would require some knowledge of the code base to fix
the declaration lookups (or to fix obvious typos).</p>
<p>Have fun!</p>]]></description>
    <pubDate>Mon, 22 Jul 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/322-gcc-15-template-checking-improvements.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>seekwatcher 0.15</title>
    <link>https://trofi.github.io/posts/321-seekwatcher-0.15.html</link>
    <description><![CDATA[<p><a href="https://github.com/trofi/seekwatcher/releases/tag/v0.15"><code>seekwatcher-0.15</code> is here</a>!</p>
<p><code>seekwatcher</code> is a tool to visualise access to the block device.</p>
<p>It’s been 2.5 years since <a href="https://trofi.github.io/posts/234-seekwatcher-0.14.html"><code>seekwatcher-0.14</code> release</a>.
The only change is the switch from <code>mencoder</code> to <code>ffmpeg</code> tool. While at
it default codec is switched from <code>MPEG2</code> to <code>H264</code>.</p>
<p>As usual here is the programs’s result ran against <code>btrfs scrub</code> on my
device:</p>
<pre><code>$ seekwatcher -t scrub.trace -p 'echo 3 &gt; /proc/sys/vm/drop_caches; sync; btrfs scrub start -B /' -d /dev/nvme1n1p2
$ seekwatcher -t scrub.trace -o scrub.mpeg --movie
$ seekwatcher -t scrub.trace -o scrub.png</code></pre>
<p>Outputs:</p>
<ul>
<li><a href="https://trofi.github.io/posts.data/321-seekwatcher/scrub.png">image</a> (127K)</li>
<li><a href="https://trofi.github.io/posts.data/321-seekwatcher/scrub.mpeg">video</a> (926K)</li>
</ul>
<p><code>H264</code> makes video size comparable to the image report.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 07 Jul 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/321-seekwatcher-0.15.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>blog tweaks</title>
    <link>https://trofi.github.io/posts/320-blog-tweaks.html</link>
    <description><![CDATA[<p>Tl;DR:</p>
<p>A few changes happened to this blog in the past few weeks:</p>
<ul>
<li><p><code>RSS</code> feed and web pages no longer embed <code>svg</code> images into <code>&lt;html&gt;</code>
and include them via <code>&lt;img src="..."&gt;</code>.</p>
<p>This fixes <code>RSS</code> readers like <code>miniflux</code> but might break others. At
least now there should be an icon in place of a missing picture
instead of just stripped tags.</p>
<p>As a small bonus <code>RSS</code> feed should not be as large to download.</p></li>
<li><p><code>RSS</code> feed now includes source code snippets without syntax
highlighting.</p>
<p>I never included <code>css</code> style into <code>rss</code> feed. <code>highlighting-kate</code> uses
various tags and decorates them with links heavily. This change fixes
source code rendering in <code>liferea</code>.</p></li>
<li><p><code>RSS</code> feed now embeds <code>https://</code> self-links instead of <code>http://</code>
(except for a few recent entries to avoid breaking reading history).</p></li>
</ul>
<p>More words:</p>
<p>I started this blog in 2010. In 2013 I moved it to
<a href="https://jaspervdj.be/hakyll/"><code>hakyll</code></a> static site generator. The
initial version was just
<a href="https://github.com/trofi/trofi.github.io.gen/blob/7ed816cf5515a47703f8cb2c804244a569bba30f/src/site.hs">88 lines of <code>haskell</code> code</a>.</p>
<p>I did not know much about <code>hakyll</code> back then and I kept it that way for
about 10 years: it just worked for me. The only thing I missed were
tag-based <code>RSS</code> feeds and article breakdown per tag. It prevented the
blog from being added to thematic <code>RSS</code> aggregators like
<a href="https://planet.gentoo.org/"><code>Planet Gentoo</code></a>. But it was not a big deal.
I though I would add it “soon” and never did.</p>
<p>The only “non-trivial” tweaks I did were
<a href="https://trofi.github.io/posts/300-inline-graphviz-dot-in-hakyll.html"><code>dot</code> support</a>
and <a href="https://trofi.github.io/posts/318-inline-gnuplot.html"><code>gunplot</code> support</a>.</p>
<p>Fast forward to 2024 few weeks ago I boasted to my friend how cool my
new <code>gnuplot</code> embeddings are. To what the response was “What pictures?”.
Apparently <code>miniflux</code> does not like <code>&lt;svg&gt;</code> tags embedded into <code>&lt;html&gt;</code>
and strips them away leaving only bits of <code>&lt;title&gt;</code> tags that almost
looks like original <code>graphviz</code> input :)</p>
<p>That meant my cool hack with <code>svg</code> embedding did not quite work for
<code>RSS</code> feed. I moved all the embeddings into separate <code>.svg</code> files with
<a href="https://github.com/trofi/trofi.github.io.gen/commit/12812bab87ce4bdff91227527d543ee3ac2161a9">this change</a>.</p>
<p>It’s not a big change, but it does violate some <code>hakyll</code> assumptions.
Apparently <code>hakyll</code> can output only one destination file for a source
file. For example <code>foo.md</code> can only produce <code>foo.html</code> and not <code>foo.html</code>
plus indefinite amount of pictures. There is a
<a href="https://jaspervdj.be/hakyll/tutorials/06-versions.html">version support</a>
in <code>hakyll</code>, but it assumes that we know number of outputs upfront. It’s
not really usable for cases like <code>N</code> unknown outputs from an input. To
work it around I’m writing all the auxiliary files without the <code>hakyll</code>
dependency tracker knowledge. I do it by defining <code>Writable</code> instance:</p>
<pre class="haskell"><code>data PWI = PWI {
    pandoc :: H.Item String
  , inlines :: [(String, H.Item DBL.ByteString)]
} deriving (GG.Generic)

deriving instance DB.Binary PWI

instance H.Writable PWI where
    write path item = do
        -- emit page itself:
        let PWI pand inls = H.itemBody item
        H.write path pand
        -- emit inlines nearby:
        CM.forM_ inls $ \(fp, contents) -&gt; do
            H.makeDirectories fp
            H.write fp contents</code></pre>
<p>Here <code>inlines</code> is the list of pairs of filenames and their contents to
write on disk and <code>pandoc</code> is the primary content one would normally
write as <code>H.Item String</code>.</p>
<p>While at it I disabled syntax highlighting in <code>RSS</code> feed as <code>liferea</code>
rendered highlighted source as an unreadable mess. And <code>miniflux</code> just
stripped out all the links and styles. <a href="https://github.com/trofi/trofi.github.io.gen/commit/1dc9d5a9d6b54db928f3fdaef1c0dcb4b6d567df">The change</a>
is somewhat long, but it’s gist is a single extra <code>writerHighlightStyle</code>
option passed to <code>pandoc</code> render:</p>
<pre class="haskell"><code>pandocRSSWriterOptions :: TPO.WriterOptions
pandocRSSWriterOptions = pandocWriterOptions{
    -- disable highlighting
    TPO.writerHighlightStyle = Nothing
}</code></pre>
<p>The last thing I changed was to switch from <code>http://</code> links to
<code>https://</code> links by default. In theory it’s a
<a href="https://github.com/trofi/trofi.github.io.gen/commit/cfc80bb575c1b131225c43c1fed47ff639540bd9">one-character change</a>.
In practice that would break unread history for all <code>RSS</code> users. I worked
it around by restoring <code>http://</code> root link for current <code>RSS</code> entries
with <a href="https://github.com/trofi/trofi.github.io.gen/commit/6b1883a1b23f6965314bfd2b55cb3e9e6a42ec16">metadata change</a>.</p>
<p>That way all new posts should contain <code>https://</code> root links and all
site-local links should automatically become <code>https://</code> links.</p>
<p>Still no tag support. Maybe later.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 06 Jul 2024 00:00:00 UT</pubDate>
    <guid>https://trofi.github.io/posts/320-blog-tweaks.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>probabilities are hard</title>
    <link>http://trofi.github.io/posts/319-probabilities-are-hard.html</link>
    <description><![CDATA[<h2 id="make---shuffle-background"><code>make --shuffle</code> background</h2>
<p><a href="https://trofi.github.io/posts/238-new-make-shuffle-mode.html">A while ago</a> I added <code>--shuffle</code>
mode to <code>GNU make</code> to shake out missing dependencies in build rules of
<code>make</code>-based build systems. It managed to find
<a href="https://trofi.github.io/posts/249-an-update-on-make-shuffle.html">a few bugs</a> since.</p>
<h2 id="the-shuffling-algorithm">the shuffling algorithm</h2>
<p>The core function of <code>--shuffle</code> is to generate one random permutation
of prerequisites for a target. I did not try to implement anything
special. I searched for “random shuffle” and got
<a href="https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle">Fisher–Yates shuffle</a>
link from <code>wikipedia</code>, skimmed the page and came up with this algorithm:</p>
<pre class="c"><code>/* Shuffle array elements using RAND().  */
static void
random_shuffle_array (void **a, size_t len)
{
  size_t i;
  for (i = 0; i &lt; len; i++)
    {
      void *t;

      /* Pick random element and swap. */
      unsigned int j = rand () % len;
      if (i == j)
        continue;

      /* Swap. */
      t = a[i];
      a[i] = a[j];
      a[j] = t;
    }
}</code></pre>
<p>The diagram of a single step looks this way:</p>
<img src="https://trofi.github.io/posts.data.inline/319-probabilities-are-hard/fig-0.gv.svg" />
<p>The implementation looked so natural: we attempt to shuffle each element
with another element chosen randomly using equal probability (assuming
<code>rand () % len</code> is unbiased). At least it seemed to produce random
results.</p>
<p><strong>Quiz question</strong>: do you see the bug in this implementation?</p>
<p>This version was shipped in <code>make-4.4.1</code>.</p>
<p>I ran <code>make</code> from <code>git</code> against <code>nixpkgs</code> and discovered a ton of
parallelism bugs. I could not be happier than that. I never got to
actual testing the quality of permutation probabilities.</p>
<h2 id="bias-in-initial-implementation">bias in initial implementation</h2>
<p>Artem Klimov had a closer look at it and discovered a bug in the
algorithm above! The algorithm has a common implementation error for
Fisher–Yates
<a href="https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle#Implementation_errors">documented</a>
on the very page I looked at before /o\. Artem demonstrated problems of
permutation quality on the following trivial <code>Makefile</code>:</p>
<pre class="makefile"><code>all: test1 test2 test3 test4 test5 test6 test7 test8;

test%:
	mkdir -p tests
	echo $@ &gt; tests/$@

test8:
	# no mkdir
	echo 'override' &gt; tests/$@</code></pre>
<p>This test was supposed to fail <code>12.5%</code> of the time in <code>--shuffle</code> mode:
only when <code>test8</code> is scheduled as the first to execute. Alas the test
when ran over thousands runs failed with <code>10.1%</code> probability. That is
<code>2%</code> too low.</p>
<p>Artem also provided a fixed version of the shuffle implementation:</p>
<pre class="c"><code>static void
random_shuffle_array (void **a, size_t len)
{
  size_t i;
  for (i = len - 1; i &gt;= 1; i--)
    {
      void *t;

      /* Pick random element and swap. */
      unsigned int j = make_rand () % (i + 1);

      /* Swap. */
      t = a[i];
      a[i] = a[j];
      a[j] = t;
    }
}</code></pre>
<p>The diagram of a single step looks this way:</p>
<img src="https://trofi.github.io/posts.data.inline/319-probabilities-are-hard/fig-1.gv.svg" />
<p>Note how this version makes sure that shuffled indices (“gray” color)
never gets considered for future shuffle iterations.</p>
<p>At least for me it’s more obvious to see why this algorithm does not
introduce any biases. But then again I did not suspect problems in the
previous one either. I realised I don’t have a good intuition on why the
initial algorithm manages to produce biases. Where does bias come from
if we pick the target element with equal probability from all the
elements available?</p>
<h1 id="a-simple-test">a simple test</h1>
<p>To get the idea how the bias looks like I wrote a tiny program:</p>
<pre class="c"><code>// $ cat a.c
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;time.h&gt;

#define LEN 3
static int a[LEN];

static void random_shuffle_array (void) {
  for (size_t i = 0; i &lt; LEN; i++) {
      unsigned int j = rand () % LEN;
      int t = a[i]; a[i] = a[j]; a[j] = t;
    }
}

static void random_shuffle_array_fixed (void) {
  for (size_t i = LEN - 1; i &gt;= 1; i--) {
      unsigned int j = rand () % (i + 1);
      int t = a[i]; a[i] = a[j]; a[j] = t;
    }
}

static void do_test(const char * name, void(*shuffler)(void)) {
    size_t hist[LEN][LEN];
    memset(hist, 0, sizeof(hist));

    size_t niters = 10000000;

    printf(&quot;%s shuffle probability over %zu iterations:\n&quot;, name, niters);
    for (size_t iter = 0; iter &lt; niters; ++iter) {
        // Initialize array `a` with { `0`,  ..., `LEN - 1` }.
        for (size_t i = 0; i &lt; LEN; ++i) a[i] = i;
        shuffler ();
        for (size_t i = 0; i &lt; LEN; ++i) hist[i][a[i]] += 1;
    }

    int prec_digits = 3; /* 0.??? */
    int cell_width = 3 + prec_digits; /* &quot; 0.???&quot; */

    printf(&quot;%*s  &quot;, cell_width, &quot;&quot;);
    for (size_t j = 0; j &lt; LEN; ++j)
        printf(&quot;%*zu&quot;, cell_width, j);
    puts(&quot;&quot;);

    for (size_t i = 0; i &lt; LEN; ++i) {
        printf(&quot;%*zu |&quot;, cell_width, i);
        for (size_t j = 0; j &lt; LEN; ++j)
            printf(&quot; %.*f&quot;, prec_digits, (double)(hist[i][j]) / (double)(niters));
        puts(&quot;&quot;);
    }
}

int main() {
    srand(time(NULL));
    do_test(&quot;broken&quot;, &amp;random_shuffle_array);
    puts(&quot;&quot;);
    do_test(&quot;fixed&quot;, &amp;random_shuffle_array_fixed);
}</code></pre>
<p>Here the program implement both current (broken) and new (fixed) shuffle
implementations. The histogram is collected over 10 million runs.
Then it prints a probability of each element to be found at a location.
We shuffle an array of <code>LEN = 3</code> elements: <code>{ 0, 1, 2, }</code>.</p>
<p>Here is the output of the program:</p>
<pre><code>$ gcc a.c -o a -O2 -Wall &amp;&amp; ./a
broken shuffle probability over 10000000 iterations:
             0     1     2
     0 | 0.333 0.370 0.296
     1 | 0.333 0.297 0.370
     2 | 0.334 0.333 0.333

fixed shuffle probability over 10000000 iterations:
             0     1     2
     0 | 0.333 0.333 0.334
     1 | 0.333 0.334 0.333
     2 | 0.333 0.333 0.333</code></pre>
<p>Here the program tells us that:</p>
<ul>
<li>broken version of the shuffle moves element <code>0</code> to <code>1</code> position <code>37%</code> of the time</li>
<li>broken version moves element <code>0</code> to <code>2</code> position <code>29.6%</code> of the time</li>
<li>fixed version is much closed to uniform distribution and has roughly
<code>33.3%</code> <code>0-&gt;1</code> and <code>0-&gt;2</code> probabilities</li>
</ul>
<p>The same data above in plots:</p>
<img src="https://trofi.github.io/posts.data.inline/319-probabilities-are-hard/fig-2.gp.svg" />
<h2 id="a-bit-of-arithmetics">a bit of arithmetics</h2>
<p>To get a bit better understanding of the bias let’s get exact probability
value for each element move for 3-element array.</p>
<h3 id="broken-version">broken version</h3>
<p>To recap the implementation we are looking at here is:</p>
<pre class="c"><code>void random_shuffle_array (void) {
  for (size_t i = 0; i &lt; LEN; i++) {
      unsigned int j = rand () % LEN;
      int t = a[i]; a[i] = a[j]; a[j] = t;
    }
}</code></pre>
<p>Let’s start from broken shuffle with <code>1/(N+1)</code> shuffle probability.</p>
<p>Our initial array state is <code>{ 0, 1, 2, }</code> with probability <code>1/1</code>
(or <code>100%</code>) for each already assigned value:</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>1/1</code></li>
<li>value <code>1</code>: <code>0/1</code></li>
<li>value <code>2</code>: <code>0/1</code></li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>0/1</code></li>
<li>value <code>1</code>: <code>1/1</code></li>
<li>value <code>2</code>: <code>0/1</code></li>
</ul></li>
<li>probability at index <code>2</code>:
<ul>
<li>value <code>0</code>: <code>0/1</code></li>
<li>value <code>1</code>: <code>0/1</code></li>
<li>value <code>2</code>: <code>1/1</code></li>
</ul></li>
</ul>
<p>On each iteration <code>i</code> we perform the actions below:</p>
<ul>
<li>at <code>i</code> position: <code>1/3</code> probability of swapping any of the possible elements</li>
<li>at non-<code>i</code> positions: <code>2/3</code> probability of keeping and old element (and <code>1/3</code>
probability of absorbing value at <code>i</code> position mentioned in the previous bullet)</li>
</ul>
<p>Thus after first shuffle step at <code>i=0</code> our probability state will be:</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>1/3</code> (was <code>1.0</code>)</li>
<li>value <code>1</code>: <code>1/3</code> (was <code>0.0</code>)</li>
<li>value <code>2</code>: <code>1/3</code> (was <code>0.0</code>)</li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>1/3</code> (was <code>0.0</code>)</li>
<li>value <code>1</code>: <code>2/3</code> (was <code>1.0</code>)</li>
<li>value <code>2</code>: <code>0/3</code> (was <code>0.0</code>)</li>
</ul></li>
<li>probability at index <code>2</code>:
<ul>
<li>value <code>0</code>: <code>1/3</code> (was <code>0.0</code>)</li>
<li>value <code>1</code>: <code>0/3</code> (was <code>0.0</code>)</li>
<li>value <code>2</code>: <code>2/3</code> (was <code>1.0</code>)</li>
</ul></li>
</ul>
<p>So far so good: element <code>0</code> has even probability among all 3 elements,
and elements <code>1</code> and <code>2</code> decreased their initial probabilities from <code>1/1</code>
down to <code>2/3</code>.</p>
<p>Let’s trace through next <code>i=1</code> step. After that the updated state will be:</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>3/9</code> (was <code>1/3</code>)</li>
<li>value <code>1</code>: <code>4/9</code> (was <code>1/3</code>)</li>
<li>value <code>2</code>: <code>2/9</code> (was <code>1/3</code>)</li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>3/9</code> (was <code>1/3</code>)</li>
<li>value <code>1</code>: <code>3/9</code> (was <code>2/3</code>)</li>
<li>value <code>2</code>: <code>3/9</code> (was <code>0/3</code>)</li>
</ul></li>
<li>probability at index <code>2</code>:
<ul>
<li>value <code>0</code>: <code>3/9</code> (was <code>1/3</code>)</li>
<li>value <code>1</code>: <code>2/9</code> (was <code>0/3</code>)</li>
<li>value <code>2</code>: <code>4/9</code> (was <code>2/3</code>)</li>
</ul></li>
</ul>
<p>Again, magically current (<code>i=1</code>) element got perfect balance. Zero
probabilities are gone by now.</p>
<p>Final <code>i=2</code> step yields this:</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>9/27</code> (was <code>3/9</code>)</li>
<li>value <code>1</code>: <code>10/27</code> (was <code>4/9</code>)</li>
<li>value <code>2</code>: <code>8/27</code> (was <code>2/9</code>)</li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>9/27</code> (was <code>3/9</code>)</li>
<li>value <code>1</code>: <code>8/27</code> (was <code>3/9</code>)</li>
<li>value <code>2</code>: <code>10/27</code> (was <code>3/9</code>)</li>
</ul></li>
<li>probability at index <code>2</code>:
<ul>
<li>value <code>0</code>: <code>9/27</code> (was <code>3/9</code>)</li>
<li>value <code>1</code>: <code>9/27</code> (was <code>2/9</code>)</li>
<li>value <code>2</code>: <code>9/27</code> (was <code>4/9</code>)</li>
</ul></li>
</ul>
<p>The same state sequence in diagrams:</p>
<img src="https://trofi.github.io/posts.data.inline/319-probabilities-are-hard/fig-3.gv.svg" />
<p>Note that final probabilities differ slightly: <code>8/27</code>, <code>9/27</code> and <code>10/27</code>
are probabilities where all should have been <code>9/27</code> (or <code>1/3</code>). This
matches observed values above!</p>
<p>The bias comes from the fact that each shuffle step affects probabilities
of all cells, not just immediately picked cells for a particular shuffle.
That was very hard to grasp for me just by glancing at the algorithm!</p>
<h3 id="fixed-version">Fixed version</h3>
<p>To recap the implementation we are looking at here is:</p>
<pre class="c"><code>void random_shuffle_array_fixed (void) {
  for (size_t i = LEN - 1; i &gt;= 1; i--) {
      unsigned int j = rand () % (i + 1);
      int t = a[i]; a[i] = a[j]; a[j] = t;
    }
}</code></pre>
<p>Now let’s have a look at a shuffle with <code>1/(i+1)</code> probability.</p>
<p>Our initial state is the same <code>{ 0, 1, 2, }</code> with probabilities <code>1/1</code>:</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>1/1</code></li>
<li>value <code>1</code>: <code>0/1</code></li>
<li>value <code>2</code>: <code>0/1</code></li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>0/1</code></li>
<li>value <code>1</code>: <code>1/1</code></li>
<li>value <code>2</code>: <code>0/1</code></li>
</ul></li>
<li>probability at index <code>2</code>:
<ul>
<li>value <code>0</code>: <code>0/1</code></li>
<li>value <code>1</code>: <code>0/1</code></li>
<li>value <code>2</code>: <code>1/1</code></li>
</ul></li>
</ul>
<p>As the algorithm iterated over the array backwards we start from <code>i=2</code>
(<code>N=3</code>).</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>2/3</code> (was <code>1/1</code>)</li>
<li>value <code>1</code>: <code>0/3</code> (was <code>0/1</code>)</li>
<li>value <code>2</code>: <code>1/3</code> (was <code>0/1</code>)</li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>0/3</code> (was <code>0/1</code>)</li>
<li>value <code>1</code>: <code>2/3</code> (was <code>1/1</code>)</li>
<li>value <code>2</code>: <code>1/3</code> (was <code>0/1</code>)</li>
</ul></li>
<li>probability at index <code>2</code>:
<ul>
<li>value <code>0</code>: <code>1/3</code> (was <code>0/1</code>)</li>
<li>value <code>1</code>: <code>1/3</code> (was <code>0/1</code>)</li>
<li>value <code>2</code>: <code>1/3</code> (was <code>1/1</code>)</li>
</ul></li>
</ul>
<p>As expected the probabilities are the mirror image of the first step of
the broken implementation.</p>
<p>The next step though is a bit different: <code>i=1</code> (<code>N=2</code>). It effectively
averages probabilities at index <code>0</code> and index <code>1</code>.</p>
<ul>
<li>probability at index <code>0</code>:
<ul>
<li>value <code>0</code>: <code>1/3</code> (was <code>2/3</code>)</li>
<li>value <code>1</code>: <code>1/3</code> (was <code>0/3</code>)</li>
<li>value <code>2</code>: <code>1/3</code> (was <code>1/3</code>)</li>
</ul></li>
<li>probability at index <code>1</code>:
<ul>
<li>value <code>0</code>: <code>1/3</code> (was <code>0/3</code>)</li>
<li>value <code>1</code>: <code>1/3</code> (was <code>2/3</code>)</li>
<li>value <code>2</code>: <code>1/3</code> (was <code>1/3</code>)</li>
</ul></li>
<li>probability at index <code>2</code> (unchanged):
<ul>
<li>value <code>0</code>: <code>1/3</code></li>
<li>value <code>1</code>: <code>1/3</code></li>
<li>value <code>2</code>: <code>1/3</code></li>
</ul></li>
</ul>
<p>Or the same in diagrams:</p>
<img src="https://trofi.github.io/posts.data.inline/319-probabilities-are-hard/fig-4.gv.svg" />
<p>The series are a lot simpler than the broken version: on each step
handled element always ends up with identical expected probabilities.
Its so much simpler!</p>
<h2 id="element-bonus">30-element bonus</h2>
<p>Let’s look at the probability table for an array of 30-elements. The
only change I did for the program above is to change <code>LEN</code> from <code>3</code> to
<code>30</code>:</p>
<img src="https://trofi.github.io/posts.data.inline/319-probabilities-are-hard/fig-5.gp.svg" />
<p>This plot shows a curious <code>i == j</code> cutoff line where probability changes
drastically:</p>
<ul>
<li><code>15-&gt;15</code> (or any <code>i-&gt;i</code>) shuffle probability is lowest and is about <code>2.8%</code></li>
<li><code>15-&gt;16</code> (or any <code>i-&gt;i+1</code>) shuffle probability is highest and is about <code>4.0%</code></li>
</ul>
<h2 id="make---shuffle-bias-fix"><code>make --shuffle</code> bias fix</h2>
<p>I posted Artem’s fix upstream for inclusion as
<a href="https://mail.gnu.org/archive/html/bug-make/2024-06/msg00008.html">this email</a>:</p>
<pre class="diff"><code>--- a/src/shuffle.c
+++ b/src/shuffle.c
@@ -104,12 +104,16 @@ static void
 random_shuffle_array (void **a, size_t len)
 {
   size_t i;
-  for (i = 0; i &lt; len; i++)
+
+  if (len &lt;= 1)
+    return;
+
+  for (i = len - 1; i &gt;= 1; i--)
     {
       void *t;

       /* Pick random element and swap. */
-      unsigned int j = make_rand () % len;
+      unsigned int j = make_rand () % (i + 1);
       if (i == j)
         continue;
</code></pre>
<h2 id="parting-words">parting words</h2>
<p>Artem Klimov found, fixed and explained the bias in <code>make --shuffle</code>
implementation. Thank you, Artem!</p>
<p>Probabilities are hard! I managed to get wrong seemingly very simple
algorithm. The bias is not too bad: <code>make --shuffle</code> is still able to
produce all possible permutations of the targets. But some of them are
slightly less frequent than the others.</p>
<p>The bias has a curious structure:</p>
<ul>
<li>least likely permutations candidate is <code>i-&gt;i</code> “identity” shuffle</li>
<li>most likely permutation candidate is <code>i-&gt;i+1</code> “right shift” shuffle</li>
</ul>
<p>At least the initial implementation was not completely broken and still
was able to generate all permutations.</p>
<p>With luck <a href="https://mail.gnu.org/archive/html/bug-make/2024-06/msg00008.html">the fix</a>
will be accepted upstream and we will get more fair <code>--shuffle</code> mode.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 23 Jun 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/319-probabilities-are-hard.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>inline gnuplot</title>
    <link>http://trofi.github.io/posts/318-inline-gnuplot.html</link>
    <description><![CDATA[<p>Time to time I find myself needing to plot histograms and approximations
in occasional posts.</p>
<p>Similar to <a href="https://trofi.github.io/posts/300-inline-graphviz-dot-in-hakyll.html">inline <code>graphviz</code></a>
support today I added <code>gnuplot</code> <code>svg</code> inlining support into this blog.</p>
<p>The trivial example looks this way:</p>
<img src="https://trofi.github.io/posts.data.inline/318-inline-gnuplot/fig-0.gp.svg" />
<p>The above is generated using the following <code>.md</code> snippet:</p>
<pre><code>    ```{render=gnuplot}
    plot [-pi:pi] sin(x)
    ```</code></pre>
<p><code>hakyll</code> <a href="https://github.com/trofi/trofi.github.io.gen/commit/4fb830628c6923873c0b21b2ac444a73d4d47cee">integration</a>
is also straightforward:</p>
<pre class="haskell"><code>inlineGnuplot :: TP.Block -&gt; Compiler TP.Block
inlineGnuplot cb@(TP.CodeBlock (id, classes, namevals) contents)
  | (&quot;render&quot;, &quot;gnuplot&quot;) `elem` namevals
  = TP.RawBlock (TP.Format &quot;html&quot;) . DT.pack &lt;$&gt; (
      unixFilter &quot;gnuplot&quot;
          [ &quot;--default-settings&quot;
          , &quot;-e&quot;, &quot;set terminal svg&quot;
          , &quot;-&quot;]
          (DT.unpack contents))
inlineGnuplot x = return x</code></pre>
<p>Here we call <code>gnuplot --default-settings -e "set terminal svg" -</code> and
pass our script over <code>stdin</code>. Easy!</p>
<p>For those who wonder what <code>gnuplot</code> is capable of have a look at
<a href="http://www.gnuplot.info/demo_svg_4.6/"><code>gnuplot.info</code> demo page</a>.</p>
<p>As a bonus here is the time chart of my commits into <code>nixpkgs</code>:</p>
<img src="https://trofi.github.io/posts.data.inline/318-inline-gnuplot/fig-1.gp.svg" />
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 22 Jun 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/318-inline-gnuplot.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc simd intrinsics bug</title>
    <link>http://trofi.github.io/posts/317-gcc-simd-intrinsics-bug.html</link>
    <description><![CDATA[<p><code>highway</code> keeps yielding very interesting <code>gcc</code> bugs. Some of them are
so obscure that I don’t even understand <code>gcc</code> developers’ comments on
where the bug lies: in <code>highway</code> or on <code>gcc</code>. In this post I’ll explore
<a href="https://gcc.gnu.org/PR115161"><code>PR115161</code></a> report here as an example of
how <code>gcc</code> handles <code>simd</code> intrinsics.</p>
<h2 id="simplest-xmm-intrinsics-example">simplest <code>xmm</code> intrinsics example</h2>
<p>Let’s start from an example based on another closely related bug:</p>
<pre class="c"><code>#include &lt;emmintrin.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;
#include &lt;string.h&gt;

int main(void) {
    const __m128i  iv = _mm_set1_epi32(0x4f000000); // 1
    const __m128   fv = _mm_castsi128_ps(iv);       // 2
    const __m128i riv = _mm_cvttps_epi32(fv);       // 3

    uint32_t r[4];
    memcpy(r, &amp;riv, sizeof(r));
    printf(&quot;%#08x %#08x %#08x %#08x\n&quot;, r[0], r[1], r[2], r[3]);
}</code></pre>
<p>The above example implements a vectored form of <code>(int)2147483648.0</code>
conversion using following steps:</p>
<ol type="1">
<li>Place 4 identical 32-bit integer <code>0x4f000000</code> values into 128-bit
<code>iv</code> variable (likely an <code>xmm</code> register).</li>
<li>Bit cast <code>4 x 0x4f00000</code> into <code>4 x 2147483648.0</code> of 32-bit <code>float</code>s.</li>
<li>Convert <code>4 x 2147483648.0</code> 32-bit <code>float</code>s into <code>4 x int32_t</code> by
truncating the fractional part and leaving the integer one.</li>
<li>Print the conversion result in hexadecimal form.</li>
</ol>
<p>Or the same in pictures:</p>
<img src="https://trofi.github.io/posts.data.inline/317-gcc-simd-intrinsics-bug/fig-0.gv.svg" />
<p>Note: <code>2147483648.0</code> is exactly 2<sup>31</sup>. Maximum <code>int32_t</code> can hold is
2<sup>31</sup>-1, or <code>2147483647</code> (one less than our value at hand).</p>
<p><strong>Quick quiz: What should this example return? Does it depend on the
compiler options?</strong></p>
<p>In theory those <code>_mm*()</code> compiler intrinsics are tiny wrappers over
corresponding <code>x86_64</code> instructions.
<a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel guide</a>
says that <code>_mm_cvttps_epi32()</code> is a <code>cvttps2dq</code> instruction.</p>
<p>Running the example:</p>
<pre><code>$ gcc -Wall a.c -o a0 -O0 &amp;&amp; ./a0
0x80000000 0x80000000 0x80000000 0x80000000

$ gcc -Wall a.c -o a1 -O1 &amp;&amp; ./a1
0x7fffffff 0x7fffffff 0x7fffffff 0x7fffffff</code></pre>
<p>Optimization levels do change the behaviour of the code when
overflow happens: sometimes the result is 2<sup>31</sup> and sometimes it’s
2<sup>31</sup>-1. Uh-oh. Let’s have a peek at the assembly of both cases.</p>
<p><code>-O0</code> case:</p>
<pre class="asm"><code>; $ rizin ./a0
; [0x00401050]&gt; aaaa
; [0x00401050]&gt; s main
; [0x00401136]&gt; pdf
            ; DATA XREF from entry0 @ 0x401068
; int main(int argc, char **argv, char **envp);
; ...
          movl  $0x4f000000, var_8ch
          movl  var_8ch, %eax
; ...
          movl  %eax, var_80h
          movd  var_80h, %xmm1
          punpckldq %xmm1, %xmm0
; ...
          movaps %xmm0, var_48h
          cvttps2dq var_48h, %xmm0
          movaps %xmm0, var_78h
          movq  var_78h, %rax
          movq  var_70h, %rdx
          movq  %rax, var_28h
          movq  %rdx, var_20h
          movl  var_1ch, %esi
          movl  var_20h, %ecx
          movl  var_24h, %edx
          movl  var_28h, %eax
          leaq  str.08x___08x___08x___08x, %rdi      ; 0x402004 ; &quot;%#08x %#08x %#08x %#08x\n&quot; ; const char *format
          movl  %esi, %r8d
          movl  %eax, %esi
          movl  $0, %eax
          callq sym.imp.printf                       ; sym.imp.printf ; int printf(const char *format)
; ...</code></pre>
<p>While it’s a lot of superfluous code we do see there <code>cvttps2dq</code>
instruction and <code>printf()</code> call against it’s result.</p>
<p><code>-O1</code> case:</p>
<pre class="asm"><code>$ rizin ./a1
; [0x00401040]&gt; aaaa
; [0x00401040]&gt; s main
; [0x00401126]&gt; pdf
            ; DATA XREF from entry0 @ 0x401058
; int main(int argc, char **argv, char **envp);
          subq  $8, %rsp
          movl  $0x7fffffff, %r9d
          movl  $0x7fffffff, %r8d
          movl  $0x7fffffff, %ecx
          movl  $0x7fffffff, %edx
          leaq  str.08x___08x___08x___08x, %rsi      ; 0x402004 ; &quot;%#08x %#08x %#08x %#08x\n&quot;
          movl  $2, %edi
          movl  $0, %eax
          callq sym.imp.__printf_chk                 ; sym.imp.__printf_chk
          movl  $0, %eax
          addq  $8, %rsp
          retq</code></pre>
<p>Here we don’t see <code>cvttps2dq</code> at all! <code>gcc</code> just puts <code>0x7fffffff</code>
constants into registers and calls <code>printf()</code> directly.</p>
<p>For completeness let’s try to find out the exact optimization pass that
performs this constant folding. Normally I would expect it to be a tree
optimization, and thus <code>-fdump-tree-all</code> would tell me where the magic
happens. Alas:</p>
<pre class="c"><code>// $ gcc a.c -o a -O2 -fdump-tree-all &amp;&amp; ./a
// $ cat a.c.265t.optimized

;; Function main (main, funcdef_no=574, decl_uid=6511, cgraph_uid=575, symbol_order=574) (executed once)

int main ()
{
  unsigned int _2;
  vector(4) int _3;
  unsigned int _4;
  unsigned int _5;
  unsigned int _6;

  &lt;bb 2&gt; [local count: 1073741824]:
  _3 = __builtin_ia32_cvttps2dq ({ 2.147483648e+9, 2.147483648e+9, 2.147483648e+9, 2.147483648e+9 });
  _2 = BIT_FIELD_REF &lt;_3, 32, 96&gt;;
  _6 = BIT_FIELD_REF &lt;_3, 32, 64&gt;;
  _4 = BIT_FIELD_REF &lt;_3, 32, 32&gt;;
  _5 = BIT_FIELD_REF &lt;_3, 32, 0&gt;;
  __printf_chk (2, &quot;%#08x %#08x %#08x %#08x\n&quot;, _5, _4, _6, _2);
  return 0;

}</code></pre>
<p>Here we see that <code>_mm_set1_epi32()</code> and <code>_mm_castsi128_ps()</code> were
“folded” into a <code>2.147483648e+9</code> successfully, but <code>_mm_cvttps_epi32()</code>
was not. And yet the final assembly does not contain the call. Let’s
have a loot at the <code>RTL</code> passes that usually follow <code>tree</code> ones as part
of the optimization:</p>
<pre><code>$ gcc a.c -o a -O2 -fdump-rtl-all-slim &amp;&amp; ./a
$ ls -1 *r.*
a.c.266r.expand
a.c.267r.vregs
a.c.268r.into_cfglayout
a.c.269r.jump
a.c.270r.subreg1
a.c.271r.dfinit
a.c.272r.cse1
a.c.273r.fwprop1
a.c.274r.cprop1
a.c.275r.pre
a.c.277r.cprop2
a.c.280r.ce1
a.c.281r.reginfo
a.c.282r.loop2
a.c.283r.loop2_init
a.c.284r.loop2_invariant
a.c.285r.loop2_unroll
a.c.287r.loop2_done
a.c.290r.cprop3
a.c.291r.stv1
a.c.292r.cse2
a.c.293r.dse1
a.c.294r.fwprop2
a.c.296r.init-regs
a.c.297r.ud_dce
a.c.298r.combine
a.c.300r.stv2
a.c.301r.ce2
a.c.302r.jump_after_combine
a.c.303r.bbpart
a.c.304r.outof_cfglayout
a.c.305r.split1
a.c.306r.subreg3
a.c.308r.mode_sw
a.c.309r.asmcons
a.c.314r.ira
a.c.315r.reload
a.c.316r.postreload
a.c.319r.split2
a.c.320r.ree
a.c.321r.cmpelim
a.c.322r.pro_and_epilogue
a.c.323r.dse2
a.c.324r.csa
a.c.325r.jump2
a.c.326r.compgotos
a.c.328r.peephole2
a.c.329r.ce3
a.c.331r.fold_mem_offsets
a.c.332r.cprop_hardreg
a.c.333r.rtl_dce
a.c.334r.bbro
a.c.335r.split3
a.c.336r.sched2
a.c.338r.stack
a.c.340r.zero_call_used_regs
a.c.341r.alignments
a.c.343r.mach
a.c.344r.barriers
a.c.349r.shorten
a.c.350r.nothrow
a.c.351r.dwarf2
a.c.352r.final
a.c.353r.dfinish</code></pre>
<p>It’s a long list of passes! Let’s have a look at the first <code>266r.expand</code>:</p>
<pre><code>$ cat a.c.266r.expand
;;
;; Full RTL generated for this function:
;;
    1: NOTE_INSN_DELETED
    3: NOTE_INSN_BASIC_BLOCK 2
    2: NOTE_INSN_FUNCTION_BEG
    5: r106:V4SF=vec_duplicate([`*.LC1'])
    6: r105:V4SF=r106:V4SF
      REG_EQUAL const_vector
    7: r104:V4SI=fix(r105:V4SF)

    8: r99:V4SI=r104:V4SI
    9: r108:V4SI=vec_select(r99:V4SI,parallel)
   10: r107:SI=vec_select(r108:V4SI,parallel)
   11: r110:V4SI=vec_select(vec_concat(r99:V4SI,r99:V4SI),parallel)
   12: r109:SI=vec_select(r110:V4SI,parallel)
   13: r112:V4SI=vec_select(r99:V4SI,parallel)
   14: r111:SI=vec_select(r112:V4SI,parallel)
   15: r113:SI=vec_select(r99:V4SI,parallel)
   16: r114:DI=`*.LC2'
   17: r9:SI=r107:SI
   18: r8:SI=r109:SI
   19: cx:SI=r111:SI
   20: dx:SI=r113:SI
   21: si:DI=r114:DI
   22: di:SI=0x2
   23: ax:QI=0
   24: ax:SI=call [`__printf_chk'] argc:0
      REG_CALL_DECL `__printf_chk'
   25: r103:SI=0
   29: ax:SI=r103:SI
   30: use ax:SI</code></pre>
<p>Here <code>V4SF</code> means the vector type of 4 floats, <code>V4SI</code> is a vector type
of 4 <code>int</code>s, <code>SI</code> is an <code>int</code> type, <code>DI</code> is a <code>long</code> type. It looks like
our <code>float-&gt;int32_t</code> conversion happens in two early <code>RTL</code> instructions:</p>
<pre><code>    5: r106:V4SF=vec_duplicate([`*.LC1'])
    6: r105:V4SF=r106:V4SF
      REG_EQUAL const_vector
    7: r104:V4SI=fix(r105:V4SF)</code></pre>
<p>The rest of <code>RTL</code> code is extraction of that result as <code>printf()</code>
arguments. It’s a lot of superfluous data moves. Later optimizations
should clean it up and assign “hardware” registers like <code>r9</code> to virtual
registers like <code>r108</code>. For completeness final <code>353r.dfinish</code> looks this
way:</p>
<pre><code>$ cat a.c.353r.dfinish

;; Function main (main, funcdef_no=574, decl_uid=6511, cgraph_uid=575, symbol_order=574) (executed once)

    1: NOTE_INSN_DELETED
    3: NOTE_INSN_BASIC_BLOCK 2
    2: NOTE_INSN_FUNCTION_BEG
   34: {sp:DI=sp:DI-0x8;clobber flags:CC;clobber [scratch];}
      REG_UNUSED flags:CC
      REG_CFA_ADJUST_CFA sp:DI=sp:DI-0x8
   35: NOTE_INSN_PROLOGUE_END
   19: cx:SI=0x7fffffff
   20: dx:SI=0x7fffffff
   44: {ax:DI=0;clobber flags:CC;}
      REG_UNUSED flags:CC
   17: r9:SI=0x7fffffff
   18: r8:SI=0x7fffffff
   22: di:SI=0x2
   32: si:DI=`*.LC2'
      REG_EQUIV `*.LC2'
   24: ax:SI=call [`__printf_chk'] argc:0
      REG_DEAD r9:SI
      REG_DEAD r8:SI
      REG_DEAD di:SI
      REG_DEAD si:DI
      REG_DEAD cx:SI
      REG_DEAD dx:SI
      REG_UNUSED ax:SI
      REG_CALL_DECL `__printf_chk'
   45: {ax:DI=0;clobber flags:CC;}
      REG_UNUSED flags:CC
   46: NOTE_INSN_EPILOGUE_BEG
   37: {sp:DI=sp:DI+0x8;clobber flags:CC;clobber [scratch];}
      REG_UNUSED flags:CC
      REG_CFA_ADJUST_CFA sp:DI=sp:DI+0x8
   30: use ax:SI
   38: simple_return
   41: barrier
   33: NOTE_INSN_DELETED</code></pre>
<p>Here we don’t have <code>fix()</code> calls any more. <code>printf()</code> call already
contains immediate <code>r8:SI=0x7fffffff</code> constants. All registers are
resolved to real register names. Searching for <code>fix()</code> in all the pass
files I found that <code>272r.cse1</code> was the last pass that mentioned it.
<code>a.c.273r.fwprop1</code> already has the constants inlined. Looking at
<code>272r.cse1</code> in <code>-fdump-rtl-all-all</code> we can see that details are inferred
by <code>cse1</code> about the <code>fix()</code> <code>RTL</code> instruction:</p>
<pre><code>(insn 7 6 8 2 (set (reg:V4SI 104)
        (fix:V4SI (reg:V4SF 106))) &quot;...-gcc-15.0.0/lib/gcc/x86_64-unknown-linux-gnu/15.0.0/include/emmintrin.h&quot;:863:19 4254 {
fix_truncv4sfv4si2}
     (expr_list:REG_EQUAL (const_vector:V4SI [
                (const_int 2147483647 [0x7fffffff]) repeated x4
            ])
        (expr_list:REG_DEAD (reg:V4SF 105)
            (nil))))</code></pre>
<p><code>fix_truncv4sfv4si2()</code> is the name of function that implements conversion
from <code>fix()</code> call down to the lower level instructions. And it looks
like <code>fix()</code> expansion also derived that the finals result is a constant:
<code>(expr_list:REG_EQUAL (const_vector:V4SI [ (const_int 2147483647 [0x7fffffff]) repeated x4])</code>.
Next <code>fwprop1</code> pass will use that constant value everywhere where <code>r104</code>
is used.</p>
<p><a href="https://gcc.gnu.org/onlinedocs/gccint/Standard-Names.html"><code>gcc</code> internals</a>
documentation says that <code>fix_trunc</code> is a <code>float-to-int</code> conversion. Note
that this conversion does not look specific to our intrinsic. Any
code that casts floats would use the same helper. That explains why
<code>_mm_cvttps_epi32()</code> semantics around the overflow are not honoured and
generic floating conversion code it performed by <code>gcc</code> as if it was
written as <code>(int)(2147483648.0f)</code>. Apparently both <code>0x7fffffff</code> and
<code>0x80000000</code> values are correct under that assumption.</p>
<p>The problem is that <code>_mm_cvttps_epi32()</code> is more specific than any valid
<code>float-&gt;int</code> conversion. <code>intel</code> manual specifically says that at
<a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"><code>CVTTPS2DQ</code> description</a>
in “Intel® 64 and IA-32 Architectures Software Developer’s Manual Combined
Volumes: 1, 2A, 2B, 2C, 2D, 3A, 3B, 3C, 3D, and 4”:</p>
<pre><code>Description
...
When a conversion is inexact, a truncated (round toward zero) value is
returned. If a converted result is larger than the maximum signed
doubleword integer, the floating-point invalid exception is raised, and
if this exception is masked, the indefinite integer value (80000000H) is
returned.</code></pre>
<p>Thus <code>0x80000000</code> would be a correct value here and not <code>0x7fffffff</code>.</p>
<h2 id="avoiding-the-_mm_cvttps_epi32-non-determinism">avoiding the <code>_mm_cvttps_epi32()</code> non-determinism</h2>
<p>OK, <code>gcc</code> decided to treat it as problematic when handling overflow
condition. That should be easy to workaround by checking first if our
value is in range first, right? Say, something like the following
pseudocode:</p>
<pre class="c"><code>float v = 2147483648.0f;
int32_t result;
if (v &gt;= 2147483648.0f) {
    result = 0x7fffffff;
} else {
    result = fix(v);
}</code></pre>
<p>In a vectored code writing branching code is problematic, thus one needs
to be creative and use masking. That is what <code>highway</code> did in
<a href="https://github.com/google/highway/commit/9dc6e1ecb0748df78398b037d6a8a89e667702e7"><code>avoid GCC "UB" in truncating cases</code></a>
commit. It’s a lot of code, but it’s idea is to mask away values
calculated against overflows:</p>
<pre class="diff"><code>@@ -10884,7 +10869,11 @@ HWY_API VFromD&lt;D&gt; ConvertInRangeTo(D /*di*/, VFromD&lt;RebindToFloat&lt;D&gt;&gt; v) {
 // F32 to I32 ConvertTo is generic for all vector lengths
 template &lt;class D, HWY_IF_I32_D(D)&gt;
 HWY_API VFromD&lt;D&gt; ConvertTo(D di, VFromD&lt;RebindToFloat&lt;D&gt;&gt; v) {
-  return detail::FixConversionOverflow(di, v, ConvertInRangeTo(di, v));
+  const RebindToFloat&lt;decltype(di)&gt; df;
+  // See comment at the first occurrence of &quot;IfThenElse(overflow,&quot;.
+  const MFromD&lt;D&gt; overflow = RebindMask(di, Ge(v, Set(df, 2147483648.0f)));
+  return IfThenElse(overflow, Set(di, LimitsMax&lt;int32_t&gt;()),
+                    ConvertInRangeTo(di, v));
 }</code></pre>
<p>If we amend our original example with this tweak we will get the
following equivalent code:</p>
<pre class="c"><code>// $ cat bug.cc
#include &lt;stdint.h&gt;
#include &lt;string.h&gt;
#include &lt;emmintrin.h&gt;

__attribute__((noipa))
static void assert_eq_p(void * l, void * r) {
    char lb[16];
    char rb[16];

    __builtin_memcpy(lb, l, 16);
    __builtin_memcpy(rb, r, 16);

    if (__builtin_memcmp(lb, rb, 16) != 0) __builtin_trap();
}

#if 0
#include &lt;stdio.h&gt;
__attribute__((noipa))
static void d_i(const char * prefix, __m128i p) {
    uint64_t v[2];
    memcpy(v, &amp;p, 16);

    fprintf(stderr, &quot;%10s(i): %#016lx %#016lx\n&quot;, prefix, v[0], v[1]);
}
#endif

__attribute__((noipa))
static void assert_eq(__m128i l, __m128i r) { assert_eq_p(&amp;l, &amp;r); }

int main() {
  const __m128i su = _mm_set1_epi32(0x4f000000);
  const __m128  sf = _mm_castsi128_ps(su);

  const __m128  overflow_mask_f32 = _mm_cmpge_ps(sf, _mm_set1_ps(2147483648.0f));
  const __m128i overflow_mask = _mm_castps_si128(overflow_mask_f32);

  const __m128i conv = _mm_cvttps_epi32(sf);
  const __m128i yes = _mm_set1_epi32(INT32_MAX);

  const __m128i a = _mm_and_si128(overflow_mask, yes);
  const __m128i na = _mm_andnot_si128(overflow_mask, conv);

  const __m128i conv_masked = _mm_or_si128(a, na);

  const __m128i actual = _mm_cmpeq_epi32(conv_masked, _mm_set1_epi32(INT32_MAX));
  const __m128i expected = _mm_set1_epi32(-1);

  assert_eq(expected, actual);
}</code></pre>
<p>Here <code>_mm_and_si128()</code> and <code>_mm_andnot_si128()</code> are used to mask away
converted values larger than <code>2147483648.0f</code>.</p>
<p>If we look at the diagram it looks this way (I collapsed vector values
into <code>... x4</code> form as all of the values should be identical):</p>
<img src="https://trofi.github.io/posts.data.inline/317-gcc-simd-intrinsics-bug/fig-1.gv.svg" />
<p>Here <code>conv -&gt; na</code> green arrow shows where we throw away all the indefinite
values. They all get substituted for <code>yes = 0x7FFFffff x4</code> value.</p>
<p>Thus the program should finally be deterministic, right? Let’s check:</p>
<pre><code>$ gcc bug.cc -O0 -o a &amp;&amp; ./a

$ gcc bug.cc -O2 -o a &amp;&amp; ./a
Illegal instruction (core dumped)</code></pre>
<p>It does not. Only <code>-O0</code> case works (just like before). Looking at the
assembly again, just <code>-O2</code> this time:</p>
<pre class="asm"><code>; $ rizin ./a
; [0x004010a0]&gt; aaaa
; [0x004010a0]&gt; s main
; [0x00401040]&gt; pdf
            ; DATA XREF from entry0 @ 0x4010a8
            ;-- section..text:
/ int main(int argc, char **argv, char **envp);
|           ; arg uint64_t arg7 @ xmm0
|                 subq  $8, %rsp                             ; [13] -r-x section size 483 named .text
|                 movss data.00402004, %xmm1                 ; [0x402004:4]=0x4f000000
|                 movss data.00402008, %xmm3                 ; [0x402008:4]=0x7fffffff
|                 shufps $0, %xmm1, %xmm1
|                 movaps %xmm1, %xmm2
|                 cvttps2dq %xmm1, %xmm0
|                 shufps $0, %xmm3, %xmm3
|                 cmpleps %xmm1, %xmm2
|                 movdqa %xmm2, %xmm1
|                 andps %xmm3, %xmm2
|                 pandn %xmm0, %xmm1
|                 por   %xmm2, %xmm1
|                 pcmpeqd %xmm0, %xmm1                       ; arg7
|                 pcmpeqd %xmm0, %xmm0                       ; arg7
|                 callq sym.assert_eq_int64_t___vector_2___int64_t___vector_2 ; sym.assert_eq_int64_t___vector_2___int64_t___vector_2
|                 xorl  %eax, %eax
|                 addq  $8, %rsp
\                 retq</code></pre>
<p>At the first glance <code>cvttps2dq</code> instruction is present, thus <code>gcc</code> was
not able to completely constant fold it away. Thus it’s not immediately
obvious why it’s incorrect. Let’s have a look at the control flow
diagram reconstructed from the assembly:</p>
<img src="https://trofi.github.io/posts.data.inline/317-gcc-simd-intrinsics-bug/fig-2.gv.svg" />
<p>In practice <code>pcmpeqd %xmm0, %xmm1</code> instruction that was supposed to
implement <code>_mm_cmpeq_epi32(conv_masked, _mm_set1_epi32(INT32_MAX))</code> gets
<code>INT32_MAX</code> not as a constant (say, from <code>%xmm3</code>), but as a <code>%xmm0</code>
register assuming it already has the expected value. Red line shows
where the assumption is introduced and brown dotted line shows what it
is removing.</p>
<p>The optimizer was not able to constant-fold all the arithmetic operations,
but it was able to fold just enough to introduce the discrepancy between
assumed and actual value of <code>cvttps2dq</code>.</p>
<p>To remove this overly specific assumption <code>gcc-15</code> updated <code>fix()</code> code
not to assume a particular value on overflows using
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=b05288d1f1e4b632eddf8830b4369d4659f6c2ff">this patch</a>:</p>
<pre class="diff"><code>--- a/gcc/fold-const.cc
+++ b/gcc/fold-const.cc
@@ -2246,7 +2246,18 @@ fold_convert_const_int_from_real (enum tree_code code, tree type, const_tree arg
   if (! overflow)
     val = real_to_integer (&amp;r, &amp;overflow, TYPE_PRECISION (type));

-  t = force_fit_type (type, val, -1, overflow | TREE_OVERFLOW (arg1));
+  /* According to IEEE standard, for conversions from floating point to
+     integer. When a NaN or infinite operand cannot be represented in the
+     destination format and this cannot otherwise be indicated, the invalid
+     operation exception shall be signaled. When a numeric operand would
+     convert to an integer outside the range of the destination format, the
+     invalid operation exception shall be signaled if this situation cannot
+     otherwise be indicated.  */
+  if (!flag_trapping_math || !overflow)
+    t = force_fit_type (type, val, -1, overflow | TREE_OVERFLOW (arg1));
+  else
+    t = NULL_TREE;
+
   return t;
 }

diff --git a/gcc/simplify-rtx.cc b/gcc/simplify-rtx.cc
index 5caf1dfd957f..f6b4d73b593c 100644
--- a/gcc/simplify-rtx.cc
+++ b/gcc/simplify-rtx.cc
@@ -2256,14 +2256,25 @@ simplify_const_unary_operation (enum rtx_code code, machine_mode mode,
       switch (code)
 	{
 	case FIX:
+	  /* According to IEEE standard, for conversions from floating point to
+	     integer. When a NaN or infinite operand cannot be represented in
+	     the destination format and this cannot otherwise be indicated, the
+	     invalid operation exception shall be signaled. When a numeric
+	     operand would convert to an integer outside the range of the
+	     destination format, the invalid operation exception shall be
+	     signaled if this situation cannot otherwise be indicated.  */
 	  if (REAL_VALUE_ISNAN (*x))
-	    return const0_rtx;
+	    return flag_trapping_math ? NULL_RTX : const0_rtx;
+
+	  if (REAL_VALUE_ISINF (*x) &amp;&amp; flag_trapping_math)
+	    return NULL_RTX;

 	  /* Test against the signed upper bound.  */
 	  wmax = wi::max_value (width, SIGNED);
 	  real_from_integer (&amp;t, VOIDmode, wmax, SIGNED);
 	  if (real_less (&amp;t, x))
-	    return immed_wide_int_const (wmax, mode);
+	    return (flag_trapping_math
+		    ? NULL_RTX : immed_wide_int_const (wmax, mode));

 	  /* Test against the signed lower bound.  */
 	  wmin = wi::min_value (width, SIGNED);
@@ -2276,13 +2287,17 @@ simplify_const_unary_operation (enum rtx_code code, machine_mode mode,

 	case UNSIGNED_FIX:
 	  if (REAL_VALUE_ISNAN (*x) || REAL_VALUE_NEGATIVE (*x))
-	    return const0_rtx;
+	    return flag_trapping_math ? NULL_RTX : const0_rtx;
+
+	  if (REAL_VALUE_ISINF (*x) &amp;&amp; flag_trapping_math)
+	    return NULL_RTX;

 	  /* Test against the unsigned upper bound.  */
 	  wmax = wi::max_value (width, UNSIGNED);
 	  real_from_integer (&amp;t, VOIDmode, wmax, UNSIGNED);
 	  if (real_less (&amp;t, x))
-	    return immed_wide_int_const (wmax, mode);
+	    return (flag_trapping_math
+		    ? NULL_RTX : immed_wide_int_const (wmax, mode));

 	  return immed_wide_int_const (real_to_integer (x, &amp;fail, width),
 				       mode);</code></pre>
<p>It fixes both tree optimizations if <code>RTL</code> optimizations not to assume a
specific value on known overflows.</p>
<p>After the fix <code>gcc</code> generates something that passes the test at hand:</p>
<pre><code>$ g++ bug.cc -o bug -O2 &amp;&amp; ./bug</code></pre>
<p>And the <code>highway</code> test suite.</p>
<p>For completeness the generated code now looks like this:</p>
<pre class="asm"><code>; $ rizin ./a
; [0x004010a0]&gt; aaaa
; [0x004010a0]&gt; s main
; [0x00401040]&gt; pdf
            ; DATA XREF from entry0 @ 0x4010b8
            ;-- section..text:
/ int main(int argc, char **argv, char **envp);
|           ; arg uint64_t arg8 @ xmm1
|                 subq  $8, %rsp                             ; [13] -r-x section size 499 named .text
|                 movss data.00402004, %xmm0                 ; [0x402004:4]=0x4f000000
|                 shufps $0, %xmm0, %xmm0
|                 movaps %xmm0, %xmm2
|                 cmpleps %xmm0, %xmm2
|                 cvttps2dq %xmm0, %xmm0
|                 movdqa %xmm2, %xmm1
|                 pandn %xmm0, %xmm1
|                 movss data.00402008, %xmm0                 ; [0x402008:4]=0x7fffffff
|                 shufps $0, %xmm0, %xmm0
|                 andps %xmm0, %xmm2
|                 pcmpeqd %xmm0, %xmm0
|                 por   %xmm1, %xmm2
|                 pcmpeqd %xmm1, %xmm1                       ; arg8
|                 psrld $1, %xmm1
|                 pcmpeqd %xmm2, %xmm1                       ; arg8
|                 callq sym.assert_eq_int64_t___vector_2___int64_t___vector_2 ; sym.assert_eq_int64_t___vector_2___int64_t___vector_2
|                 xorl  %eax, %eax
|                 addq  $8, %rsp
\                 retq</code></pre>
<p>This code looks slightly closed to originally written <code>C</code> code: <code>%xmm2</code>
collects masked result of <code>cvttps2dq</code> and <code>%xmm1</code> contains <code>0x7FFFffff</code>
value.</p>
<h2 id="parting-words">Parting words</h2>
<p>While not as powerful as tree passes <code>RTL</code> passes are capable of folding
constants, propagating assumed values and removing dead code.</p>
<p><code>highway</code> uncovered an old <code>gcc</code> <a href="https://gcc.gnu.org/PR115161">bug</a> in
a set of <code>float-&gt;int</code> conversion <code>x86</code> intrinsics. This bug was not seen
as frequently until <code>gcc</code> implemented more constant folding cases for
intrinsics in <a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=f2449b55fb2d32">this change</a>.</p>
<p><code>gcc</code> still has a few places where it could constant-fold a lot more:</p>
<ul>
<li>handle <code>_mm_cvttps_epi32(constant)</code></li>
<li>eliminate redundant <code>movaps %xmm0, %xmm2; cmpleps %xmm0, %xmm2</code> and
below</li>
</ul>
<p>But <code>gcc</code> does not do it today.</p>
<p>If <code>gcc</code> thinks that some intrinsic returns a value that differs from
reality it’s very hard to reliably convince <code>gcc</code> to assume something
else. Sometimes it’s easier to use inline assembly to get the desired
result as a short term workaround.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 16 Jun 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/317-gcc-simd-intrinsics-bug.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>Three years on NixOS</title>
    <link>http://trofi.github.io/posts/316-three-years-on-nixos.html</link>
    <description><![CDATA[<p>This year I decided to shift yearly updates on my <code>NixOS</code> endeavours
(<a href="https://trofi.github.io/posts/290-two-years-on-nixos.html">2023 instance</a>). This time
the occasion is <a href="https://nixos.org/blog/announcements/2024/nixos-2405/"><code>NixOS 24.05 release</code></a>.</p>
<h2 id="system-maintenance">System maintenance</h2>
<p>Looking at the <code>git log</code> for <code>/etc/nixos</code> for the desktop system I see
the following things happening over the past year:</p>
<ul>
<li>follow <code>fonts.fonts</code> to <code>fonts.packages</code> rename (added in <a href="https://github.com/NixOS/nixpkgs/pull/244332">PR#244332</a>)</li>
<li>follow <code>pipewire</code> migration to <code>extraConfig</code> (added in
<a href="https://github.com/NixOS/nixpkgs/pull/282377">PR#282377</a>).</li>
<li>follow <code>programs.gnupg.agent.pinentryFlavor</code> to
<code>programs.gnupg.agent.pinentryPackage</code> migration (added in
<a href="https://github.com/NixOS/nixpkgs/pull/133542">PR#133542</a>).</li>
<li>follow the rename from <code>nix.unstable</code> to <code>nix.latest</code> (added in
<a href="https://github.com/NixOS/nixpkgs/pull/305951">PR#305951</a>).</li>
</ul>
<p>All four were trivial to tweak and did not cause much confusion.</p>
<p>Similar to previous year I did not have any problems related to package
build failures for any on <code>nixos-unstable</code>. Again, probably because I
tested <code>staging</code> time to time.</p>
<p>This time I had two non-trivial problems in upstream packages:</p>
<ul>
<li>problematic <code>firefox</code> update broke <code>meet</code> video streaming. It was
triggered by the use of <code>--with-system-libvpx</code> option in <code>nixpkgs</code>. That
was one of the cases where I had the luxury of bisecting the whole
system to pinpoint the bad component:
<a href="https://github.com/NixOS/nixpkgs/pull/283010#issuecomment-1925703583" class="uri">https://github.com/NixOS/nixpkgs/pull/283010#issuecomment-1925703583</a>.
Local revert until the fix was shipped was trivial.</li>
<li>problematic unstable <code>6.8</code> kernel upgrade caused kernel panic in
<code>eevdf</code> scheduler. Was fixed upstream in
<a href="https://lore.kernel.org/lkml/ZicOSiEWHJJcahi%2F@yujie-X299/t/" class="uri">https://lore.kernel.org/lkml/ZicOSiEWHJJcahi%2F@yujie-X299/t/</a> around
<code>6.9</code> kernel. The crashes were nasty as scheduler crash locks up the
machine and does not print anything when it happens. Luckily
<code>systemd</code> recovered crash log from <code>EFI</code>s <code>nvram</code> and it was clear
from the backtrace that it’s a bug related to scheduling kernel
subsystem.</li>
</ul>
<h2 id="community-support">Community support</h2>
<p><code>NixOS</code> community remains to be a friendly place that welcomes
newcomers, experiments and day-to-day maintenance work. This year
<code>NixOS Foundation</code> received some heat for how it governs some aspects of
the community. <code>NixOS Foundation</code> proposed a
<a href="https://discourse.nixos.org/t/nixos-foundation-board-giving-power-to-the-community/44552">few major changes</a>
on how it will operate in future.</p>
<p>The most important (and hardest organizationally) change I did was to
document and exercise the procedure of updating
<a href="https://trofi.github.io/posts/315-nixpkgs-bootstrap-files-update.html">bootstrap binaries</a> in
<code>nixpkgs</code>.</p>
<p>My fanciest contribution was
<a href="https://trofi.github.io/posts/309-listing-all-nixpkgs-packages.html">my failed attempt</a> at
listing “all” the package attributes available in <code>nixpkgs</code>. While I was
not able to list all the attributes initially I managed to derive about
60 fixes to <code>nixpkgs</code> (all linked in the article) to make future listing
smoother. Tl:DR; of the fixes is: dynamic typing is hard.</p>
<p>The most unusual <code>nixpkgs</code> contribution was to find
<a href="https://trofi.github.io/posts/292-nix-language-nondeterminism-example.html">the non-determinism</a>
in <code>nix expression language</code> itself. It’s not something I expected to
encounter in real code. Alas.</p>
<p>The trickiest from technical standpoint was the fix for
<a href="https://trofi.github.io/posts/293-mysterious-patchelf-linkage-bug.html">parallel strip breakage</a>.
<a href="https://trofi.github.io/posts/302-Ofast-and-ffast-math-non-local-effects.html"><code>-Ofast</code></a> and
<a href="https://trofi.github.io/posts/310-a-libpam-bug.html"><code>libpam</code></a> bugs were also fun.</p>
<p>The most satisfying was to
<a href="https://trofi.github.io/posts/298-unexpected-runtime-dependencies-in-nixpkgs.html">reduce the runtime closure</a>
for many packages that use <code>__FILE__</code> just for for debug messages.</p>
<p>Surprisingly I managed to get about 800 commits into <code>nixpkgs</code> this year.
About ~90 of them is fixes to get compatibility with <code>gcc-13</code>. About 60
are evaluation fixes mentioned above. About 400 of them are various
package version updates.</p>
<p>I still read some of Matrix channels but I mostly skim through
<a href="https://discourse.nixos.org/">discourse</a> as I have even less free time
than last year.</p>
<h2 id="home-server-experience">Home server experience</h2>
<p>I did not have to adapt anything for the past year. I switched from
<code>apache</code> to <code>nginx</code> as an <code>httpd</code> without any issues. And that’s about
it. Things Just Work.</p>
<h2 id="local-experiments">Local experiments</h2>
<p>As an experiment I gave <a href="https://hyprland.org/"><code>hyprland</code></a> a short try.
I had to switch back to <code>sway</code>. I had two issues with
<code>hyprland</code>: new applications are visibly changing layout a few times
before they settle on final window size (I could not get used to it) and
configuration language quirks (I frequently missed commas where empty
arguments are required).</p>
<p>I also did a bit of fresh <code>gcc</code> testing. This time frame also coincided
with <code>gcc-14</code> development and release cycle. <code>nixpkgs</code> ended up being a
reasonable vehicle to play with <code>gcc-14</code>. The
<a href="https://trofi.github.io/posts/311-gcc-14-bug-pile-4.html">last bug pile report</a> tells me that
I found about 50 <code>gcc</code> bugs and even fixed at least
<a href="https://trofi.github.io/posts/301-another-gcc-profiling-bug.html">one non-trivial one</a>.</p>
<h2 id="parting-words">Parting words</h2>
<p><code>NixOS</code> still works fine for me. I did not do as much as I managed to
last year. But looking back the list looks impressive.</p>
<p>Give it a go if you did not yet :)</p>]]></description>
    <pubDate>Sun, 02 Jun 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/316-three-years-on-nixos.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>nixpkgs bootstrap files update</title>
    <link>http://trofi.github.io/posts/315-nixpkgs-bootstrap-files-update.html</link>
    <description><![CDATA[<h2 id="tldr">Tl;DR</h2>
<p><code>nixpkgs</code> now has up to date <code>bootstrapFiles</code> at least for <code>i686-linux</code>
and <code>x86_64-linux</code>. Moreover we now have an easy procedure to update the
binaries! Instructions are hiding in
<a href="https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/bootstrap-files/README.md#how-to-request-the-bootstrap-seed-update"><code>maintainers/scripts/bootstrap-files/README.md</code></a>.
For example the
<a href="https://github.com/NixOS/nixpkgs/pull/288866">PR#288866</a> to update
<code>i686-unknown-linux-gnu</code> was generated as:</p>
<pre><code>$ maintainers/scripts/bootstrap-files/refresh-tarballs.bash \
    --commit \
    --targets=x86_64-unknown-linux-gnu
$ git push my-fork staging:bootstrapFiles-x86_64-unknown-linux-gnu-update</code></pre>
<p>This work paves the way for more frequent updates of the existing
bootstrap files and simplifies the procedure of introducing support for
new targets into <code>nixpkgs</code>.</p>
<p>As a nice side-effect <code>x86_64-linux</code> bootstrap does not depend on <code>i686</code>
<code>busybox</code> binary any more and uses <code>x86_64</code> binary instead:</p>
<img src="https://trofi.github.io/posts.data.inline/315-nixpkgs-bootstrap-files-update/fig-0.gv.svg" />
<p>This means that updating <code>i686-linux</code> bootstrap files alone does not
trigger the rebuild of <code>x86_64-linux</code> world any more.</p>
<h2 id="more-words">More words</h2>
<h3 id="intro">Intro</h3>
<p>About two years ago <a href="https://trofi.github.io/posts/240-nixpkgs-bootstrap-intro.html">I noticed</a>
that <code>nixpkgs</code> has quite old initial seed binaries used to bootstrap the
rest of the system.</p>
<p>Normally the version of bootstrap files does not matter as once bootstrap
finishes the original files are not referenced any more. There are a few
annoying exceptions that people stumbled from time to time. One of them
was stale <code>libgcc.so</code>.</p>
<p>Stale binaries also cause build breakages from time to time. One
example breakage is discussed in the
<a href="https://trofi.github.io/posts/275-nixpkgs-bootstrap-deep-dive.html">bootstrap deep dive</a> post,
another example is a <a href="https://github.com/NixOS/nixpkgs/pull/229898#issuecomment-1589179355">stale <code>gnumake</code></a>
breakage. There are a lot more. They usually get workarounds somewhere
else in <code>nixpkgs</code> but almost never in the bootstrap files as they are
harder to update.</p>
<p>These failures are not always easy to debug (or workaround). I
occasionally suggested updating the bootstrap binaries as I expected it
to be a trivial operation for people who did those initially.</p>
<p>I asked a few times on infra’s Matrix if bootstrap files could be
updated as part of a release preparation and did not get anywhere.</p>
<p>At some point Bernardo visited me in person and explained the details of
what it takes to upload the binaries and what the requirements for the
new binaries are nowadays. In essence there are two requirements:</p>
<ol type="1">
<li>The binaries should be built by <a href="https://hydra.nixos.org" class="uri">https://hydra.nixos.org</a> to make
sure that binaries come from a somewhat trusted location and others
can replicate the same binaries from source.</li>
<li>The binaries must be uploaded to <a href="https://tarballs.nixos.org" class="uri">https://tarballs.nixos.org</a> by
someone someone has the permissions to do it.</li>
</ol>
<p>Sounds trivial?</p>
<p>At some point I encountered complete failure of <code>i686-linux</code> bootstrap
on my file system due to
<a href="https://trofi.github.io/posts/297-32-bit-file-API-strikes-back.html">64-bit inode values</a> on my
<code>/nix/store</code>.</p>
<p>I filed an <a href="https://github.com/NixOS/nixpkgs/issues/253713">Issue#253713</a>
to request automated periodic bootstrap files updates. I also listed a
few examples where periodic refresh would fix the problems people
encounter hoping that somebody will consider it bad enough and upload
the binaries.</p>
<h3 id="a-light-in-the-tunnel">A light in the tunnel</h3>
<p>Alas just filing an issue did not magically fix things.</p>
<p>I noticed that recently <code>riscv64-linux</code> bootstrap files were updated in
<a href="https://github.com/NixOS/nixpkgs/pull/282517">PR#2826517</a> and I took it
as an opportunity to explore the mechanism and automate the whole PR
preparation as the first step.</p>
<p>The procedure looked trivial: you follow a few hydra links and put them
into the <code>.nix</code> file.</p>
<h3 id="annoying-details">Annoying details</h3>
<p>I hoped for a script to be 2-3 <code>curl</code> calls. But there are always those
pesky details that get in your way.</p>
<h4 id="job-names">Job names</h4>
<p>Some targets (like <code>risc-v</code> or <code>powerpc64</code>) don’t yet have a native
build support on <code>hydra</code> (lack of hardware). And yet we have bootstrap
files for those: they are cross-compiled.</p>
<p>Hydra job name and even job results format were different between native
and cross-builds:</p>
<ul>
<li>native targets used only <code>.dist</code> style builds</li>
<li>cross-targets had <code>.bootstrapTools</code> style builds</li>
</ul>
<p>Those were easy to fix by exposing builds unconditionally with
<a href="https://github.com/NixOS/nixpkgs/pull/284090">PR#284090</a>. And drop
unused <code>.dist</code> indirection with
<a href="https://github.com/NixOS/nixpkgs/pull/301639">PR#301639</a> suggested by
Alyssa.</p>
<h4 id="nixpkgs-file-inconsistency-darwin"><code>nixpkgs</code> file inconsistency (<code>darwin</code>)</h4>
<p>Once I had a glance at <code>darwin</code> bootstrap jobs I noticed it puts files
into slightly different location. I unified it with
<a href="https://github.com/NixOS/nixpkgs/pull/284628">PR#284628</a> hoping that
somebody else will finish the <code>darwin</code> part. And help did come from
<code>annalee</code> in <a href="https://github.com/NixOS/nixpkgs/pull/295557">PR#295557</a>.</p>
<h4 id="actual-regenerator">Actual regenerator</h4>
<p>Once enough things were in place I hacked up a shell script that fetches
needed files and generates <code>.nix</code> files with enough contents as
<a href="https://github.com/NixOS/nixpkgs/pull/284541">PR#284541</a>. The script
ended up being almost 300 lines long!</p>
<p>As a first test I tried it on <code>musl</code> targets as they were not using
the binaries from <code>tarballs.nixos.org</code> and that felt list an urgent issue.
The <a href="https://github.com/NixOS/nixpkgs/pull/285906">PR#285906</a> dealt with
<code>x86_64-unknown-linux-musl</code> bootstrap files.</p>
<h4 id="cross-case">cross-case</h4>
<p>Updating existing files is slightly easier than bringing it a completely
new set of binaries. How do you deal with those?</p>
<p>Having dealt with changes above I could finally answer that question
with some confidence:</p>
<ul>
<li>add a new target to <code>lib/systems/examples.nix</code>, make sure it can build
basic things like <code>pkgsCross.$target.hello</code></li>
<li>add <code>bootstrapFiles</code> build entry to
<code>pkgs/stdenv/linux/make-bootstrap-tools-cross.nix</code>, wait for <code>hydra</code>
to build binaries for you</li>
<li>add your new target to <code>maintainers/scripts/bootstrap-files/refresh-tarballs.bash</code>
your in <code>CROSS_TARGETS=()</code> list and run the script.</li>
<li>send a resulting PR requesting binaries upload as described in
<code>maintainers/scripts/bootstrap-files/README.md</code></li>
</ul>
<p><a href="https://github.com/NixOS/nixpkgs/pull/314823">PR#314823</a> should
document the same procedure in <code>nixpkgs</code>.</p>
<h2 id="parting-words">Parting words</h2>
<p>I managed to update bootstrap files for <code>i686-linux</code> and <code>x86_64-linux</code>!</p>
<p>It immediately got the following benefits:</p>
<ul>
<li>fixed <code>i686-linux</code> bootstrap on file systems with 64-bit inodes</li>
<li>untangled <code>x86_64-linux</code> bootstrap from <code>i686</code> <code>busybox</code></li>
<li>switched <code>musl</code> bootstrap files to <code>hydra</code>-built files hosted on
<code>tarballs.nixos.org</code>.</li>
<li>documented a way to introduce new target into <code>nixpkgs</code> via
cross-compiled bootstrap files.</li>
</ul>
<p>Next steps:</p>
<ul>
<li>update <code>aarch64-linux</code> bootstrap files (trivial)</li>
<li>update other cross-targets (trivial)</li>
<li>work with release engineering team to periodically update the binaries
on a defined cadence (moderate)</li>
</ul>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 26 May 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/315-nixpkgs-bootstrap-files-update.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>Zero Hydra Failures towards 24.05 NixOS release</title>
    <link>http://trofi.github.io/posts/314-Zero-Hydra-Failures-towards-24.05-NixOS-release.html</link>
    <description><![CDATA[<p>I somehow missed the beginning of <code>ZHF</code> phase
<a href="https://github.com/NixOS/nixpkgs/issues/309482">this release cycle</a>.</p>
<p>For those who don’t know <code>ZHF</code> (or Zero Hydra Failures) is the time when
most build failures are squashed before final <code>NixOS-24.05</code> release
(see <a href="https://github.com/NixOS/nixpkgs/issues/303285">full release schedule</a>).</p>
<p>To follow the tradition let’s fix one bug for <code>ZHF</code>.</p>
<p>I picked <a href="https://hydra.nixos.org/build/261188699"><code>miniupnpc</code></a> build
failure. Surprisingly it blocks about 60 packages!</p>
<p>The failure looks trivial:</p>
<pre><code>trying https://miniupnp.tuxfamily.org/files/miniupnpc-2.2.7.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:02:14 --:--:--     0
curl: (28) Failed to connect to miniupnp.tuxfamily.org port 443 after 134794 ms: Couldn't connect to server
Warning: Problem : timeout. Will retry in 1 seconds. 3 retries left.
  0     0    0     0    0     0      0      0 --:--:--  0:02:14 --:--:--     0
curl: (28) Failed to connect to miniupnp.tuxfamily.org port 443 after 134159 ms: Couldn't connect to server
Warning: Problem : timeout. Will retry in 2 seconds. 2 retries left.
  0     0    0     0    0     0      0      0 --:--:--  0:02:13 --:--:--     0
curl: (28) Failed to connect to miniupnp.tuxfamily.org port 443 after 133158 ms: Couldn't connect to server
Warning: Problem : timeout. Will retry in 4 seconds. 1 retries left.
  0     0    0     0    0     0      0      0 --:--:--  0:02:15 --:--:--     0
curl: (28) Failed to connect to miniupnp.tuxfamily.org port 443 after 135253 ms: Couldn't connect to server
error: cannot download miniupnpc-2.2.7.tar.gz from any mirror</code></pre>
<p>Upstream source is unavailable and <code>curl</code> times out fetching it.</p>
<p>With great suggestions from others to switch the package to <code>github</code>
source fetch I came up with <a href="https://github.com/NixOS/nixpkgs/pull/314510">PR#314510</a>:</p>
<pre class="diff"><code>--- a/pkgs/tools/networking/miniupnpc/default.nix
+++ b/pkgs/tools/networking/miniupnpc/default.nix
@@ -1,6 +1,6 @@
 { lib
 , stdenv
-, fetchurl
+, fetchFromGitHub
 , cmake
 }:

@@ -8,14 +8,15 @@ stdenv.mkDerivation rec {
   pname = &quot;miniupnpc&quot;;
   version = &quot;2.2.7&quot;;

-  src = fetchurl {
-    urls = [
-      &quot;https://miniupnp.tuxfamily.org/files/${pname}-${version}.tar.gz&quot;
-      &quot;http://miniupnp.free.fr/files/${pname}-${version}.tar.gz&quot;
-    ];
-    sha256 = &quot;sha256-sMOicFaED9DskyilqbrD3F4OxtLoczNJz1d7CqHnCsE=&quot;;
+  src = fetchFromGitHub {
+    owner = &quot;miniupnp&quot;;
+    repo = &quot;miniupnp&quot;;
+    rev = &quot;miniupnpc_${lib.replaceStrings [&quot;.&quot;] [&quot;_&quot;] version}&quot;;
+    hash = &quot;sha256-cIijY1NcdF169tibfB13845UT9ZoJ/CZ+XLES9ctWTY=&quot;;
   };

+  sourceRoot = &quot;${src.name}/miniupnpc&quot;;
+
   nativeBuildInputs = [ cmake ];

   doCheck = !stdenv.isFreeBSD;</code></pre>
<p>The fix is slightly larger than the average one-liner as we have to
fiddle with the source-fetching helper. But otherwise it’s simple.</p>
<p>Testing:</p>
<pre><code>$ nix build -f. miniupnpc</code></pre>
<p>All good!</p>
<h2 id="parting-words">Parting words</h2>
<p>As <code>24.05</code> branch was already created the fix will have to be backported
to it by adding a specific label. One of the maintainers will have to do
it.</p>
<p>Otherwise contributing to <code>ZHF</code> is very easy. Give it a try!</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 25 May 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/314-Zero-Hydra-Failures-towards-24.05-NixOS-release.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>highway debugging example</title>
    <link>http://trofi.github.io/posts/313-highway-debugging-example.html</link>
    <description><![CDATA[<p><a href="https://github.com/google/highway">highway</a> test suite is a great
stress test for <code>gcc</code>’s vectorization and SIMD intrinsics code
generators:</p>
<ul>
<li>at compile time <code>highway</code> instantiates all the vector extensions your CPU could support</li>
<li>at runtime it runs the tests on all of the supported extensions against
various vector sizes</li>
</ul>
<p>It cover many corner cases of what could possibly go wrong with vectored
forms of various operations. A few past examples are:
<a href="https://gcc.gnu.org/PR110274"><code>PR110274</code></a>,
<a href="https://gcc.gnu.org/PR110880"><code>PR110880</code></a>,
<a href="https://gcc.gnu.org/PR111048"><code>PR111048</code></a>,
<a href="https://gcc.gnu.org/PR111051"><code>PR111051</code></a>,
<a href="https://gcc.gnu.org/PR115115"><code>PR115115</code></a>.</p>
<p>While <code>highway</code> tests are quite small they are somewhat tricky to
extract into self-contained examples. In this post I’ll write down a few
hacks I usually use to simplify this task.</p>
<h2 id="an-example">An example</h2>
<p>Today test suite failed at me on today’s <code>gcc-15</code> build against
<code>nixpkgs</code> as:</p>
<pre><code> 1146 - HwyReverseTestGroup/HwyReverseTest.TestAllReverseLaneBytes/EMU128  # GetParam() = 2305843009213693952 (Subprocess aborted)
 1151 - HwyReverseTestGroup/HwyReverseTest.TestAllReverseBits/EMU128  # GetParam() = 2305843009213693952 (Subprocess aborted)
 1186 - HwyShuffle4TestGroup/HwyShuffle4Test.TestAllPer4LaneBlockShuffle/EMU128  # GetParam() = 2305843009213693952 (Subprocess aborted)</code></pre>
<p><code>TestAllReverseLaneBytes</code> is the test function. <code>EMU128</code> is an
(emulated) CPU target: the code does not use compiler intrinsics and
uses loops over scalar operations to emulate <code>SIMD</code>.</p>
<h2 id="check-latest-git">Check latest <code>git</code></h2>
<p><code>highway</code> is actively maintained. In case the failure is caused by a
<code>highway</code> bug (and not by a faulty compiler) chances are that it’s
already fixed in latest version. Worth trying it first:</p>
<pre><code># get the build time depends into the development shell
$ nix develop -f ~/n libhwy

$$ git clone https://github.com/google/highway.git
$$ cd highway

$$ mkdir build
$$ cd build
$$ cmake ..
$$ make -j $(nproc) &amp;&amp; make test
...
1146 - HwyReverseTestGroup/HwyReverseTest.TestAllReverseLaneBytes/EMU128  # GetParam() = 2305843009213693952 (Subprocess aborted)
1151 - HwyReverseTestGroup/HwyReverseTest.TestAllReverseBits/EMU128  # GetParam() = 2305843009213693952 (Subprocess aborted)
1186 - HwyShuffle4TestGroup/HwyShuffle4Test.TestAllPer4LaneBlockShuffle/EMU128  # GetParam() = 2305843009213693952 (Subprocess aborted)
</code></pre>
<p>The bug was still there!</p>
<h2 id="enable-single-simplest-target">Enable single (simplest) target</h2>
<p><code>highway</code> uses heavy <code>C++</code> template code and various iterator macros to
compile the library for each supported CPU extension <code>highway</code> knows
about. This increases build times and complicated debugging via code
tweaking as code has to compile for all active targets, not just one.</p>
<p>I disabled all targets except the problematic one. In our case the
problematic target is <code>EMU128</code>. Thus the local change to leave <code>EMU128</code>
as the only available option is:</p>
<pre class="diff"><code>--- a/hwy/detect_targets.h
+++ b/hwy/detect_targets.h
@@ -29,7 +29,7 @@
 // #define HWY_BASELINE_TARGETS (HWY_SSE4 | HWY_SCALAR)

 // Uncomment to override the default blocklist:
-// #define HWY_BROKEN_TARGETS HWY_AVX3
+#define HWY_BROKEN_TARGETS (HWY_AVX2 | HWY_SSE4 | HWY_SSE2 | HWY_SSSE3 | HWY_SSE4 | HWY_AVX3_SPR | HWY_AVX3_ZEN4 | HWY_AVX3)

 // Uncomment to definitely avoid generating those target(s):
 // #define HWY_DISABLED_TARGETS HWY_SSE4</code></pre>
<p>Here I disabled anything that build system reports as supported.</p>
<p>Before the change I had <code>Compiled HWY_TARGETS:   AVX3_SPR AVX3_ZEN4 AVX3 AVX2 SSE4 SSSE3 SSE2</code>
in this output:</p>
<pre><code>Config: emu128:0 scalar:0 static:0 all_attain:0 is_test:0
Compiled HWY_TARGETS:   AVX3_SPR AVX3_ZEN4 AVX3 AVX2 SSE4 SSSE3 SSE2
HWY_ATTAINABLE_TARGETS: AVX3_SPR AVX3_ZEN4 AVX3 AVX2 SSE4 SSSE3 SSE2 EMU128
HWY_BASELINE_TARGETS:   SSE2 EMU128
HWY_STATIC_TARGET:      SSE2
HWY_BROKEN_TARGETS:     Unknown
HWY_DISABLED_TARGETS:
Current CPU supports:   AVX2 SSE4 SSSE3 SSE2 EMU128 SCALAR</code></pre>
<p>After the change I get <code>Compiled HWY_TARGETS:   EMU128</code> in this output:</p>
<pre><code>Config: emu128:0 scalar:0 static:0 all_attain:0 is_test:0
Compiled HWY_TARGETS:   EMU128
HWY_ATTAINABLE_TARGETS: EMU128
HWY_BASELINE_TARGETS:   SSE2 EMU128
HWY_STATIC_TARGET:      EMU128
HWY_BROKEN_TARGETS:     AVX3_SPR AVX3_ZEN4 AVX3 AVX2 SSE4 SSSE3 SSE2
HWY_DISABLED_TARGETS:
Current CPU supports:   AVX2 SSE4 SSSE3 SSE2 EMU128 SCALAR</code></pre>
<p>Leaving a single compiled target speeds the builds a few times up.</p>
<p>Then I picked the specific binary that implements failing test. In this
case it was <code>tests/reverse_test</code>:</p>
<pre><code>$ make -j$(nproc) &amp;&amp; ./tests/reverse_test
...
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from HwyReverseTestGroup/HwyReverseTest
[ RUN      ] HwyReverseTestGroup/HwyReverseTest.TestAllReverseLaneBytes/EMU128


u16x4 expect [0+ -&gt;]:
  0xD49E,0x049E,0x0137,0x69D3,
u16x4 actual [0+ -&gt;]:
  0xFF9E,0xFF9E,0x0137,0xFFD3,
Abort at reverse_test.cc:162: EMU128, u16x4 lane 0 mismatch:
  expected '0xD49E', got '0xFF9E'.

Aborted (core dumped)</code></pre>
<p>Here we can see that instead of expected <code>0xD49E,0x049E,0x0137,0x69D3</code>
output our library did <code>0xFF9E,0xFF9E,0x0137,0xFFD3</code>.</p>
<h2 id="shrink-the-test">Shrink the test</h2>
<p>The rest reduction is usually test-specific, but some of the hacks can
be applied to many tests. In this case I kept only one failing test:</p>
<pre class="diff"><code>--- a/hwy/tests/reverse_test.cc
+++ b/hwy/tests/reverse_test.cc
@@ -293,13 +295,7 @@ HWY_AFTER_NAMESPACE();

 namespace hwy {
 HWY_BEFORE_TEST(HwyReverseTest);
-HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverse);
-HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverse2);
-HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverse4);
-HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverse8);
 HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverseLaneBytes);
-HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverseBits);
-HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverseBlocks);
 HWY_AFTER_TEST();
 }  // namespace hwy</code></pre>
<p>The test was still failing (sometimes it’s not the case when mere
presence of unrelated code changes the inlining and vectorization
decisions).</p>
<p>Then I shrunk the cases down to 16-bit element sizes by inlining a
<code>ForUI163264</code> definition:</p>
<pre class="diff"><code>--- a/hwy/tests/reverse_test.cc
+++ b/hwy/tests/reverse_test.cc
@@ -248,7 +249,7 @@ HWY_NOINLINE void TestAllReverse8() {
 }

 HWY_NOINLINE void TestAllReverseLaneBytes() {
-  ForUI163264(ForPartialVectors&lt;TestReverseLaneBytes&gt;());
+  ForPartialVectors&lt;TestReverseLaneBytes&gt;()(uint16_t());
 }</code></pre>
<p>Then I removed all the other unrelated test asserts from the
<code>hwy/tests/reverse_test.cc</code> file.</p>
<p>Then I inlined obvious template parameters right into local test class.</p>
<p>Then I extracted random generated data used in the failing vectors (using
<code>printf()</code> statements) and inlined values into <code>.cc</code> file. Sometimes
I had to sprinkle <code>__attribute__((noipa))</code> attributes on local functions
to inhibit too eager constant folding.</p>
<h2 id="gdb-hints"><code>gdb</code> hints</h2>
<p>To explore generated code in <code>gdb</code> I explored <code>hwy::N_&lt;target&gt;::</code>
namespace as:</p>
<pre><code>$ gdb tests/reverse_test
(gdb) disassemble hwy::N_EMU128::TestAllReverseLaneBytes
...
   &lt;+113&gt;:   mov    0x3d190(%rip),%rax        # 0x4dc68
   &lt;+120&gt;:   mov    $0xffffd49e,%esi
   &lt;+125&gt;:   xor    %edx,%edx
   &lt;+127&gt;:   mov    $0x8,%edi
   &lt;+132&gt;:   mov    %rax,0x0(%rbp)
   &lt;+136&gt;:   mov    %si,(%r12)

   &lt;+141&gt;:   movzwl 0x2(%rbp),%eax
   &lt;+145&gt;:   xor    %esi,%esi
   &lt;+147&gt;:   rol    $0x8,%ax
   &lt;+151&gt;:   mov    %ax,0x2(%r12)

   &lt;+157&gt;:   movzwl 0x4(%rbp),%eax
   &lt;+161&gt;:   rol    $0x8,%ax
   &lt;+165&gt;:   mov    %ax,0x4(%r12)

   &lt;+171&gt;:   movzwl 0x6(%rbp),%eax
   &lt;+175&gt;:   rol    $0x8,%ax
   &lt;+179&gt;:   mov    %ax,0x6(%r12)

   &lt;+185&gt;:   mov    0x0(%rbp),%rax
   &lt;+189&gt;:   movq   %rax,%xmm0
   &lt;+194&gt;:   movdqa %xmm0,%xmm1
   &lt;+198&gt;:   psllw  $0x8,%xmm0
   &lt;+203&gt;:   psraw  $0x8,%xmm1
   &lt;+208&gt;:   por    %xmm0,%xmm1
   &lt;+212&gt;:   movq   %xmm1,0x8(%rsp)</code></pre>
<p>Here I was lucky! I immediately spotted the bug. We see both:</p>
<ul>
<li>16-bit wide move/rotate/move: <code>movzwl / rol / mov</code> (looks correct)</li>
<li>and 128-bit wide move/rotate/move: <code>movq / psllw / psraw / por / movq</code></li>
</ul>
<p>The rotate part is broken here: it should have been logical <code>psrlw</code>
shift, not arithmetic (sign-preserving) <code>psraw</code> shift.</p>
<p>At this point my test looked this way:</p>
<pre class="cpp"><code>HWY_NOINLINE void TestAllReverseLaneBytes() {
    const CappedTag&lt;uint16_t, 4, 0&gt; d;

    const size_t N = Lanes(d);
    fprintf(stderr, &quot;N = %zu\n&quot;, N);
    auto in = AllocateAligned&lt;uint16_t&gt;(N);
    auto expected = AllocateAligned&lt;uint16_t&gt;(N);

    fprintf(stderr, &quot;iter\n&quot;);
        in[0] = 0x9ed4u;
        in[1] = 0x049eu;
        in[2] = 0x0137u;
        in[3] = 0x69d3u;
        expected[0] = ReverseBytesOfValue(in[0]);
        expected[1] = ReverseBytesOfValue(in[1]);
        expected[2] = ReverseBytesOfValue(in[2]);
        expected[3] = ReverseBytesOfValue(in[3]);

    const auto v = Load(d, in.get());
    HWY_ASSERT_VEC_EQ(d, expected.get(), ReverseLaneBytes(v));
}</code></pre>
<p>I looked at the <code>ReverseLaneBytes()</code> implementation. It had two parts.</p>
<p>The first part was generic for all targets:</p>
<pre class="cpp"><code>// from hwy/ops/generic_ops-inl.h
template &lt;class V, HWY_IF_T_SIZE_V(V, 2)&gt;
HWY_API V ReverseLaneBytes(V v) {
  const DFromV&lt;V&gt; d;
  const Repartition&lt;uint8_t, decltype(d)&gt; du8;
  return BitCast(d, Reverse2(du8, BitCast(du8, v)));
}</code></pre>
<p>And the second part was <code>EMU128</code>-specific:</p>
<pre class="cpp"><code>// from hwy/ops/emu128-inl.h
template &lt;class D&gt;
HWY_API VFromD&lt;D&gt; Reverse2(D d, VFromD&lt;D&gt; v) {
  VFromD&lt;D&gt; ret;
  for (size_t i = 0; i &lt; MaxLanes(d); i += 2) {
    ret.raw[i + 0] = v.raw[i + 1];
    ret.raw[i + 1] = v.raw[i + 0];
  }
  return ret;
}</code></pre>
<p>I inlined the above definitions into the test and got this:</p>
<pre class="cpp"><code>// $ cat hwy/tests/reverse_test.cc
#include &lt;stddef.h&gt;

#undef HWY_TARGET_INCLUDE
#define HWY_TARGET_INCLUDE &quot;tests/reverse_test.cc&quot;
#include &quot;hwy/foreach_target.h&quot;  // IWYU pragma: keep
#include &quot;hwy/highway.h&quot;
#include &quot;hwy/tests/test_util-inl.h&quot;

HWY_BEFORE_NAMESPACE();
namespace hwy {
namespace HWY_NAMESPACE {

template &lt;class D&gt;
__attribute__((noipa))
static VFromD&lt;D&gt; Reverse2_(D d, VFromD&lt;D&gt; v) {
  VFromD&lt;D&gt; ret;
  for (size_t i = 0; i &lt; MaxLanes(d); i += 2) {
    ret.raw[i + 0] = v.raw[i + 1];
    ret.raw[i + 1] = v.raw[i + 0];
  }
  return ret;
}

HWY_NOINLINE void TestAllReverseLaneBytes() {
    const CappedTag&lt;uint16_t, 4, 0&gt; d;

    const size_t N = Lanes(d); // 4
    auto in = AllocateAligned&lt;uint16_t&gt;(N);
    auto expected = AllocateAligned&lt;uint16_t&gt;(N);

    in[0] = 0x9ed4u;
    in[1] = 0x049eu;
    in[2] = 0x0137u;
    in[3] = 0x69d3u;
    expected[0] = 0xd49eu;
    expected[1] = 0x9e04u;
    expected[2] = 0x3701u;
    expected[3] = 0xd369u;

    const auto v = Load(d, in.get());
    const Repartition&lt;uint8_t, decltype(d)&gt; du8;
    const auto r = BitCast(d, Reverse2_(du8, BitCast(du8, v)));
    HWY_ASSERT_VEC_EQ(d, expected.get(), r);
}

// NOLINTNEXTLINE(google-readability-namespace-comments)
}  // namespace HWY_NAMESPACE
}  // namespace hwy
HWY_AFTER_NAMESPACE();

#if HWY_ONCE

namespace hwy {
HWY_BEFORE_TEST(HwyReverseTest);
HWY_EXPORT_AND_TEST_P(HwyReverseTest, TestAllReverseLaneBytes);
HWY_AFTER_TEST();
}  // namespace hwy

#endif</code></pre>
<h2 id="make-sure-its-an-optimizer">Make sure it’s an optimizer</h2>
<p>Adding <code>#pragma GCC optimize(0)</code> to the beginning of the file makes the
bug to go away. It’s a good hint that it’s a compiler bug: the test looks
obviously correct (not much hidden code is left in the templates).</p>
<p>But the only way to make sure is to finish the reduction down to a
self-contained example. We will need it anyway to report upstream.</p>
<h2 id="final-result">Final result</h2>
<p>After a few manual extra inlines and simplifications I got this
self-contained example:</p>
<pre class="c"><code>// $ cat bug.c
typedef unsigned char u8;

__attribute__((noipa))
static void fill_src(u8 * src) {
    src[0] = 0x00; src[1] = 0xff;
}

__attribute__((noipa))
static void assert_dst(const u8 * dst) {
    if (dst[0] != 0xff) __builtin_trap();
    if (dst[1] != 0x00) __builtin_trap();
}

int main() {
    u8 src[8] __attribute__((aligned(16))) = { 0 };
    u8 dst[8] __attribute__((aligned(16))) = { 0 };

    // place 0x00 into src[0] and 0xFF into src[1]
    fill_src(src);

    // swap bytes:
    // place 0xFF into dst[0], 0x00 into dst[1]
    for (unsigned long i = 0; i &lt; 8; i += 2) {
        dst[i + 0] = src[i + 1];
        dst[i + 1] = src[i + 0];
    }

    // make sure bytes swapped
    assert_dst(dst);
}</code></pre>
<p>Triggering:</p>
<pre><code>$ gcc bug.c -o a -O1 &amp;&amp; ./a
$ gcc bug.c -o a -O2 &amp;&amp; ./a
Illegal instruction (core dumped)</code></pre>
<h2 id="upstream-report">Upstream report</h2>
<p>I reported the bug as <a href="https://gcc.gnu.org/PR115146"><code>PR115146</code></a>.
Bisecting <code>gcc</code> pointed me to this
<a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=a71f90c5a7ae29">“vector shift” change</a>.</p>
<p>This change looks very close to the culprit as the code explicitly picks
the “arithmetic” flavour of shift instruction (should be “logical”
instead).</p>
<p>By now the original change author already provided a test patch in the
report! So quick!</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 18 May 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/313-highway-debugging-example.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>the sagemath saga</title>
    <link>http://trofi.github.io/posts/312-the-sagemath-saga.html</link>
    <description><![CDATA[<p>It’s a story of me was
<a href="https://fosstodon.org/@sheerluck@misskey.io/112372289317724185">nerd sniped</a>
by <code>@sheerluck@misskey.io</code> with <a href="https://gcc.gnu.org/PR114872"><code>PR114872</code></a>.
I spent this week having fun with a rare kind of bug: <code>gcc</code> was suspected
to have a bug that causes <code>sagemath</code> to crash with <code>SIGSEGV</code> on certain
inputs.</p>
<p>Ideally <code>sage</code> should not <code>SIGSEGV</code> on problematic inputs and should
instead print reasonable backtraces. At least printing a nicer error
message should not be hard, should it?</p>
<h2 id="the-symptom">The symptom</h2>
<p>The report said that a simple session caused <code>sage</code> tool from <code>sagemath</code>
package to <code>SIGSEGV</code>:</p>
<pre><code>$ sage
sage: libgap.AbelianGroup(0,0,0)

...
Segmentation fault (core dumped)</code></pre>
<p><code>sage</code> is an <code>ipython</code> <code>REPL</code> with a bunch of bindings for math
libraries like <a href="https://www.gap-system.org/"><code>GAP</code></a>.</p>
<p>It is said that the bug happens only when <code>sagemath</code> is built against
<code>python-3.12</code> while <code>python-3.11</code> would work without the problems.</p>
<p>Normally it would be a strong hint of a <code>sagemath</code> bug. But the reporter
suspected it’s a <code>gcc</code> problem as building <code>sage</code> with <code>-O1</code> made the
bug go away. Thus the bug is at least dependent on generated code and is
likely not just a logic bug.</p>
<p><strong>Quick quiz: where do you think the bug lies?</strong> In <code>gcc</code>, <code>sagemath</code> or
somewhere else? And while at it: what is the cause of the bug?
Use-after-free, use of uninitialized data, logic bug or maybe something
else?</p>
<h2 id="the-first-reproducer-attempt-nixpkgs-package">The first reproducer attempt: <code>nixpkgs</code> package</h2>
<p>I tried to reproduce the bug by building <code>sage</code> from <code>nxipkgs</code>. As
expected <code>sage</code> built against <code>python-3.11</code> worked just fine.
<code>python-3.11</code> is a <code>nixpkgs</code> default. I tried to flip the default to
<code>python-3.12</code> with this local change:</p>
<pre class="diff"><code>--- a/pkgs/top-level/all-packages.nix
+++ b/pkgs/top-level/all-packages.nix
@@ -17505 +17505 @@ with pkgs;
-  python3 = python311;
+  python3 = python312;
@@ -17509 +17509 @@ with pkgs;
-  python3Packages = dontRecurseIntoAttrs python311Packages;
+  python3Packages = dontRecurseIntoAttrs python312Packages;</code></pre>
<p>Building it did not work as is:</p>
<pre><code>$ nix build -f. sage
...


error: ipython-genutils-0.2.0 not supported for interpreter python3.12


error: nose-1.3.7 not supported for interpreter python3.12


&gt; src/gmpy2_convert_gmp.c:464:76: error: ‘PyLongObject’ {aka ‘struct _longobject’} has no member named ‘ob_digit’
&gt;   464 |                    sizeof(templong-&gt;ob_digit[0])*8 - PyLong_SHIFT, templong-&gt;ob_digit);
&gt;       |                                                                            ^~
&gt; error: command '/nix/store/8mjb3ziimfi3rki71q4s0916xkm4cm5p-gcc-wrapper-13.2.0/bin/gcc' failed with exit code 1
&gt; /nix/store/558iw5j1bk7z6wrg8cp96q2rx03jqj1v-stdenv-linux/setup: line 1579: pop_var_context: head of shell_variables not a function context
For full logs, run 'nix log /nix/store/g7mf3p2cylf74j3ypq2ifcspx61isb36-python3.12-gmpy2-2.1.2.drv'.


&gt; ModuleNotFoundError: No module named 'distutils'
&gt; configure: error: Python explicitly requested and python headers were not found
For full logs, run 'nix log /nix/store/xyd63v16k1krblcfypfn5bs6jqbj9lwd-audit-3.1.2.drv'.</code></pre>
<p>The above told me that some dependencies (at least in <code>nixpkgs</code>) are not
ready for <code>python-3.12</code>:</p>
<ul>
<li><code>nose</code> and <code>ipython-genutils</code> are explicitly disabled for <code>python-3.12</code>
in <code>nixpkgs</code></li>
<li><code>gmpy2</code> and <code>audit</code> just fail to build for API changes in <code>python</code>
itself</li>
</ul>
<p><code>gmpy2</code> specifically has an open
<a href="https://github.com/aleaxit/gmpy/issues/446">upstream report</a>
to add support for <code>python-3.12</code>. This means distributions have to apply
not yet upstreamed changes to get earlier <code>python-3.12</code> support.</p>
<p>All the above means that porting fixes are sometimes not trivial and
might vary from a distribution to distribution if they want to get
<code>python-3.12</code> tested earlier.</p>
<p>I did not feel confident to patch at least 4 <code>python</code> libraries to get
<code>sagemath</code> to build. I switched the tactic to reproduce the bug on the
system reporters were using and to explore it there.</p>
<p>Original reporter used Arch Linux to reproduce the failure. Another user
<a href="https://github.com/sagemath/sage/pull/36407#issuecomment-2093792864">reported</a>
that <code>Gentoo</code> users also seen the similar problem.</p>
<h2 id="the-second-reproducer-attempt-gentoo-package-from-sage-on-gentoo">The second reproducer attempt: <code>Gentoo</code> package from <code>::sage-on-gentoo</code></h2>
<p>I had a <code>Gentoo</code> chroot lying around for <code>nix</code> packaging testing. I
tried to reproduce <code>sagemath</code> failure there by using
<a href="https://github.com/cschwan/sage-on-gentoo"><code>::sage-on-gentoo</code></a> overlay.
Unfortunately neither latest release of <code>sagemath-standard-10.3</code> nor
<code>sagemath-standard-9999</code> <code>git</code> versions did build for me as is. I filed
2 bugs:</p>
<ul>
<li><a href="https://github.com/cschwan/sage-on-gentoo/issues/783">cschwan/sage-on-gentoo#783</a>: <code>=sci-mathematics/sagemath-standard-10.3</code> fails as: <code>AttributeError: Can't pickle local object '_prepare_extension_detection.&lt;locals&gt;.&lt;lambda&gt;'</code></li>
<li><a href="https://github.com/cschwan/sage-on-gentoo/issues/784">cschwan/sage-on-gentoo#784</a>: <code>=sci-mathematics/sage_setup-9999</code> fails as: <code>tar (child): sage-setup-*.tar.gz: Cannot open: No such file or directory</code></li>
</ul>
<p>I hoped that <code>pickle</code> failure was fixed in latest <code>git</code> and I could avoid
the second pickle bug by using it.</p>
<p>At least the <code>tar</code> failure looked like a packaging issue:</p>
<pre><code># ACCEPT_KEYWORDS='**' USE=text emerge -av1 sagemath-standard
...
tar (child): sage-setup-*.tar.gz: Cannot open: No such file or directory
tar (child): Error is not recoverable: exiting now
tar: Child returned status 2
tar: Error is not recoverable: exiting now
 * ERROR: sci-mathematics/sage_setup-9999::sage-on-gentoo failed (unpack phase):
...</code></pre>
<p>François Bissey promptly
<a href="https://github.com/cschwan/sage-on-gentoo/commit/cc57aef4021bf673d02d20bd483b2708f9336f63">fixed</a>
<code>tar</code> failure! Unfortunately that did not fix the <code>pickle</code> bug in
<code>sagemath-standard-9999</code> for me and it started failing just like <code>sagemath-standard-10.3</code>:</p>
<pre><code># emerge -av1 sagemath-standard
...
AttributeError: Can't pickle local object '_prepare_extension_detection.&lt;locals&gt;.&lt;lambda&gt;'</code></pre>
<p>Surprisingly not everyone saw that problem and some people were able to
build the packages just fine. Day later I explored where
<code>_prepare_extension_detection</code> comes from and I was able to find a
<a href="https://github.com/cschwan/sage-on-gentoo/issues/783#issuecomment-2095500118">surprising workaround</a>:
I needed to uninstall completely unrelated <code>scikit-build-core</code> <code>python</code>
package that happened to be present in my system. <code>scikit-build-core</code> is
not used by <code>sagemath-standard</code> neither directly nor indirectly. But
somehow <a href="https://github.com/scikit-build/scikit-build-core/blob/f6ed5a28fc85e621b03d984011d17def888ee0db/src/scikit_build_core/setuptools/build_cmake.py#L183">it’s code</a> injected
the extra attributes to <code>cmake</code>-based package builds and failed the build.</p>
<p>At least I finally got <code>sage</code> tool in my <code>$PATH</code>!</p>
<p>I took me two evenings to get <code>sagemath</code> to build. At last I could look
at the crash now.</p>
<h2 id="exploring-the-crash">Exploring the crash</h2>
<p><code>sage</code> is a python program. It has a default handler that executes <code>gdb</code>
at crash time. Unfortunately it does not work on <code>Gentoo</code>:</p>
<pre><code>Attaching gdb to process id 1023.
Traceback (most recent call last):
  File &quot;/usr/lib/python-exec/python3.12/cysignals-CSI&quot;, line 225, in &lt;module&gt;
    main(args)
  File &quot;/usr/lib/python-exec/python3.12/cysignals-CSI&quot;, line 174, in main
    trace = run_gdb(args.pid, not args.nocolor)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;/usr/lib/python-exec/python3.12/cysignals-CSI&quot;, line 98, in run_gdb
    stdout, stderr = cmd.communicate(gdb_commands(pid, color))
                                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;/usr/lib/python-exec/python3.12/cysignals-CSI&quot;, line 71, in gdb_commands
    with open(script, 'rb') as f:
         ^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python-exec/python3.12/../share/cysignals/cysignals-CSI-helper.py'</code></pre>
<p>Missing <code>cysignals-CSI-helper.py</code> file at the expected location is a
case of <a href="https://bugs.gentoo.org/927767">packaging error</a>. <code>Gentoo</code> uses
very unusual path to python launcher and breaks too simplistic
<code>argv[0]+"/../share"</code> path construction used in <code>cysignals</code>. Adding a
few more <code>"../../../"</code> should do as a workaround.</p>
<p>I was able to workaround <code>gdb</code> launch failure by attaching <code>gdb</code> to
already running process before pasting the problematic command into the
<code>REPL</code>:</p>
<pre><code># gdb --quiet -p `pgrep sage-ipython`
Attaching to process 1060
[New LWP 1082]
[New LWP 1083]
[Thread debugging using libthread_db enabled]
Using host libthread_db library &quot;/lib64/libthread_db.so.1&quot;.
0x00007fedba181256 in epoll_wait (epfd=5, events=events@entry=0x7fed57127590, maxevents=maxevents@entry=2,
    timeout=timeout@entry=500) at ../sysdeps/unix/sysv/linux/epoll_wait.c:30
30        return SYSCALL_CANCEL (epoll_wait, epfd, events, maxevents, timeout);</code></pre>
<p>To get more details from the crash site I ran <code>continue</code> in <code>gdb</code> and
typed the trigger expression: <code>libgap.AbelianGroup(0,0,0)</code>.</p>
<p>To my surprise I got not a <code>SIGSEGV</code> but a <code>SIGABRT</code>:</p>
<pre><code>(gdb) continue
Continuing.
[Thread 0x7fed56e006c0 (LWP 1083) exited]
[Detaching after vfork from child process 1105]

Thread 1 &quot;sage-ipython&quot; received signal SIGABRT, Aborted.
0x00007fedba0b97a7 in __GI_kill () at ../sysdeps/unix/syscall-template.S:120
120     T_PSEUDO (SYSCALL_SYMBOL, SYSCALL_NAME, SYSCALL_NARGS)</code></pre>
<p>The default signal handler for <code>SIGABRT</code> normally crashes the process
and generates a core dump. <code>sagemath</code> installs <code>SIGABRT</code> handler (via
<code>cysignals</code> library) to report and recover from some errors like argument
type errors in the interpreter session.</p>
<p><code>gdb</code> always intercepts <code>SIGABRT</code> before executing the handler. Thus I
needed to explicitly continue execution in <code>gdb</code> session:</p>
<pre><code>(gdb) continue
Continuing.

Thread 1 &quot;sage-ipython&quot; received signal SIGSEGV, Segmentation fault.
0x00007fed5d13956f in _Py_IsImmortal (op=0x0) at /usr/include/python3.12/object.h:242
242         return _Py_CAST(PY_INT32_T, op-&gt;ob_refcnt) &lt; 0;</code></pre>
<p>Yay! I got the <code>SIGSEGV</code>!</p>
<p>A simple <code>NULL</code> dereference. What could be easier to debug? Just check
where it was set to <code>NULL</code> and do something about it, right?</p>
<p>First thing I wondered about is how does <code>SIGABRT</code> handler look like? It
was an idle curiosity. I expected to see some simple global variable tweak.
Alas what I found was <a href="https://github.com/sagemath/cysignals/blob/035ed1605a8741a6f265a55cc682b26ea6e5d1c2/src/cysignals/implementation.c#L279"><code>longjmp()</code></a>:</p>
<pre class="c"><code>static void cysigs_interrupt_handler(int sig)
{
...
    if (cysigs.sig_on_count &gt; 0)
    {
        if (!cysigs.block_sigint &amp;&amp; !PARI_SIGINT_block &amp;&amp; !custom_signal_is_blocked())
        {
            /* Raise an exception so Python can see it */
            do_raise_exception(sig);

            /* Jump back to sig_on() (the first one if there is a stack) */
            siglongjmp(trampoline, sig);
        }
    }
...
}</code></pre>
<p>One has to be
<a href="https://trofi.github.io/posts/188-grub-0.97-and-gcc-4.9.html">very</a>
<a href="https://trofi.github.io/posts/205-stack-protection-on-mips64.html">careful</a>
with <code>setjmp()</code> / <code>longjmp()</code>.</p>
<h2 id="the-example-setjmp-longjmp-failure-mode">The example <code>setjmp()</code> / <code>longjmp()</code> failure mode</h2>
<p>The <code>C</code> standard has a few constructs that don’t mix well with <code>C</code>
abstract machine. <code>setjmp()</code> / <code>longjmp()</code> is one of those. It’s a
frequent source of subtle and latent bugs.</p>
<p>In theory <code>setjmp()</code> / <code>longjmp()</code> is a portable way to save and restore
the execution at a certain point in the program. It’s a non-local
<code>goto</code>. It is very powerful: you can jump from a few nested calls with
a <code>longjmp()</code> back to where you called <code>setjmp()</code>. In practice one has
to be very careful to get something that works most of the time.</p>
<p>Let’s look at a contrived and <strong>intentionally buggy</strong> example:</p>
<pre class="c"><code>// $ cat a.c
#include &lt;assert.h&gt;
#include &lt;setjmp.h&gt;
#include &lt;stdio.h&gt;

static jmp_buf jb;

__attribute__((noipa)) static int foo(void) {
    int a = 0;
    int r = setjmp(jb); // r = 0 initially, r = 1 after longjmp()

    a += 1; // gets executed twice, but the compiler does not know it!

    if (!r) longjmp(jb, 1); // execute it just once

    return a;
}

int main(void) {
    int r = foo();
    printf(&quot;foo() = %d (expect 2)\n&quot;, r);
    assert(r == 2);
    return 0;
}</code></pre>
<p>Here we execute <code>foo()</code> function once and use <code>longjmp()</code> to return to
<code>setjmp()</code> (also just once). As a result we should execute <code>a += 1;</code>
statement twice:</p>
<ul>
<li>once during natural <code>foo()</code> execution</li>
<li>once via “hidden” jump via <code>longjmp()</code> call to <code>setjmp()</code>
location.</li>
</ul>
<p>I’m using <code>__attribute__((noipa))</code> to keep <code>foo()</code> from being inlined
into <code>main()</code> to ease <code>foo()</code>’s code exploration.</p>
<p>The test against the unoptimized build confirms that <code>a += 1</code> gets
executed twice:</p>
<pre><code>$ gcc a.c -o a -O0 &amp;&amp; ./a
foo() = 2 (expect 2)</code></pre>
<p>Assembly output shows the expected code:</p>
<pre class="asm"><code>; $ gdb ./a
; (gdb) disassemble foo
Dump of assembler code for function foo:
   &lt;+0&gt;:     push   %rbp
   &lt;+1&gt;:     mov    %rsp,%rbp
   &lt;+4&gt;:     sub    $0x10,%rsp
   &lt;+8&gt;:     movl   $0x0,-0x8(%rbp)
   &lt;+15&gt;:    lea    0x2ed4(%rip),%rax        # 0x404040 &lt;jb&gt;
   &lt;+22&gt;:    mov    %rax,%rdi
   &lt;+25&gt;:    call   0x401050 &lt;_setjmp@plt&gt; // setjmp();
   &lt;+30&gt;:    mov    %eax,-0x4(%rbp)
   &lt;+33&gt;:    addl   $0x1,-0x8(%rbp)        // a += 1;
   &lt;+37&gt;:    cmpl   $0x0,-0x4(%rbp)        // if (!r) ...
   &lt;+41&gt;:    jne    0x401195 &lt;foo+63&gt;
   &lt;+43&gt;:    mov    $0x1,%esi
   &lt;+48&gt;:    lea    0x2eb3(%rip),%rax        # 0x404040 &lt;jb&gt;
   &lt;+55&gt;:    mov    %rax,%rdi
   &lt;+58&gt;:    call   0x401060 &lt;longjmp@plt&gt; // longjmp();
   &lt;+63&gt;:    mov    -0x8(%rbp),%eax
   &lt;+66&gt;:    leave
   &lt;+67&gt;:    ret                           // return a;</code></pre>
<p>It’s a linear code with a single explicit branch to skip <code>longjmp()</code> call.
Looks easy?</p>
<p>Now let’s optimize it:</p>
<pre><code>$ gcc a.c -o a -O2 &amp;&amp; ./a
foo() = 1 (expect 2)
a: a.c:21: main: Assertion `r == 2' failed.
Aborted (core dumped)</code></pre>
<p>Whoops. <code>foo() = 1</code> output suggests that <code>a</code> was incremented only once.
Let’s look at the generated code to get the idea of what happened:</p>
<pre class="asm"><code>; $ gdb ./a
; (gdb) disassemble foo
Dump of assembler code for function foo:
   &lt;+0&gt;:     sub    $0x8,%rsp
   &lt;+4&gt;:     lea    0x2e85(%rip),%rdi        # 0x404040 &lt;jb&gt;
   &lt;+11&gt;:    call   0x401040 &lt;_setjmp@plt&gt;
   &lt;+16&gt;:    test   %eax,%eax              // if (!r) ...
   &lt;+18&gt;:    je     0x4011ce &lt;foo+30&gt;
   &lt;+20&gt;:    mov    $0x1,%eax              // a = 1;
   &lt;+25&gt;:    add    $0x8,%rsp
   &lt;+29&gt;:    ret                           // return a
   &lt;+30&gt;:    mov    $0x1,%esi
   &lt;+35&gt;:    lea    0x2e66(%rip),%rdi        # 0x404040 &lt;jb&gt;
   &lt;+42&gt;:    call   0x401060 &lt;__longjmp_chk@plt&gt;</code></pre>
<p>Nothing prevented <code>gcc</code> from transforming the original <code>foo()</code> into this
simpler form:</p>
<pre class="c"><code>// ...
__attribute__((noipa)) static int foo(void) {
    int r = setjmp(jb); // r = 0 initially, r = 1 after longjmp()
    if (!r) longjmp(jb, 1);
    int a = 1;          // moved `int a = 0;` here and merged into `a += 1;`.
    return a;
}
// ...</code></pre>
<p>Here <code>gcc</code> did quite a bit of code motion:</p>
<ul>
<li><code>gcc</code> moved <code>int a = 0;</code> assignment and an <code>a += 1;</code> increment after
both <code>setjmp()</code> and <code>longjmp()</code>.</li>
<li><code>gcc</code> merged <code>int a = 0;</code>, <code>a += 1;</code> and <code>return a;</code> into a single <code>return 1;</code>.</li>
</ul>
<p><strong>Note that <code>gcc</code> moved all <code>a</code> manipulation across <code>setjmp()</code> and even
<code>longjmp()</code> boundaries</strong>. <code>setjmp()</code> is expected to be
just a C function for <code>gcc</code>. <code>gcc</code> does not have to have any special
knowledge about control flow semantics of those functions. Thus this
optimization transformation while completely breaking the original
code’s intent is legitimate and expected.</p>
<p><code>man 3 setjmp</code> covers exactly this case in <code>CAVEATS</code> section as:</p>
<pre><code>CAVEATS
  The compiler may optimize variables into registers, and longjmp() may
  restore the values of other registers in addition to the stack pointer
  and program counter. Consequently, the values of automatic variables
  are unspecified after a call to longjmp() if they meet all the
  following criteria:
  •  they are local to the function that made the corresponding setjmp()
     call;
  •  their values are changed between the calls to setjmp() and
     longjmp(); and
  •  they are not declared as volatile.</code></pre>
<p>It’s up to code author to adhere to these <code>CAVEATS</code>. Would be nice if
the compiler would be able to warn about the violations in simpler cases
though: <code>-flto</code> could expose large chunk of the control flow graph to
the analyzer.</p>
<p>Back to our broken example. One of the possible fixes here is to declare
<code>a</code> as <code>volatile</code>:</p>
<pre class="diff"><code>--- a.c.buggy   2024-05-09 23:14:54.383811692 +0100
+++ a.c 2024-05-10 00:03:53.694219636 +0100
@@ -7,3 +7,3 @@
 __attribute__((noipa)) static int foo(void) {
-    int a = 0;
+    volatile int a = 0;
     int r = setjmp(jb); // r = 0 initially, r = 1 after longjmp()</code></pre>
<p>That would give us the following (correct) example:</p>
<pre class="c"><code>#include &lt;assert.h&gt;
#include &lt;setjmp.h&gt;
#include &lt;stdio.h&gt;

static jmp_buf jb;

__attribute__((noipa)) static int foo(void) {
    volatile int a = 0;
    int r = setjmp(jb); // r = 0 initially, r = 1 after longjmp()

    a += 1; // gets executed twice

    if (!r) longjmp(jb, 1);

    return a;
}

int main(void) {
    int r = foo();
    printf(&quot;foo() = %d (expect 2)\n&quot;, r);
    assert(r == 2);
}</code></pre>
<p>Running:</p>
<pre><code>$ gcc a.c -o a -O0 &amp;&amp; ./a
foo() = 2 (expect 2)

$ gcc a.c -o a -O2 &amp;&amp; ./a
foo() = 2 (expect 2)</code></pre>
<p>The execution confirms that both optimizations run the increment twice
as intended. This is the generated code for completeness:</p>
<pre class="asm"><code>; gdb ./a
; (gdb) disassemble foo
Dump of assembler code for function foo:
   &lt;+0&gt;:     sub    $0x18,%rsp
   &lt;+4&gt;:     lea    0x2e85(%rip),%rdi        # 0x404040 &lt;jb&gt;
   &lt;+11&gt;:    movl   $0x0,0xc(%rsp)           // int a = 0;
   &lt;+19&gt;:    call   0x401040 &lt;_setjmp@plt&gt;
   &lt;+24&gt;:    mov    %eax,%edx
   &lt;+26&gt;:    mov    0xc(%rsp),%eax           // load a from stack
   &lt;+30&gt;:    add    $0x1,%eax                // a += 1;
   &lt;+33&gt;:    mov    %eax,0xc(%rsp)           // store a on stack
   &lt;+37&gt;:    test   %edx,%edx
   &lt;+39&gt;:    je     0x4011e2 &lt;foo+50&gt;
   &lt;+41&gt;:    mov    0xc(%rsp),%eax           // load a from stack
   &lt;+45&gt;:    add    $0x18,%rsp
   &lt;+49&gt;:    ret                             // return
   &lt;+50&gt;:    mov    $0x1,%esi
   &lt;+55&gt;:    lea    0x2e52(%rip),%rdi        # 0x404040 &lt;jb&gt;
   &lt;+62&gt;:    call   0x401060 &lt;__longjmp_chk@plt&gt;</code></pre>
<p>Note that use of <code>volatile</code> in <code>setjmp()</code> / <code>longjmp()</code> effectively
inhibits completely reasonable compiler optimizations just to make loads
and stores in generated code to match the order written in <code>C</code> source
code for a given function.</p>
<p>I wonder if adding <code>volatile</code> is enough for more heavyweight
optimizations like <code>-flto</code> that enable even more code movement, constant
propagation and stack reuse. The time will tell.</p>
<h2 id="sagemath-use-of-setjmp-longjmp"><code>sagemath</code> use of <code>setjmp()</code> / <code>longjmp()</code></h2>
<p>After I noticed <code>setjmp()</code> / <code>longjmp()</code> use in <code>sagemath</code> I wondered how
many <code>volatile</code> keywords it has in the code where those were used.</p>
<p>To my surprise it had none. That was a good hint in a sense that it
looked like the problem we are dealing with. From that point I was
reasonably sure it’s an application bug and not a <code>gcc</code> bug.</p>
<p>Still, having the concrete corruption evidence would help to clear any
doubts and would help the reporter to craft a fix for <code>sagemath</code>.</p>
<p>The backtrace claimed that the crash happens in
<code>__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__</code>
function:</p>
<pre><code>(gdb) continue
Continuing.

Thread 1 &quot;sage-ipython&quot; received signal SIGSEGV, Segmentation fault.
0x00007feb544b756f in _Py_IsImmortal (op=0x0) at /usr/include/python3.12/object.h:242
242         return _Py_CAST(PY_INT32_T, op-&gt;ob_refcnt) &lt; 0;
(gdb) bt
#0  0x00007feb544b756f in _Py_IsImmortal (op=0x0) at /usr/include/python3.12/object.h:242
#1  Py_DECREF (op=0x0) at /usr/include/python3.12/object.h:700
#2  Py_XDECREF (op=0x0) at /usr/include/python3.12/object.h:798
#3  __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__ (
    __pyx_v_self=__pyx_v_self@entry=0x7feb4e274f40,
    __pyx_v_args=__pyx_v_args@entry=(&lt;sage.rings.integer.Integer at remote 0x7feb533456e0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd8c0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd620&gt;))
    at /usr/src/debug/sci-mathematics/sagemath-standard-10.3/sagemath-standard-10.3-python3_12/build/cythonized/sage/libs/gap/element.c:26535
...</code></pre>
<p><code>"__pyx_"</code> prefix suggests it’s a function generated by
<a href="https://cython.org/"><code>cython</code></a>, a python-style DSL for writing <code>C</code> part
of code to create bindings for <code>C</code> libraries to be used in <code>python</code>
libraries. In this case <code>sagemath</code> created bindings for <code>libgap</code>
discrete algebra library.</p>
<p>The <code>cython</code> code for a function we a <code>SIGSEGV</code> in looked
<a href="https://github.com/sagemath/sage/blob/744939e037a67193e730d7205e612e2d58197fca/src/sage/libs/gap/element.pyx#L2504">this way</a>:</p>
<pre class="python"><code>cdef class GapElement_Function(GapElement):
    # ...
    def __call__(self, *args):
    # ...
        cdef Obj result = NULL
        cdef Obj arg_list
        cdef int n = len(args)

        if n &gt; 0 and n &lt;= 3:
            libgap = self.parent()
            a = [x if isinstance(x, GapElement) else libgap(x) for x in args]

        try:
            sig_GAP_Enter()
            sig_on()
            if n == 0:
                result = GAP_CallFunc0Args(self.value)
            elif n == 1:
                result = GAP_CallFunc1Args(self.value,
                                           (&lt;GapElement&gt;a[0]).value)
            elif n == 2:
                result = GAP_CallFunc2Args(self.value,
                                           (&lt;GapElement&gt;a[0]).value,
                                           (&lt;GapElement&gt;a[1]).value)
            elif n == 3:
                result = GAP_CallFunc3Args(self.value,
                                           (&lt;GapElement&gt;a[0]).value,
                                           (&lt;GapElement&gt;a[1]).value,
                                           (&lt;GapElement&gt;a[2]).value)
            else:
                arg_list = make_gap_list(args)
                result = GAP_CallFuncList(self.value, arg_list)
            sig_off()
        finally:
            GAP_Leave()
        if result == NULL:
            # We called a procedure that does not return anything
            return None
        return make_any_gap_element(self.parent(), result)</code></pre>
<p>Looks very straightforward. No <code>setjmp()</code> in sight yet, or is there?.</p>
<p>WARNING: you are about to scroll through A Lot Of Code. You might want
to skip the bulk it and return later The build system produces
<code>element.c</code> with this contents:</p>
<pre class="c"><code>#define sig_GAP_Enter() {int t = GAP_Enter(); if (!t) sig_error();}
#define GAP_Enter() GAP_Error_Setjmp(); GAP_EnterStack()
#define GAP_Error_Setjmp() \
    (GAP_unlikely(GAP_Error_Prejmp_(__FILE__, __LINE__)) \
     || GAP_Error_Postjmp_(_setjmp(*GAP_GetReadJmpError())))
// ...
static PyObject *__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__(struct __pyx_obj_4sage_4libs_3gap_7element_GapElement_Function *__pyx_v_self, PyObject *__pyx_v_args) {
  Obj __pyx_v_result;
  Obj __pyx_v_arg_list;
  int __pyx_v_n;
  PyObject *__pyx_v_libgap = NULL;
  PyObject *__pyx_v_a = NULL;
  PyObject *__pyx_8genexpr3__pyx_v_x = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  Obj __pyx_t_11;
  int __pyx_t_12;
  char const *__pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext(&quot;__call__&quot;, 1);

  /* &quot;sage/libs/gap/element.pyx&quot;:2504
 *             hello from the shell
 *         &quot;&quot;&quot;
 *         cdef Obj result = NULL             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *         cdef Obj arg_list
 *         cdef int n = len(args)
 */
  __pyx_v_result = NULL;

  /* &quot;sage/libs/gap/element.pyx&quot;:2506
 *         cdef Obj result = NULL
 *         cdef Obj arg_list
 *         cdef int n = len(args)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 * 
 *         if n &gt; 0 and n &lt;= 3:
 */
  __pyx_t_1 = __Pyx_PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2506, __pyx_L1_error)
  __pyx_v_n = __pyx_t_1;

  /* &quot;sage/libs/gap/element.pyx&quot;:2508
 *         cdef int n = len(args)
 * 
 *         if n &gt; 0 and n &lt;= 3:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             libgap = self.parent()
 *             a = [x if isinstance(x, GapElement) else libgap(x) for x in args]
 */
  __pyx_t_3 = (__pyx_v_n &gt; 0);
  if (__pyx_t_3) {
  } else {
    __pyx_t_2 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = (__pyx_v_n &lt;= 3);
  __pyx_t_2 = __pyx_t_3;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_2) {

    /* &quot;sage/libs/gap/element.pyx&quot;:2509
 * 
 *         if n &gt; 0 and n &lt;= 3:
 *             libgap = self.parent()             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             a = [x if isinstance(x, GapElement) else libgap(x) for x in args]
 * 
 */
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_parent); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2509, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    __pyx_t_7 = 0;
    #if CYTHON_UNPACK_METHODS
    if (likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_7 = 1;
      }
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_6, NULL};
      __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+1-__pyx_t_7, 0+__pyx_t_7);
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2509, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __pyx_v_libgap = __pyx_t_4;
    __pyx_t_4 = 0;

    /* &quot;sage/libs/gap/element.pyx&quot;:2510
 *         if n &gt; 0 and n &lt;= 3:
 *             libgap = self.parent()
 *             a = [x if isinstance(x, GapElement) else libgap(x) for x in args]             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 * 
 *         try:
 */
    { /* enter inner scope */
      __pyx_t_4 = PyList_New(0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2510, __pyx_L8_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = __pyx_v_args; __Pyx_INCREF(__pyx_t_5);
      __pyx_t_1 = 0;
      for (;;) {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_5);
          #if !CYTHON_ASSUME_SAFE_MACROS
          if (unlikely((__pyx_temp &lt; 0))) __PYX_ERR(0, 2510, __pyx_L8_error)
          #endif
          if (__pyx_t_1 &gt;= __pyx_temp) break;
        }
        #if CYTHON_ASSUME_SAFE_MACROS &amp;&amp; !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_1); __Pyx_INCREF(__pyx_t_6); __pyx_t_1++; if (unlikely((0 &lt; 0))) __PYX_ERR(0, 2510, __pyx_L8_error)
        #else
        __pyx_t_6 = __Pyx_PySequence_ITEM(__pyx_t_5, __pyx_t_1); __pyx_t_1++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2510, __pyx_L8_error)
        __Pyx_GOTREF(__pyx_t_6);
        #endif
        __Pyx_XDECREF_SET(__pyx_8genexpr3__pyx_v_x, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_2 = __Pyx_TypeCheck(__pyx_8genexpr3__pyx_v_x, __pyx_ptype_4sage_4libs_3gap_7element_GapElement); 
        if (__pyx_t_2) {
          __Pyx_INCREF(__pyx_8genexpr3__pyx_v_x);
          __pyx_t_6 = __pyx_8genexpr3__pyx_v_x;
        } else {
          __Pyx_INCREF(__pyx_v_libgap);
          __pyx_t_9 = __pyx_v_libgap; __pyx_t_10 = NULL;
          __pyx_t_7 = 0;
          #if CYTHON_UNPACK_METHODS
          if (unlikely(PyMethod_Check(__pyx_t_9))) {
            __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_9);
            if (likely(__pyx_t_10)) {
              PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
              __Pyx_INCREF(__pyx_t_10);
              __Pyx_INCREF(function);
              __Pyx_DECREF_SET(__pyx_t_9, function);
              __pyx_t_7 = 1;
            }
          }
          #endif
          {
            PyObject *__pyx_callargs[2] = {__pyx_t_10, __pyx_8genexpr3__pyx_v_x};
            __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+1-__pyx_t_7, 1+__pyx_t_7);
            __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
            if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2510, __pyx_L8_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          }
          __pyx_t_6 = __pyx_t_8;
          __pyx_t_8 = 0;
        }
        if (unlikely(__Pyx_ListComp_Append(__pyx_t_4, (PyObject*)__pyx_t_6))) __PYX_ERR(0, 2510, __pyx_L8_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_8genexpr3__pyx_v_x); __pyx_8genexpr3__pyx_v_x = 0;
      goto __pyx_L12_exit_scope;
      __pyx_L8_error:;
      __Pyx_XDECREF(__pyx_8genexpr3__pyx_v_x); __pyx_8genexpr3__pyx_v_x = 0;
      goto __pyx_L1_error;
      __pyx_L12_exit_scope:;
    } /* exit inner scope */
    __pyx_v_a = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* &quot;sage/libs/gap/element.pyx&quot;:2508
 *         cdef int n = len(args)
 * 
 *         if n &gt; 0 and n &lt;= 3:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             libgap = self.parent()
 *             a = [x if isinstance(x, GapElement) else libgap(x) for x in args]
 */
  }

  /* &quot;sage/libs/gap/element.pyx&quot;:2512
 *             a = [x if isinstance(x, GapElement) else libgap(x) for x in args]
 * 
 *         try:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             sig_GAP_Enter()
 *             sig_on()
 */
  /*try:*/ {

    /* &quot;sage/libs/gap/element.pyx&quot;:2513
 * 
 *         try:
 *             sig_GAP_Enter()             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             sig_on()
 *             if n == 0:
 */
    sig_GAP_Enter();

    /* &quot;sage/libs/gap/element.pyx&quot;:2514
 *         try:
 *             sig_GAP_Enter()
 *             sig_on()             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             if n == 0:
 *                 result = GAP_CallFunc0Args(self.value)
 */
    __pyx_t_7 = sig_on(); if (unlikely(__pyx_t_7 == ((int)0))) __PYX_ERR(0, 2514, __pyx_L14_error)

    /* &quot;sage/libs/gap/element.pyx&quot;:2515
 *             sig_GAP_Enter()
 *             sig_on()
 *             if n == 0:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                 result = GAP_CallFunc0Args(self.value)
 *             elif n == 1:
 */
    switch (__pyx_v_n) {
      case 0:

      /* &quot;sage/libs/gap/element.pyx&quot;:2516
 *             sig_on()
 *             if n == 0:
 *                 result = GAP_CallFunc0Args(self.value)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             elif n == 1:
 *                 result = GAP_CallFunc1Args(self.value,
 */
      __pyx_v_result = GAP_CallFunc0Args(__pyx_v_self-&gt;__pyx_base.value);

      /* &quot;sage/libs/gap/element.pyx&quot;:2515
 *             sig_GAP_Enter()
 *             sig_on()
 *             if n == 0:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                 result = GAP_CallFunc0Args(self.value)
 *             elif n == 1:
 */
      break;
      case 1:

      /* &quot;sage/libs/gap/element.pyx&quot;:2519
 *             elif n == 1:
 *                 result = GAP_CallFunc1Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             elif n == 2:
 *                 result = GAP_CallFunc2Args(self.value,
 */
      if (unlikely(!__pyx_v_a)) { __Pyx_RaiseUnboundLocalError(&quot;a&quot;); __PYX_ERR(0, 2519, __pyx_L14_error) }
      __pyx_t_4 = __Pyx_GetItemInt_List(__pyx_v_a, 0, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2519, __pyx_L14_error)
      __Pyx_GOTREF(__pyx_t_4);

      /* &quot;sage/libs/gap/element.pyx&quot;:2518
 *                 result = GAP_CallFunc0Args(self.value)
 *             elif n == 1:
 *                 result = GAP_CallFunc1Args(self.value,             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                                            (&lt;GapElement&gt;a[0]).value)
 *             elif n == 2:
 */
      __pyx_v_result = GAP_CallFunc1Args(__pyx_v_self-&gt;__pyx_base.value, ((struct __pyx_obj_4sage_4libs_3gap_7element_GapElement *)__pyx_t_4)-&gt;value);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* &quot;sage/libs/gap/element.pyx&quot;:2517
 *             if n == 0:
 *                 result = GAP_CallFunc0Args(self.value)
 *             elif n == 1:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                 result = GAP_CallFunc1Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value)
 */
      break;
      case 2:

      /* &quot;sage/libs/gap/element.pyx&quot;:2522
 *             elif n == 2:
 *                 result = GAP_CallFunc2Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value,             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                                            (&lt;GapElement&gt;a[1]).value)
 *             elif n == 3:
 */
      if (unlikely(!__pyx_v_a)) { __Pyx_RaiseUnboundLocalError(&quot;a&quot;); __PYX_ERR(0, 2522, __pyx_L14_error) }
      __pyx_t_4 = __Pyx_GetItemInt_List(__pyx_v_a, 0, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2522, __pyx_L14_error)
      __Pyx_GOTREF(__pyx_t_4);

      /* &quot;sage/libs/gap/element.pyx&quot;:2523
 *                 result = GAP_CallFunc2Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value,
 *                                            (&lt;GapElement&gt;a[1]).value)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             elif n == 3:
 *                 result = GAP_CallFunc3Args(self.value,
 */
      if (unlikely(!__pyx_v_a)) { __Pyx_RaiseUnboundLocalError(&quot;a&quot;); __PYX_ERR(0, 2523, __pyx_L14_error) }
      __pyx_t_5 = __Pyx_GetItemInt_List(__pyx_v_a, 1, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2523, __pyx_L14_error)
      __Pyx_GOTREF(__pyx_t_5);

      /* &quot;sage/libs/gap/element.pyx&quot;:2521
 *                                            (&lt;GapElement&gt;a[0]).value)
 *             elif n == 2:
 *                 result = GAP_CallFunc2Args(self.value,             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                                            (&lt;GapElement&gt;a[0]).value,
 *                                            (&lt;GapElement&gt;a[1]).value)
 */
      __pyx_v_result = GAP_CallFunc2Args(__pyx_v_self-&gt;__pyx_base.value, ((struct __pyx_obj_4sage_4libs_3gap_7element_GapElement *)__pyx_t_4)-&gt;value, ((struct __pyx_obj_4sage_4libs_3gap_7element_GapElement *)__pyx_t_5)-&gt;value);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* &quot;sage/libs/gap/element.pyx&quot;:2520
 *                 result = GAP_CallFunc1Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value)
 *             elif n == 2:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                 result = GAP_CallFunc2Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value,
 */
      break;
      case 3:

      /* &quot;sage/libs/gap/element.pyx&quot;:2526
 *             elif n == 3:
 *                 result = GAP_CallFunc3Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value,             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                                            (&lt;GapElement&gt;a[1]).value,
 *                                            (&lt;GapElement&gt;a[2]).value)
 */
      if (unlikely(!__pyx_v_a)) { __Pyx_RaiseUnboundLocalError(&quot;a&quot;); __PYX_ERR(0, 2526, __pyx_L14_error) }
      __pyx_t_5 = __Pyx_GetItemInt_List(__pyx_v_a, 0, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2526, __pyx_L14_error)
      __Pyx_GOTREF(__pyx_t_5);

      /* &quot;sage/libs/gap/element.pyx&quot;:2527
 *                 result = GAP_CallFunc3Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value,
 *                                            (&lt;GapElement&gt;a[1]).value,             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                                            (&lt;GapElement&gt;a[2]).value)
 *             else:
 */
      if (unlikely(!__pyx_v_a)) { __Pyx_RaiseUnboundLocalError(&quot;a&quot;); __PYX_ERR(0, 2527, __pyx_L14_error) }
      __pyx_t_4 = __Pyx_GetItemInt_List(__pyx_v_a, 1, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2527, __pyx_L14_error)
      __Pyx_GOTREF(__pyx_t_4);

      /* &quot;sage/libs/gap/element.pyx&quot;:2528
 *                                            (&lt;GapElement&gt;a[0]).value,
 *                                            (&lt;GapElement&gt;a[1]).value,
 *                                            (&lt;GapElement&gt;a[2]).value)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             else:
 *                 arg_list = make_gap_list(args)
 */
      if (unlikely(!__pyx_v_a)) { __Pyx_RaiseUnboundLocalError(&quot;a&quot;); __PYX_ERR(0, 2528, __pyx_L14_error) }
      __pyx_t_6 = __Pyx_GetItemInt_List(__pyx_v_a, 2, long, 1, __Pyx_PyInt_From_long, 1, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2528, __pyx_L14_error)
      __Pyx_GOTREF(__pyx_t_6);

      /* &quot;sage/libs/gap/element.pyx&quot;:2525
 *                                            (&lt;GapElement&gt;a[1]).value)
 *             elif n == 3:
 *                 result = GAP_CallFunc3Args(self.value,             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                                            (&lt;GapElement&gt;a[0]).value,
 *                                            (&lt;GapElement&gt;a[1]).value,
 */
      __pyx_v_result = GAP_CallFunc3Args(__pyx_v_self-&gt;__pyx_base.value, ((struct __pyx_obj_4sage_4libs_3gap_7element_GapElement *)__pyx_t_5)-&gt;value, ((struct __pyx_obj_4sage_4libs_3gap_7element_GapElement *)__pyx_t_4)-&gt;value, ((struct __pyx_obj_4sage_4libs_3gap_7element_GapElement *)__pyx_t_6)-&gt;value);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

      /* &quot;sage/libs/gap/element.pyx&quot;:2524
 *                                            (&lt;GapElement&gt;a[0]).value,
 *                                            (&lt;GapElement&gt;a[1]).value)
 *             elif n == 3:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                 result = GAP_CallFunc3Args(self.value,
 *                                            (&lt;GapElement&gt;a[0]).value,
 */
      break;
      default:

      /* &quot;sage/libs/gap/element.pyx&quot;:2530
 *                                            (&lt;GapElement&gt;a[2]).value)
 *             else:
 *                 arg_list = make_gap_list(args)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *                 result = GAP_CallFuncList(self.value, arg_list)
 *             sig_off()
 */
      __pyx_t_11 = __pyx_f_4sage_4libs_3gap_7element_make_gap_list(__pyx_v_args); if (unlikely(__pyx_t_11 == ((Obj)NULL))) __PYX_ERR(0, 2530, __pyx_L14_error)
      __pyx_v_arg_list = __pyx_t_11;

      /* &quot;sage/libs/gap/element.pyx&quot;:2531
 *             else:
 *                 arg_list = make_gap_list(args)
 *                 result = GAP_CallFuncList(self.value, arg_list)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             sig_off()
 *         finally:
 */
      __pyx_v_result = GAP_CallFuncList(__pyx_v_self-&gt;__pyx_base.value, __pyx_v_arg_list);
      break;
    }

    /* &quot;sage/libs/gap/element.pyx&quot;:2532
 *                 arg_list = make_gap_list(args)
 *                 result = GAP_CallFuncList(self.value, arg_list)
 *             sig_off()             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *         finally:
 *             GAP_Leave()
 */
    sig_off();
  }

  /* &quot;sage/libs/gap/element.pyx&quot;:2534
 *             sig_off()
 *         finally:
 *             GAP_Leave()             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *         if result == NULL:
 *             # We called a procedure that does not return anything
 */
  /*finally:*/ {
    /*normal exit:*/{
      GAP_Leave();
      goto __pyx_L15;
    }
    __pyx_L14_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (PY_MAJOR_VERSION &gt;= 3) __Pyx_ExceptionSwap(&amp;__pyx_t_17, &amp;__pyx_t_18, &amp;__pyx_t_19);
      if ((PY_MAJOR_VERSION &lt; 3) || unlikely(__Pyx_GetException(&amp;__pyx_t_14, &amp;__pyx_t_15, &amp;__pyx_t_16) &lt; 0)) __Pyx_ErrFetch(&amp;__pyx_t_14, &amp;__pyx_t_15, &amp;__pyx_t_16);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __Pyx_XGOTREF(__pyx_t_17);
      __Pyx_XGOTREF(__pyx_t_18);
      __Pyx_XGOTREF(__pyx_t_19);
      __pyx_t_7 = __pyx_lineno; __pyx_t_12 = __pyx_clineno; __pyx_t_13 = __pyx_filename;
      {
        GAP_Leave();
      }
      if (PY_MAJOR_VERSION &gt;= 3) {
        __Pyx_XGIVEREF(__pyx_t_17);
        __Pyx_XGIVEREF(__pyx_t_18);
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_ExceptionReset(__pyx_t_17, __pyx_t_18, __pyx_t_19);
      }
      __Pyx_XGIVEREF(__pyx_t_14);
      __Pyx_XGIVEREF(__pyx_t_15);
      __Pyx_XGIVEREF(__pyx_t_16);
      __Pyx_ErrRestore(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
      __pyx_lineno = __pyx_t_7; __pyx_clineno = __pyx_t_12; __pyx_filename = __pyx_t_13;
      goto __pyx_L1_error;
    }
    __pyx_L15:;
  }

  /* &quot;sage/libs/gap/element.pyx&quot;:2535
 *         finally:
 *             GAP_Leave()
 *         if result == NULL:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             # We called a procedure that does not return anything
 *             return None
 */
  __pyx_t_2 = (__pyx_v_result == NULL);
  if (__pyx_t_2) {

    /* &quot;sage/libs/gap/element.pyx&quot;:2537
 *         if result == NULL:
 *             # We called a procedure that does not return anything
 *             return None             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *         return make_any_gap_element(self.parent(), result)
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* &quot;sage/libs/gap/element.pyx&quot;:2535
 *         finally:
 *             GAP_Leave()
 *         if result == NULL:             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *             # We called a procedure that does not return anything
 *             return None
 */
  }

  /* &quot;sage/libs/gap/element.pyx&quot;:2538
 *             # We called a procedure that does not return anything
 *             return None
 *         return make_any_gap_element(self.parent(), result)             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_parent); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2538, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  __pyx_t_12 = 0;
  #if CYTHON_UNPACK_METHODS
  if (likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
      __pyx_t_12 = 1;
    }
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_5, NULL};
    __pyx_t_6 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+1-__pyx_t_12, 0+__pyx_t_12);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2538, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __pyx_t_4 = ((PyObject *)__pyx_f_4sage_4libs_3gap_7element_make_any_gap_element(__pyx_t_6, __pyx_v_result)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2538, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* &quot;sage/libs/gap/element.pyx&quot;:2412
 * 
 * 
 *     def __call__(self, *args):             # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
 *         &quot;&quot;&quot;
 *         Call syntax for functions.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback(&quot;sage.libs.gap.element.GapElement_Function.__call__&quot;, __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_libgap);
  __Pyx_XDECREF(__pyx_v_a);
  __Pyx_XDECREF(__pyx_8genexpr3__pyx_v_x);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}</code></pre>
<p><code>cython</code> does a great job annotating generated code with corresponding
source code. Very useful! While it’s a lot of boilerplate the code is
straightforward.</p>
<p>A few important facts:</p>
<ol type="1">
<li><p><code>sig_GAP_Enter()</code> is our <code>setjmp()</code> in disguise of a few
macros defined at the beginning of the file. You can’t see <code>longjmp()</code>
calls here but they are lurking in various <code>GAP_CallFunc3Args()</code> calls.</p></li>
<li><p>There is a ton of local variables being updated in this file. And
none of them has <code>volatile</code> annotations.</p></li>
</ol>
<p>The above strongly suggests we are hitting a <code>volatile</code> <code>setjmp()</code>
<code>CAVEAT</code>. But how to find out for sure?</p>
<h2 id="nailing-down-the-specific-variable-corruption">Nailing down the specific variable corruption</h2>
<p>The general “missing <code>volatile</code>” hint is a bit abstract. Is it easy to
find out what variable is being corrupted here? The <code>gdb</code> is
surprisingly useful here. Let’s look at our <code>SIGSEGV</code> again:</p>
<pre><code>(gdb) bt
#0  0x00007feb544b756f in _Py_IsImmortal (op=0x0) at /usr/include/python3.12/object.h:242
#1  Py_DECREF (op=0x0) at /usr/include/python3.12/object.h:700
#2  Py_XDECREF (op=0x0) at /usr/include/python3.12/object.h:798
#3  __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__ (
    __pyx_v_self=__pyx_v_self@entry=0x7feb4e274f40,
    __pyx_v_args=__pyx_v_args@entry=(&lt;sage.rings.integer.Integer at remote 0x7feb533456e0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd8c0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd620&gt;))
    at /usr/src/debug/sci-mathematics/sagemath-standard-10.3/sagemath-standard-10.3-python3_12/build/cythonized/sage/libs/gap/element.c:26535
#4  0x00007feb544b84e7 in __pyx_pw_4sage_4libs_3gap_7element_19GapElement_Function_3__call__ (
    __pyx_v_self=&lt;sage.libs.gap.element.GapElement_Function at remote 0x7feb4e274f40&gt;,
    __pyx_args=(&lt;sage.rings.integer.Integer at remote 0x7feb533456e0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd8c0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd620&gt;),
    __pyx_kwds=&lt;optimized out&gt;)
    at /usr/src/debug/sci-mathematics/sagemath-standard-10.3/sagemath-standard-10.3-python3_12/build/cythonized/sage/libs/gap/element.c:26105</code></pre>
<p>Our function is in <code>frame 3</code> right now. Let’s look at it:</p>
<pre><code>(gdb) fr 3
#3  __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__ (
    __pyx_v_self=__pyx_v_self@entry=0x7feb4e274f40,
    __pyx_v_args=__pyx_v_args@entry=(&lt;sage.rings.integer.Integer at remote 0x7feb533456e0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd8c0&gt;, &lt;sage.rings.integer.Integer at remote 0x7feb4e5dd620&gt;))
    at /usr/src/debug/sci-mathematics/sagemath-standard-10.3/sagemath-standard-10.3-python3_12/build/cythonized/sage/libs/gap/element.c:26535
list
26535         __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;</code></pre>
<p><code>__Pyx_XDECREF()</code> looks promising.</p>
<pre><code>(gdb) list
26530         __Pyx_PyThreadState_assign
26531         __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
26532         __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
26533         __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
26534         __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
26535         __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
26536         __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
26537         __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
26538         if (PY_MAJOR_VERSION &gt;= 3) __Pyx_ExceptionSwap(&amp;__pyx_t_17, &amp;__pyx_t_18, &amp;__pyx_t_19);
26539         if ((PY_MAJOR_VERSION &lt; 3) || unlikely(__Pyx_GetException(&amp;__pyx_t_14, &amp;__pyx_t_15, &amp;__pyx_t_16) &lt; 0)) __Pyx_ErrFetch(&amp;__pyx_t_14, &amp;__pyx_t_15, &amp;__pyx_t_16);</code></pre>
<p><code>gdb</code> says that crash happens at line
<code>26535 __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;</code>. Thus <code>__pyx_t_6 = 0;</code>
is our primary suspect.</p>
<p>To trace the life of <code>__pyx_t_6</code> in assembly code I built <code>element.c</code>
with <code>-S -fverbose-asm</code> flags and got this tiny snippet of variable
reference:</p>
<pre class="asm"><code># /usr/include/python3.12/object.h:242:     return _Py_CAST(PY_INT32_T, op-&gt;ob_refcnt) &lt; 0;
    .loc 5 242 12 is_stmt 0 view .LVU66168
    movq -200(%rbp), %rdx # %sfp, r
    movq (%rdx), %rax # __pyx_t_6_10(ab)-&gt;D.11083.ob_refcnt, _1070</code></pre>
<p>It’s the first few instructions of <code>__Pyx_XDECREF()</code> implementation.</p>
<p>The main take away here is that <code>__pyx_t_6</code> is stored on stack at the
address <code>%rbp-200</code>. We can trace all the updates at that location and
see what is missing.</p>
<p>Before doing that I navigated to the beginning of crashing
<code>__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__</code>
function as:</p>
<pre><code>$ gdb -p `pgrep sage-ipython`
(gdb) break __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__
(gdb) continue

    # trigger break with with ` libgap.AbelianGroup(0,0,0)`

(gdb) disassemble
Dump of assembler code for function __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__:
=&gt; 0x00007f4ed9981b60 &lt;+0&gt;:     push   %rbp
   0x00007f4ed9981b61 &lt;+1&gt;:     mov    %rsp,%rbp</code></pre>
<p>And then executed first two instructions to initialize <code>%rbp</code>
register (as our variable lives at a constant offset from <code>%rbp</code> on
stack):</p>
<pre><code>(gdb) nexti
(gdb) nexti
(gdb) disassemble
Dump of assembler code for function __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__:
   0x00007f4ed9981b60 &lt;+0&gt;:     push   %rbp
   0x00007f4ed9981b61 &lt;+1&gt;:     mov    %rsp,%rbp
=&gt; 0x00007f4ed9981b64 &lt;+4&gt;:     push   %r15</code></pre>
<p>Now I set the watch point at stack memory where we expect <code>__pyx_t_6</code> to
reside:</p>
<pre><code>(gdb) print $rbp-200
$2 = (void *) 0x7ffd2824c5e8

(gdb) watch *(int*)(void *) 0x7ffd2824c5e8
Hardware watchpoint 2: *(int*)(void *) 0x7ffd2824c5e8

(gdb) continue
Continuing.

Thread 1 &quot;sage-ipython&quot; hit Hardware watchpoint 2: *(int*)(void *) 0x7ffd2824c5e8

Old value = 673498624
New value = 0
0x00007f98e609d2a8 in __pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__ (
    __pyx_v_self=__pyx_v_self@entry=0x7f98dfe70dc0,
    __pyx_v_args=__pyx_v_args@entry=(&lt;sage.rings.integer.Integer at remote 0x7f98e4722c40&gt;, &lt;sage.rings.integer.Integer at remote 0x7f98dfe7afd0&gt;, &lt;sage.rings.integer.Integer at remote 0x7f98e01dd5c0&gt;))
    at /usr/src/debug/sci-mathematics/sagemath-standard-10.3/sagemath-standard-10.3-python3_12/build/cythonized/sage/libs/gap/element.c:26192
26192       __pyx_t_6 = NULL;</code></pre>
<p>This break is our initial <code>__pyx_t_6 = NULL;</code> store. Nothing unusual.
Moving to the next update:</p>
<pre><code>(gdb) continue
Continuing.

Thread 1 &quot;sage-ipython&quot; hit Hardware watchpoint 2: *(int*)(void *) 0x7ffd2824c5e8

Old value = 0
New value = -538669696
__Pyx_GetItemInt_List_Fast (wraparound=0, boundscheck=1, i=2,
    o=[&lt;sage.libs.gap.element.GapElement_Integer at remote 0x7f98e0ac5c00&gt;, &lt;sage.libs.gap.element.GapElement_Integer at remote 0x7f98dfe4b500&gt;, &lt;sage.libs.gap.element.GapElement_Integer at remote 0x7f98dfe48d80&gt;])
    at /usr/src/debug/sci-mathematics/sagemath-standard-10.3/sagemath-standard-10.3-python3_12/build/cythonized/sage/libs/gap/element.c:38070
38070           Py_INCREF(r);</code></pre>
<p>Here we create an object and increment a reference via <code>__pyx_t_6</code> address.
Moving on:</p>
<pre><code>(gdb) continue
Continuing.

Thread 1 &quot;sage-ipython&quot; received signal SIGABRT, Aborted.
0x00007f99428617a7 in __GI_kill () at ../sysdeps/unix/syscall-template.S:120
120     T_PSEUDO (SYSCALL_SYMBOL, SYSCALL_NAME, SYSCALL_NARGS)</code></pre>
<p>Got to <code>SIGABRT</code> signal, <code>longjmp()</code> is about to be called. Moving on.</p>
<pre><code>(gdb) continue
Continuing.

Thread 1 &quot;sage-ipython&quot; received signal SIGSEGV, Segmentation fault.
0x00007f98e609c56f in _Py_IsImmortal (op=0x0) at /usr/include/python3.12/object.h:242
242         return _Py_CAST(PY_INT32_T, op-&gt;ob_refcnt) &lt; 0;</code></pre>
<p>We arrived at a final <code>SIGSEGV</code> signal.</p>
<p>Curiously we see only two stores (one <code>NULL</code> store and one
non-<code>NULL</code> store) at inspected address. Both are before the <code>SIGABRT</code>
signal (and thus <code>longjmp()</code> call). I was initially afraid that stack
got corrupted by stack reuse in nested functions. But it’s not the case
and our case is a lot simpler than it could be. Phew.</p>
<p>This session allowed me to finally understand the control flow happening
here.</p>
<h2 id="sagemath-breakage-mechanics"><code>sagemath</code> breakage mechanics</h2>
<p>Armed with <code>__pyx_t_6</code> <code>runtime</code> behaviour I think I got the properties
<code>__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__</code> had
to force <code>gcc</code> into <code>SIGSEGV</code>.</p>
<p>Slightly oversimplified function has the following form:</p>
<pre class="c"><code>__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__() {
    __pyx_t_6 = NULL;

    int mode = setjmp(jb);

    switch (mode) {
      case 1:                                  // longjmp() case
        break;
      case 0:                                  // regular case (`case 3:` in real code)
        __pyx_t_6 = something_else();          // set __pyx_t_6 to non-zero
        int done = use_post_setjmp(__pyx_t_6); // call longjmp(jb, 1) here
        __pyx_t_6 = NULL;
        break;
    }

    // get here via longjmp() or via natural execution flow
    //
    // Note: natural execution flow always gets here with `__pyx_t_6 = NULL`.
    if (__pyx_t_6 != NULL) deref(__pyx_t_6);
}</code></pre>
<p>Similar to our contrived example we save the function state at the
beginning of a function and return back to it from <code>use_post_setjmp()</code>
helper after we changed the value of a local variable.</p>
<p><code>__pyx_t_6</code> is not marked <code>volatile</code>. <code>gcc</code> noticed that <code>__pyx_t_6</code> is
always expected to be <code>NULL</code> when it reaches the final statement . And
<code>gcc</code> optimizes the function code into the following equivalent:</p>
<pre class="c"><code>__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__() {
    __pyx_t_6 = NULL;

    int mode = setjmp(jb);

    switch (mode) {
      case 1:                                  // longjmp() case
        break;
      case 0:                                  // regular case (`case 3:` in real code)
        __pyx_t_6 = something_else();          // set __pyx_t_6 to non-zero
        int done = use_post_setjmp(__pyx_t_6); // call longjmp(jb, 1) here
        __pyx_t_6 = NULL;
        break;
    }

    // Constant-fold `__pyx_t_6 = NULL` in `deref()` call site
    if (__pyx_t_6 != NULL) deref(NULL);
}</code></pre>
<p>Note that <code>gcc</code> did not eliminate the <code>if (__pyx_t_6 != NULL)</code> even
though the condition is always expected to be <code>false</code> (Richard explains
it <a href="https://gcc.gnu.org/PR114872#c24">here</a>).</p>
<p>The presence of <code>longjmp()</code> effectively skips the
<code>__pyx_t_6 = NULL;</code> assignment and executes <code>if (__pyx_t_6 != NULL) deref(NULL);</code>.
That leads to <code>SIGSEGV</code>.</p>
<p>Phew. We finally have the breakage mechanics caused by <code>gcc</code> code motion.</p>
<p>This bug is known for a while in <code>sagemath</code> bug tracker as an
<a href="https://github.com/sagemath/sage/issues/37026">Issue#37026</a>.</p>
<p>Fixing it will probably require adding <code>volatile</code> marking to quite a few
temporary variables in <code>.pyx</code> files of <code>sagemath</code>. Or alternatively
avoid the <code>setjmp()</code> / <code>longjmp()</code> pattern in inner functions if
feasible. They are just too large to be auditable for <code>setjmp()</code>
constraints.</p>
<h2 id="bonus-how-setjmp-longjmp-works-in-glibc">Bonus: how <code>setjmp()</code> / <code>longjmp()</code> works in <code>glibc</code></h2>
<p>Let’s have a look what <code>glibc</code> does <code>&lt;S-Del&gt;</code> on <code>x86_64</code> at
<a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=sysdeps/x86_64/setjmp.S;h=40807e73b51c362464730212d7c973848be612bf;hb=HEAD"><code>sysdeps/x86_64/setjmp.S</code></a>:</p>
<pre class="asm"><code>ENTRY (__sigsetjmp)
        /* Save registers.  */
        movq %rbx, (JB_RBX*8)(%rdi)
#ifdef PTR_MANGLE
        mov %RBP_LP, %RAX_LP
        PTR_MANGLE (%RAX_LP)
        mov %RAX_LP, (JB_RBP*8)(%rdi)
#else
        movq %rbp, (JB_RBP*8)(%rdi)
#endif
        movq %r12, (JB_R12*8)(%rdi)
        movq %r13, (JB_R13*8)(%rdi)
        movq %r14, (JB_R14*8)(%rdi)
        movq %r15, (JB_R15*8)(%rdi)
        lea 8(%rsp), %RDX_LP    /* Save SP as it will be after we return.  */
#ifdef PTR_MANGLE
        PTR_MANGLE (%RDX_LP)
#endif
        movq %rdx, (JB_RSP*8)(%rdi)
        mov (%rsp), %RAX_LP     /* Save PC we are returning to now.  */
        LIBC_PROBE (setjmp, 3, LP_SIZE@%RDI_LP, -4@%esi, LP_SIZE@%RAX_LP)
#ifdef PTR_MANGLE
        PTR_MANGLE (%RAX_LP)
#endif
        movq %rax, (JB_PC*8)(%rdi)

        /* Make a tail call to __sigjmp_save; it takes the same args.  */
        jmp __sigjmp_save
END (__sigsetjmp)</code></pre>
<p><code>%rdi</code> is our <code>env</code> parameter in <code>int setjmp(jmp_buf env);</code> signature.</p>
<p><code>__sigsetjmp</code> does a few things:</p>
<ul>
<li><p>is saves <code>r12</code>, <code>r13</code>, <code>r14</code>, <code>r15</code>, <code>rbx</code>, <code>rsp</code>, <code>rbp</code> registers into
<code>jmp_buf env</code> parameter. These registers happen to be all <code>callee-save</code>
registers on <code>System V x86_64 ABI</code>. Any <code>ABI</code>-conformant <code>C</code> function
does the same if it plans to use these registers locally.</p></li>
<li><p>the only twist is that some of the stack-related registers are
obfuscated with <code>PTR_MANGLE</code> macro. The macro mixes in stack canary
into the value.</p></li>
<li><p><code>__sigsetjmp</code> also saves return address as <code>mov (%rsp), %RAX_LP</code> to be
able to resume from it later.</p></li>
<li><p><code>__sigsetjmp</code> also handles shadow call stack if that exists, I skipped
it entirely for simplicity</p></li>
</ul>
<p>Importantly <code>__sigsetjmp</code> does not save any stack contents. It assumes
that <code>gcc</code> and the code author make sure it does not get corrupted on
return.</p>
<p>The <code>longjmp()</code> recovery is a mirror-image of <code>setjmp()</code>
in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=sysdeps/x86_64/__longjmp.S;h=22fedc49970eba0ab86cb8dec8411197bec95d37;hb=HEAD"><code>sysdeps/x86_64/__longjmp.S</code></a>. I’ll skip
pasting <code>longjmp()</code> implementation here.</p>
<h2 id="bonus-2--wclobbered-is-able-to-detect-some-of-the-clobber-cases">Bonus 2: <code>-Wclobbered</code> is able to detect some of the clobber cases</h2>
<p>Alexander Monakov <a href="https://fosstodon.org/@amonakov@mastodon.gamedev.place/112429019564307874">pointed out</a>
that <code>gcc</code> actually has an option to detect some of the clobbering cases
with <code>-Wclobbered</code>.</p>
<p>On a contrived example it reports nothing:</p>
<pre><code>$ gcc -O2 -c example.c -Wclobbered -Wall -Wextra -W</code></pre>
<p>It’s unfortunate as we can clearly see the different output.</p>
<p>But on the real <code>element.c</code> it complains as:</p>
<pre><code>$ gcc -O2 -Wclobbered -c element.i
...
element.c: In function '__pyx_pf_4sage_4libs_3gap_7element_19GapElement_Function_2__call__':
element.c:26122:13: warning: variable '__pyx_v_libgap' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26123:13: warning: variable '__pyx_v_a' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26125:13: warning: variable '__pyx_r' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26130:13: warning: variable '__pyx_t_4' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26131:13: warning: variable '__pyx_t_5' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26132:13: warning: variable '__pyx_t_6' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26134:13: warning: variable '__pyx_t_8' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26135:13: warning: variable '__pyx_t_9' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:26136:13: warning: variable '__pyx_t_10' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:38074:19: warning: variable 'r' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]
element.c:38074:19: warning: variable 'r' might be clobbered by 'longjmp' or 'vfork' [-Wclobbered]</code></pre>
<p>And that includes our <code>__pyx_t_6</code> variable!</p>
<h2 id="parting-words">Parting words</h2>
<p>Python ecosystem did not fully update to latest <code>python</code> release:
<code>python-3.12</code> was out in October 2023 and many packages did not yet
catch up with it. That makes it tedious to fix a long tail of issues
like <code>sagemath</code> crashes. Also makes it hard to reproduce issues on some
distributions that follow upstream packages without much patching.</p>
<p>While it was a bit unfortunate that <code>sagemath</code> is not packaged in
<code>::gentoo</code> I was pleasantly surprised by the responsive maintainer of
<code>::sage-on-gentoo</code> overlay. I managed to build <code>sagemath-standard</code> with
their help relatively quickly.</p>
<p><code>scikit-build-core</code> package is invasive and is able to break the build
of packages that don’t import it directly or indirectly, like
<a href="https://github.com/cschwan/sage-on-gentoo/issues/783"><code>sagemath-standard</code></a>.</p>
<p><code>cysignals</code> in <code>::gentoo</code> has a <a href="https://bugs.gentoo.org/927767">broken path</a>
to the <code>gdb</code> helper which makes it more tedious to debug <code>sagemath</code>
crashes.</p>
<p><code>cysignals</code> uses <code>SIGABRT</code> and <code>setjmp()</code> / <code>longjmp()</code> to recover from
errors. <code>sagemath</code> decided to use it in <code>C</code> bindings. Unfortunately it
does not mix well with <code>cython</code>’s use of local variables and leads to
broken code.</p>
<p>I was lucky to look at the <code>SIGABRT</code> handler first to notice <code>longjmp()</code>
there. If <code>gdb</code> hook would not fail for a wrong <code>share</code> path I would
take me a lot more time to discover <code>setjmp()</code> clue.</p>
<p>We were lucky that <code>gcc</code> did not delete <code>NULL</code>-dereference code and
generated something that <code>SIGSEGV</code>s on execution. Otherwise it would be
at best resource leak and use-after-free or data corruption at worst.</p>
<p><code>setjmp()</code> / <code>longjmp()</code> is very hard to use correctly in large
functions. One has to be very careful to sprinkle enough <code>volatile</code>
keywords to inhibit enough compiler optimizations to get expected
semantics from the program.</p>
<p>It was not a compiler bug after all but the <code>sagemath</code> one. It was
interaction between two aspects <code>sagemath</code> used:</p>
<ul>
<li><code>cython</code> usage that generates a ton of local variables it mutates
along the way without the <code>volatile</code> annotations</li>
<li>use of <code>cysignals</code>’ <code>sig_GAP_Enter()</code> (aka <code>setjmp()</code>) error recovery
in the same function</li>
</ul>
<p><code>gcc</code> can detect some of the clobber cases with <code>-Wclobbered</code> flag.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sun, 12 May 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/312-the-sagemath-saga.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc-14 bugs, pile 4</title>
    <link>http://trofi.github.io/posts/311-gcc-14-bug-pile-4.html</link>
    <description><![CDATA[<p>In a few weeks <code>gcc-14</code> branch should see a <code>14.1.0</code> release.</p>
<p>Since <a href="https://trofi.github.io/posts/306-gcc-14-bug-pile-3.html">November 2023</a> I encountered
only 8 more bugs. That makes it 2 bugs per month. 4 time lower rate than
I had last time.</p>
<h2 id="summary">summary</h2>
<p>Bugs I saw (in discovery order):</p>
<ul>
<li><a href="https://gcc.gnu.org/PR112711">tree-optimization/112711</a>: wrong code
on <code>llvm-16</code>, <code>bswap</code> and <code>assume(aligned)</code>.</li>
<li><a href="https://gcc.gnu.org/PR112869">c++/112869</a>: <code>ICE</code> on <code>libmpt-0.7.3</code>
when built with <code>-std=c++20</code>.</li>
<li><a href="https://gcc.gnu.org/PR112991">tree-optimization/112991</a>: <code>ICE</code> on
<code>p7zip</code> due to value numbering bugs.</li>
<li><a href="https://gcc.gnu.org/PR113132">bootstrap/113132</a>: bootstrap build
failure due to <code>-Werror</code>.</li>
<li><a href="https://gcc.gnu.org/PR113445">bootstrap/113445</a>: bootstrap comparison
failure due to instruction scheduler changes.</li>
<li><a href="https://gcc.gnu.org/PR114249">tree-optimization/114249</a>: <code>ICE</code> on
<code>lvm2</code> (wrong type transform in <code>SLP</code>).</li>
<li><a href="https://gcc.gnu.org/PR114439">c++/114439</a>: <code>icu4c</code> build failure due
to the initialization changes in <code>c++</code>.</li>
<li><a href="https://gcc.gnu.org/PR114574">lto/114574</a>: <code>unbound</code> ICE in <code>-flto</code>
mode.</li>
</ul>
<h2 id="fun-bug">fun bug</h2>
<p>Only one of 8 bug was a runtime failure on <code>llvm-16</code> in
<code>__builtin_assume_aligned()</code> handling code. It’s extracted from
<code>EndiaTest.cpp</code>:</p>
<pre class="c"><code>// $ cat EndianTest.cpp
typedef          int i32;
typedef unsigned int u32;

static inline void write_i32(void *memory, i32 value) {
  // swap i32 bytes as if it was u32:
  u32 u_value = value;
  value = __builtin_bswap32(u_value);

  // llvm infers '1' alignment from destination type
  __builtin_memcpy(__builtin_assume_aligned(memory, 1), &amp;value, sizeof(value));
}

__attribute__((noipa))
static void bug (void) {
  #define assert_eq(lhs, rhs) if (lhs != rhs) __builtin_trap()

  unsigned char data[5];
  write_i32(data, -1362446643);
  assert_eq(data[0], 0xAE);
  assert_eq(data[1], 0xCA);
  write_i32(data + 1, -1362446643);
  assert_eq(data[1], 0xAE);
}

int main() {
    bug();
}</code></pre>
<p>The optimization breaks simple <code>store-32</code> / <code>load-8</code> / <code>compare</code>
sequence:</p>
<pre><code>$ gcc/xg++ -Bgcc EndianTest.cpp -o bug -O0 &amp;&amp; ./bug
$ gcc/xg++ -Bgcc EndianTest.cpp -o bug -O2 &amp;&amp; ./bug
Illegal instruction (core dumped)</code></pre>
<p>There <code>gcc</code> was too optimistic in assuming that
<code>__builtin_assume_aligned()</code> returns address not aliased to input
argument. As a result <code>gcc</code> erroneously removed dead-looking stores.</p>
<p><a href="https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=302461ad9a04d82fee904bddac69811d13d5bb6a">The fix</a>
drops overly optimistic assumption.</p>
<h2 id="histograms">histograms</h2>
<ul>
<li><code>tree-optimization</code>: 3</li>
<li><code>c++</code>: 2</li>
<li><code>bootstrap</code>: 2</li>
<li><code>lto</code>: 1</li>
</ul>
<p>We are back to the usual <code>tree-optimization</code> at the top of subsystems
where bugs lurked.</p>
<h2 id="parting-words">parting words</h2>
<p>This cycle felt easier than the previous three. It feels like <code>gcc-14</code>
is ready for release.</p>
<p>Since the time <code>gcc-13</code> was released about a year ago I found 53 bugs
(past piles
<a href="https://trofi.github.io/posts/291-gcc-14-bugs-pile-1.html">1</a>,
<a href="https://trofi.github.io/posts/296-gcc-14-bugs-pile-2.html">2</a>,
<a href="https://trofi.github.io/posts/306-gcc-14-bug-pile-3.html">3</a>).
This is about one bug a week.</p>
<p>I think the most impactful <code>gcc-14</code> change will probably be
<code>-Werror=implicit-int</code>, <code>-Werror=implicit-function-declaration</code> and
friends (see <a href="https://gcc.gnu.org/gcc-14/porting_to.html" class="uri">https://gcc.gnu.org/gcc-14/porting_to.html</a> for more
details). This will break quite a few old unmaintained but used
everywhere C projects like <code>zip</code>, <code>opensp</code>, <code>jam</code>, <code>directfb</code>.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 13 Apr 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/311-gcc-14-bug-pile-4.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>a libpam bug</title>
    <link>http://trofi.github.io/posts/310-a-libpam-bug.html</link>
    <description><![CDATA[<p>Over a past few months I updated <code>libpam</code> <code>nixpkgs</code> package a few times.
I broke it at least three times:</p>
<ul>
<li><a href="https://github.com/NixOS/nixpkgs/pull/266828">fix clobbered patched <code>Makefile.in</code></a></li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/281182">fix deleted <code>required pam_lastlog</code> module</a></li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/298994">fix broken empty password handling</a></li>
</ul>
<p>It’s not great. But at least each breakage is slightly different.
Exploring it gives me some insight into how <code>libpam</code> works.</p>
<p>Let’s have a look at the most recent breakage related to empty passwords.</p>
<h2 id="actual-password-handling-bug">actual password handling bug</h2>
<p>In <a href="https://github.com/NixOS/nixpkgs/issues/297920"><code>nixpkgs</code> issue#297920</a>
Thomas M. DuBuisson reported that users with empty passwords no longer
work on <code>NixOS</code>.</p>
<p>An example <code>/etc/nixos/configuration.nix</code> snippet to create such an user
is:</p>
<pre class="nix"><code>{ ... }:
{
  users.users.test = {
    isNormalUser = true;
    password = &quot;&quot;;
    extraGroups = [ ];
  };
}</code></pre>
<p>After an update to <code>libpam-1.6.0</code> <code>login</code> did not work any more:</p>
<pre><code>login: test
Password:

Login incorrect</code></pre>
<p>Why did it break? Let’s have a look at how passwords are stored in <code>linux</code>.</p>
<h2 id="etcshadow-structure"><code>/etc/shadow</code> structure</h2>
<p>On <code>linux</code> desktops hashed user passwords are usually stored in
<code>/etc/shadow</code>:</p>
<pre><code># cat /etc/shadow
...
nobody:!:1::::::
nulloktest:$6$D0XkOSlH$fWuW6/7aFD5ZD2YzBuerj0STra3LddBNoXMn5pomYRmdbmsjM6bGzIX7nQQS4bGepDBoao2U.IZRGhgAJ4qOp.:1::::::</code></pre>
<p><a href="https://manpages.opensuse.org/Tumbleweed/shadow/shadow.5.en.html"><code>man 5 shadow</code></a>
from <code>shadow</code> package has more detail on what each field means.</p>
<p>As hashed passwords are still sensitive information <code>/etc/shadow</code> is not
readable by most users:</p>
<pre><code>$ ls -l /etc/shadow
-rw-r----- 1 root shadow 3454 Mar 29 07:03 /etc/shadow</code></pre>
<p>Programs that check passwords are usually ran as <code>root</code> or are
<code>SUID</code>-root themselves.</p>
<h2 id="hash-structure">hash structure</h2>
<p><code>$6$D0XkOSlH$fWuW6/7aFD5ZD2YzBuerj0STra3LddBNoXMn5pomYRmdbmsjM6bGzIX7nQQS4bGepDBoao2U.IZRGhgAJ4qOp.</code>
is not just a hash string of a well known hash algorithm. It used to be.
But not any more.</p>
<p><a href="https://manpages.opensuse.org/Tumbleweed/libxcrypt-devel/crypt.5.en.html"><code>man 5 crypt</code></a>
from <code>libxcrypt</code> package explains the string format in detail. It’s 10
pages long!</p>
<p>The main takeaway from that page is that there are a few ways to encode
empty (“” password) and blank (no password prompt) passwords for a user:</p>
<pre><code>nulloktest:$6$D0XkOSlH$fWuW6/7aFD5ZD2YzBuerj0STra3LddBNoXMn5pomYRmdbmsjM6bGzIX7nQQS4bGepDBoao2U.IZRGhgAJ4qOp.:1::::::
nulloktest::1::::::</code></pre>
<p>Hashed version (first) accepts only empty(““) password while empty version
(second) does not prompt for a password at all.</p>
<p>This hashed version happens to use <code>SHA512</code> algorithm (<code>$6$</code> prefix). You
can have other encodings as well: by varying used hash salt for <code>SHA512</code>
algorithm or by switching the hashing algorithm (for example to
<code>yescrypt</code>.)</p>
<h2 id="libpam-overview"><code>libpam</code> overview</h2>
<p><code>PAM</code> stands for “Pluggable Authentication Modules”. It allows programs
to embed user authentication without having to deal with the specifics of
accessing <code>/etc/shadow</code> contents directly. <code>libpam</code> allows you to
completely change authentication back end via <code>/etc/pam.d/</code>
configuration to use non-<code>shadow</code> mechanisms instead. I’ll focus on
<code>shadow</code> here and will avoid any configuration aspects.</p>
<p>Well known <code>libpam</code> users are <code>sudo</code> and <code>login</code> programs. Those are
expected to be ran as <code>root</code> or gain <code>root</code> via <code>SUID</code> <code>root</code> bit on the
binaries. <code>login</code> can authenticate any user in the system while <code>sudo</code>
probably only needs to authenticate current user.</p>
<p>Fun fact: normally you need <code>root</code> (or <code>shadow</code>) privileges to read
<code>/etc/shadow</code> for password verification purposes.</p>
<p>But <code>libpam</code> can be used for non-root programs as well! The typical
example is the session screen locker like <code>swaylock</code> or <code>i3lock</code>: those
lock your screen until you type current user’s password. How do they
manage to validate current user’s password without having a <code>SUID</code>
<code>root</code> bit? <code>libpam</code> does it by by calling external <code>unix_chkpwd</code>
<code>SUID</code> <code>root</code> program from <code>libpam</code> package:</p>
<pre><code>$ ls -l `which unix_chkpwd`
-r-s--x--x 1 root root 63472 Mar 29 04:41 /run/wrappers/bin/unix_chkpwd</code></pre>
<p>No magic unfortunately :)</p>
<h2 id="back-to-password-handling-bug">back to password handling bug</h2>
<p>In <a href="https://github.com/linux-pam/linux-pam/issues/758"><code>libpam</code> issue#758</a>
Chris Severance narrowed the regression down to
<a href="https://github.com/linux-pam/linux-pam/commit/b3020da7da384d769f27a8713257fbe1001878be">the <code>pam_unix/passverify</code> change</a>.
Here are two diagrams to show the effect of that change.</p>
<p>Before the change <code>libpam-1.5.3</code> password checking diagram looked this way:</p>
<img src="https://trofi.github.io/posts.data.inline/310-a-libpam-bug/fig-0.gv.svg" />
<p>After the change <code>libpam-1.6.0</code> password checking diagram looks this way:</p>
<img src="https://trofi.github.io/posts.data.inline/310-a-libpam-bug/fig-1.gv.svg" />
<p>To phrase it in words: <code>libpam-1.5.3</code> used <code>unix_chkpwd</code> external helper
program only if <code>program</code> was not already ran as <code>root</code>. <code>libpam-1.6.0</code>
in contrast always uses <code>unix_chkpwd</code>.</p>
<p>In theory both versions should work the same.</p>
<p>In practice <code>unix_chkpwd</code> disallows empty passwords (bug) but allows the
blank ones (feature).</p>
<p>Mechanically the bug happens as <code>unix_chkpwd</code> adds
<a href="https://github.com/linux-pam/linux-pam/commit/9e74e90147c530801e3ea3428d64371722c90e01">this extra bit of code</a>:</p>
<pre class="diff"><code>--- a/modules/pam_unix/passverify.c
+++ b/modules/pam_unix/passverify.c
@@ -1096,6 +1096,12 @@ helper_verify_password(const char *name, const char *p, int nullok)
 	if (pwd == NULL || hash == NULL) {
 		helper_log_err(LOG_NOTICE, &quot;check pass; user unknown&quot;);
 		retval = PAM_USER_UNKNOWN;
+	} else if (p[0] == '\0' &amp;&amp; nullok) {
+		if (hash[0] == '\0') {
+			retval = PAM_SUCCESS;
+		} else {
+			retval = PAM_AUTH_ERR;
+		}
 	} else {
 		retval = verify_pwd_hash(p, hash, nullok);
 	}</code></pre>
<p>Here <code>helper_verify_password()</code> started rejecting empty passwords with
non-empty hashes present in <code>/etc/shadow</code>. Oops. This change is what
distinguishes theses hashes:</p>
<ul>
<li><code>nulloktest::1::::::</code>: <code>hash[0] == '\0'</code> (hash of length <code>0</code>): accepted</li>
<li><code>nulloktest:$6$D0...</code>: <code>hash[0] != '\0'</code> (hash of length <code>&gt;0</code>): rejected</li>
</ul>
<p>Such an early rejection is a bug. The hash needs to have a chance to be
verified instead.</p>
<p><code>helper_verify_password()</code> function is only used by external helpers like
<code>unix_chkpwd</code> and was never used by <code>libpam.so</code> itself. That’s why
<code>libpam-1.5.3</code> just worked for <code>login</code>.</p>
<p>The fix is <a href="https://github.com/linux-pam/linux-pam/pull/784">simple</a>:</p>
<pre class="diff"><code>--- a/modules/pam_unix/passverify.c
+++ b/modules/pam_unix/passverify.c
@@ -76,9 +76,13 @@ PAMH_ARG_DECL(int verify_pwd_hash,
 
 	strip_hpux_aging(hash);
 	hash_len = strlen(hash);
-	if (!hash_len) {
+
+	if (p &amp;&amp; p[0] == '\0' &amp;&amp; !nullok) {
+		/* The passed password is empty */
+		retval = PAM_AUTH_ERR;
+	} else if (!hash_len) {
 		/* the stored password is NULL */
-		if (nullok) { /* this means we've succeeded */
+		if (p &amp;&amp; p[0] == '\0' &amp;&amp; nullok) { /* this means we've succeeded */
 			D((&quot;user has empty password - access granted&quot;));
 			retval = PAM_SUCCESS;
 		} else {
@@ -1109,12 +1113,6 @@ helper_verify_password(const char *name, const char *p, int nullok)
 	if (pwd == NULL || hash == NULL) {
 		helper_log_err(LOG_NOTICE, &quot;check pass; user unknown&quot;);
 		retval = PAM_USER_UNKNOWN;
-	} else if (p[0] == '\0' &amp;&amp; nullok) {
-		if (hash[0] == '\0') {
-			retval = PAM_SUCCESS;
-		} else {
-			retval = PAM_AUTH_ERR;
-		}
 	} else {
 		retval = verify_pwd_hash(p, hash, nullok);
 	}</code></pre>
<p>Here we move all the null password checking to a common <code>verify_pwd_hash</code>
code and check for password length and not for hash length to handle
<code>nullok</code> <code>libpam</code> configuration.</p>
<h2 id="debugging-tips">debugging tips</h2>
<p><code>unix_chkpwd</code> is a <code>SUID</code> <code>root</code> binary. Moreover it changes it’s
behaviour based on actual user calling it. I wanted to find a way to
probe directly it’s ability to validate <code>/etc/shadow</code> contents without
involving external <code>login</code> binary.</p>
<p>On a system with <code>libpam</code> installed password checking session for an
arbitrary user could be done this way:</p>
<pre><code>$ printf &quot;correct-password\0&quot; | sudo unix_chkpwd testuser nullok; echo $?
0
$ printf &quot;incorrect-password\0&quot; | sudo unix_chkpwd testuser nullok; echo $?
7</code></pre>
<p>You need to pass null-terminated password into <code>unix_chkpwd</code>’s <code>stdin</code>
descriptor. The error code will tell you back if the check succeeded or
why it failed.</p>
<p>I needed an equivalent check for a locally built <code>unix_chkpwd</code> from
<code>linux-pam</code> <code>git</code> repository. I came up with this hack:</p>
<pre><code># build unix_chkpwd
$ cd linux-pam
$ ./configure --disable-doc
$ make

# mark unix_chkpwd SUID-root
$ sudo chown root modules/pam_unix/unix_chkpwd
$ sudo chmod 4755 modules/pam_unix/unix_chkpwd

# check if it can authenticate the suer
$ printf &quot;\0&quot; | sudo modules/pam_unix/unix_chkpwd nulloktest nullok; echo $?</code></pre>
<p>This setup allowed me to quickly find the problematic bit using
<code>printf()</code> debugging.</p>
<h2 id="hashed-empty-passwords">hashed empty passwords</h2>
<p>Is it typical to have empty hashed passwords? At least <code>passwd</code> does not
allow you to specify an empty password explicitly:</p>
<pre><code># passwd nulloktest
New password:
Retype new password:
No password has been supplied.
...
passwd: Permission denied
passwd: password unchanged</code></pre>
<p>But we can set a blank password with a <code>-d</code> option:</p>
<pre><code># passwd -d nulloktest
passwd: password changed.

# grep nulloktest /etc/shadow
nulloktest::1::::::</code></pre>
<p>This subtlety was one of the reasons why upstream <code>linux-pam</code> had a hard
time verifying a problem of empty hashed password. So how does <code>NixOS</code>
manage to create empty hashed passwords in the first place?</p>
<p>It uses <code>perl</code> code to call <code>crypt()</code> function from <code>libxcrypt</code> to
generate one. <a href="https://github.com/NixOS/nixpkgs/blob/8f72bd17eae0d1a7fcb63e3f1a3baa7dadebef68/nixos/modules/config/update-users-groups.pl#L37">Actual code</a>:</p>
<pre class="perl"><code>sub hashPassword {
    my ($password) = @_;
    my $salt = &quot;&quot;;
    my @chars = ('.', '/', 0..9, 'A'..'Z', 'a'..'z');
    $salt .= $chars[rand 64] for (1..8);
    return crypt($password, '$6$' . $salt . '$');
}</code></pre>
<p>Here the <code>$password</code> passed is an empty string. We can generate a few of
them just for fun:</p>
<pre><code>$ perl -e 'my $salt = &quot;&quot;; my @chars = (&quot;.&quot;, &quot;/&quot;, 0..9, &quot;A&quot;..&quot;Z&quot;, &quot;a&quot;..&quot;z&quot;); $salt .= $chars[rand 64] for (1..8); print(crypt(&quot;&quot;, &quot;\$6\$&quot; . $salt . &quot;\$&quot;) . &quot;\n&quot;);'
$6$AgpQ6azd$0YmJW0VFg0FwyPgSW1KSiF8cy5qB8NB/.IcMbjMa1OCbGH3ki9a4bkuhtMxQupeMeiagB86tpW7F/7yOl3Hhc0</code></pre>
<h2 id="parting-words">parting words</h2>
<p><code>libpam</code> updates are tricky. Every time I update <code>libpam</code> I break
something. This time it was a somewhat benign case of empty password
handling. We need more tests. The empty password fix fix was merged to
<code>libpam</code> as <a href="https://github.com/linux-pam/linux-pam/pull/784">PR#784</a>
and to <code>nixpkgs</code> as <a href="https://github.com/NixOS/nixpkgs/pull/298994">PR#298994</a>.</p>
<p>If you are affected by an empty password bug you can set the password to
a blank hash with <code>hashedPassword = ""</code>. Or set it to blank with
<code>passwd -d $user</code>. Both are equivalent.</p>
<p><code>libpam-1.6.0</code> executes an external<code>unix_chkpwd</code> binary with <code>SUID</code>
<code>root</code> set to validate passwords.</p>
<p>Blank passwords (empty hash) are subtly different from empty passwords
(present hash of empty string): blank passwords don’t get prompted by
<code>login</code> and friends while empty passwords do. Sometimes this causes the
confusion.</p>
<p><code>NixOS</code> uses direct <code>crypt()</code> call to <code>libxcrypt</code> to generate
<code>/etc/shadow</code> entries.</p>
<p><code>libxcrypt</code> supports quite a few hashing algorithms and tweaks on top of
them that control hashing rounds and so on.</p>
<p><code>linux-pam</code> upstream is very responsive! It’s always a pleasure to send
fixes there.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 30 Mar 2024 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/310-a-libpam-bug.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>listing all nixpkgs packages</title>
    <link>http://trofi.github.io/posts/309-listing-all-nixpkgs-packages.html</link>
    <description><![CDATA[<h2 id="intro">Intro</h2>
<p><code>nixpkgs</code> provides <a href="https://repology.org/repository/nix_unstable">a lot of packages</a>.
Today <code>repology.org</code> says it’s <code>106937</code> packages for <code>89083</code> projects.</p>
<p>As I understand it <code>repology</code>’s <code>project</code> means upstream project name.
If we pick <code>python:networkx</code> <code>repology</code> name then <code>nixpkgs</code> provides a
few versions of <code>networkx</code> for each python version:</p>
<pre><code>$ nix-env -qa | grep networkx
python3.10-networkx-3.1
python3.11-networkx-3.1</code></pre>
<p>But what if I tell you the above number is only a minor subset of package
definitions hiding in <code>nixpkgs</code>? You could easily access packages like
<code>python3.12-networkx-3.1</code>, <code>python3.10-networkx-3.1</code> or even
<code>python3.11-networkx-3.1-riscv64-unknown-linux-gnu</code>. None of them are
listed on <code>repology</code>.</p>
<p>Abundance of various package flavours like this one is a well-known fact
or a seasoned user of <code>nixpkgs</code>.</p>
<p>A few days ago I attempted to update <code>autoconf</code> from <code>2.71</code> to <code>2.72</code>
version. It’s supposed to be a minor maintenance release without
many breaking changes. To make sure I don’t break too much I attempted
to validate that all the packages that somehow use <code>autoconf</code> are still
building correctly.</p>
<h2 id="on-attributes-and-package-names">On attributes and package names</h2>
<p><code>NixOS</code> and <code>nixpkgs</code> users almost never deal with exact package names:
resolving a package name to package definition is slow and ambiguous.</p>
<p>Instead <code>nixpkgs</code> encourages users to use “attribute names” using
<code>nix</code>-language level constructs.</p>
<p>For example <code>python3.11-networkx-3.1</code> would have a name of
<code>python3Packages.networkx</code> on my system. The same package also has quite
a few aliases:</p>
<ul>
<li><code>python311Packages.networkx</code></li>
<li><code>python3.pkgs.networkx</code></li>
<li><code>python311.pkgs.networkx</code></li>
</ul>
<p>Each of them evaluates to the same package definition. An example
<code>nix repl</code> session to make sure it’s still true:</p>
<pre><code>$ nix repl -f '&lt;nixpkgs&gt;'

nix-repl&gt; python3Packages.networkx
«derivation /nix/store/659allxmdwqxr4zmg03z8wqyizlsdmgh-python3.11-networkx-3.1.drv»

nix-repl&gt; python311Packages.networkx
«derivation /nix/store/659allxmdwqxr4zmg03z8wqyizlsdmgh-python3.11-networkx-3.1.drv»

nix-repl&gt; python311.pkgs.networkx
«derivation /nix/store/659allxmdwqxr4zmg03z8wqyizlsdmgh-python3.11-networkx-3.1.drv</code></pre>
<p>The <code>.drv</code> files have identical hash part which means all the names are
equivalent when used as is.</p>
<p>Simpler examples of attributes are <code>re2c</code> and <code>gnugrep</code>. More complex
ones are <code>python3Packages.ninja</code>, <code>linuxPackages_latest.kernel.configfile</code> and
<code>pkgsCross.riscv64.re2c</code>.</p>
<p>Thus to answer a question of what packages should I test after
<code>autoconf</code> upgrade I would prefer to get attribute names instead of
package names.</p>
<h2 id="poor-mans-reverse-dependency-lookup">Poor man’s reverse dependency lookup</h2>
<p>I routinely do package updates that touch many packages indirectly.
To get a list of impacted packages <code>nixpkgs</code> provides a
<a href="https://github.com/NixOS/nixpkgs/blob/master/maintainers/scripts/rebuild-amount.sh"><code>maintainers/scripts/rebuild-amount.sh</code> script</a>.</p>
<p>It instantiates all the known to hydra attributes into <code>.drv</code> files and
checks changed hashes before and after the change. This diff is our
impact. Script’s typical output looks like that:</p>
<pre><code>$ time ./maintainers/scripts/rebuild-amount.sh --print HEAD^
Estimating rebuild amount by counting changed Hydra jobs (parallel=unset).
     32 x86_64-darwin
     63 x86_64-linux

          asciidoc-full-with-plugins.x86_64-darwin  dist=/nix/store/...-asciidoc-full-with-plugins-10.2.0-dist;/nix/store/...-asciidoc-full-with-plugins-10.2.0
          asciidoc-full-with-plugins.x86_64-linux   dist=/nix/store/...-asciidoc-full-with-plugins-10.2.0-dist;/nix/store/...-asciidoc-full-with-plugins-10.2.0
          asciidoc-full.x86_64-darwin               dist=/nix/store/...-asciidoc-full-10.2.0-dist;/nix/store/...-asciidoc-full-10.2.0
          asciidoc-full.x86_64-linux                dist=/nix/store/...-asciidoc-full-10.2.0-dist;/nix/store/...-asciidoc-full-10.2.0
          auto-multiple-choice.x86_64-darwin        /nix/store/...-auto-multiple-choice-1.6.0
          auto-multiple-choice.x86_64-linux         /nix/store/...-auto-multiple-choice-1.6.0
          bicgl.x86_64-darwin                       /nix/store/...-bicgl-unstable-2018-04-06
          bicgl.x86_64-linux                        /nix/store/...-bicgl-unstable-2018-04-06
          bicpl.x86_64-darwin                       /nix/store/...-bicpl-unstable-2020-10-15
          bicpl.x86_64-linux                        /nix/store/...-bicpl-unstable-2020-10-15
          cantor.x86_64-linux                       /nix/store/...-cantor-23.08.4
          clevis.x86_64-linux                       man=/nix/store/...-clevis-19-man;/nix/store/...-clevis-19
          conglomerate.x86_64-darwin                /nix/store/...-conglomerate-unstable-2017-09-10
          ...
          netpbm.x86_64-darwin                                                                     bin=/nix/store/...-netpbm-11.4.4-bin;dev=/nix/store/...-netpbm-11.4.4-dev;/nix/store/...-netpbm-11.4.4
          netpbm.x86_64-linux                                                                      bin=/nix/store/...-netpbm-11.4.4-bin;dev=/nix/store/...-netpbm-11.4.4-dev;/nix/store/...-netpbm-11.4.4

          ...
...
real    6m38,854s
user    6m19,604s
sys     0m17,102s</code></pre>
<p>Here I changed <code>netpbm</code> package in <code>HEAD</code> commit and that caused the
rebuild of <code>63</code> <code>x86_64-linux</code> packages (and <code>32</code> <code>x86_64-darwin</code> ones).
In this case rebuilding all <code>63</code> of them is not a big deal.</p>
<p>But even here some of the packages are probably not worth testing.
<code>netpbm</code> has something to do with image formats and <code>cleavis</code> is about
the encryption. I would guess <code>cleavis</code> would not be impacted by the
update at all.</p>
<p>It would be nice to find all <strong>direct</strong> users of <code>netpbm</code> instead and
rebuild those.</p>
<p>The very first topic I created on <code>NixOS discourse</code> was about
<a href="https://discourse.nixos.org/t/how-do-you-find-reverse-dependencies/15057">reverse dependencies lookup</a>.</p>
<p>I was a bit surprised there was no standard tool like that and wrote a
hack to do it:</p>
<pre class="nix"><code># use as:
#    import ./arevdeps.nix linuxHeaders pkgs lib
revdepAttr: pkgs: lib:
let isDrv = v: (builtins.tryEval v).success &amp;&amp; lib.isDerivation v;
    # skip broken and unsupported packages on this system in a very crude way:
    safeReadFile = df: let c = builtins.tryEval (builtins.readFile df); in if c.success then c.value else &quot;&quot;;
    fastHasEntry = i: s: s != builtins.replaceStrings [i] [&quot;&lt;FOUND-HERE&gt;&quot;] s;
    sInDrv = s: d: fastHasEntry s (safeReadFile d.drvPath);
    rdepInDrv = rdep: d: builtins.any (s: sInDrv s d)
                                      (builtins.map (o: rdep.${o}.outPath) rdep.outputs);
    matchedPackages = lib.filterAttrs (n: d: isDrv d &amp;&amp; rdepInDrv revdepAttr d)
                                      pkgs;
in builtins.attrNames matchedPackages</code></pre>
<p>It’s a bit wordy (not much <code>nix</code> experience by then) but it’s idea is
simple: find references to a searched package via it’s <code>.drv</code> path by
looking at <code>.drv</code> files created from attributes in <code>&lt;nixpkgs&gt;</code> object.
Let’s try to look up <code>netpbm</code> against it:</p>
<pre><code>nix-repl&gt; import ./arevdeps.nix netpbm pkgs lib
[ &quot;auto-multiple-choice&quot; &quot;bicpl&quot; &quot;fbcat&quot; &quot;foomatic-db-ppds&quot; &quot;fped&quot;
  &quot;img2pdf&quot; &quot;latex2html&quot; &quot;lilypond&quot; &quot;lilypond-unstable&quot; &quot;mup&quot; &quot;netpbm&quot;
  &quot;pcb&quot; &quot;pnglatex&quot; &quot;sng&quot; &quot;xplanet&quot; &quot;yad&quot; ]</code></pre>
<p>Only 16 packages!</p>
<p>The major caveat is that the hack does not try to descend from the top
level down to other attributes like <code>python3Packages.*</code> or
<code>haskellPackages.*</code>.</p>
<p>In theory you could direct the hack to specific attributes and expand
the output:</p>
<pre><code>nix-repl&gt; import ./arevdeps.nix netpbm pkgs.python3Packages lib
[ &quot;img2pdf&quot; &quot;pnglatex&quot; ]</code></pre>
<p>In practice it’s not very convenient and I never did it. The command
already takes a while to run and running it multiple times is no fun.</p>
<p>I decided to extend initial script to handle nested attributes.</p>
<h2 id="naive-attempt-to-extend-the-hack">Naive attempt to extend the hack</h2>
<p>In theory it’s one small extension: add a tiny amount of code to descend
into child attributes and you are done.</p>
<p>Sounds good, did not work.</p>
<p>The result started crashing on various syntax errors in various
<code>nixpkgs</code> files. When I worked error around <code>nix</code> ate <code>100GB</code> of <code>RAM</code>
and crashed without producing the result.</p>
<p>I’ll spare you the implementation details of a modified script.</p>
<p>Unbounded <code>RAM</code> usage is very unfortunate as the script in theory could
run in constant space. It’s not very simple in practice as <code>nix</code> uses
<a href="https://en.wikipedia.org/wiki/Boehm_garbage_collector"><code>boehm-gc</code></a> to
control it’s heap usage. I’m not sure a single loaded <code>&lt;nixpkgs&gt;</code> tree
allows for any garbage collection of <code>.drv</code> files.</p>
<p>I filed <a href="https://github.com/NixOS/nix/issues/9671" class="uri">https://github.com/NixOS/nix/issues/9671</a> issue to see if there
are any obvious references <code>nix</code> could remove to make garbage collection
more efficient.</p>
<p>But in the shorter term I had to try something else.</p>
<h2 id="a-step-back-just-list-all-the-attributes">A step back: just list all the attributes</h2>
<p>I realized there are multiple problems with my hack and I attempted to
solve a simple problem. I wanted to just list all the available
attributes in <code>&lt;nixpkgs&gt;</code>. Ideally not just those known to <code>hydra</code> CI
builder but the ones hiding in <code>pkgsCross</code> in other places.</p>
<p>Quiz question: how hard is it to get a list of such attributes to
explore?</p>
<p>Getting an attribute list of a single set is trivial via single call of
<code>lib.attrNames</code>:</p>
<pre><code>$ nix repl -f '&lt;nixpkgs&gt;'

nix-repl&gt; lib.take 4 (lib.attrNames pkgs)
[ &quot;AAAAAASomeThingsFailToEvaluate&quot; &quot;AMB-plugins&quot; &quot;ArchiSteamFarm&quot; &quot;AusweisApp2&quot; ]

nix-repl&gt; lib.length (lib.attrNames pkgs)
20059</code></pre>
<p>The problem is that some of the attributes are neither derivations not
attribute sets:</p>
<pre><code>nix-repl&gt; pathsFromGraph
/nix/store/jp811zl7njhg1g59x95dgqs4rddgr7xz-source/pkgs/build-support/kernel/paths-from-graph.pl</code></pre>
<p>Luckily it’s easy to introspect value type via predefined predicates:</p>
<pre><code>nix-repl&gt; lib.isPath pkgs.pathsFromGraph
true

nix-repl&gt; lib.isDerivation re2c
true

nix-repl&gt; lib.isAttrs pkgsCross
true</code></pre>
<p>Another problem is that some of attribute values don’t evaluate
successfully. Sometimes intentionally:</p>
<pre><code>nix-repl&gt; pkgs.AAAAAASomeThingsFailToEvaluate
error:
       … while calling the 'throw' builtin

         at /nix/store/jp811zl7njhg1g59x95dgqs4rddgr7xz-source/pkgs/top-level/all-packages.nix:106:36:

          105|   ### Evaluating the entire Nixpkgs naively will fail, make failure fast
          106|   AAAAAASomeThingsFailToEvaluate = throw ''
             |                                    ^
          107|     Please be informed that this pseudo-package is not the only part

       error: Please be informed that this pseudo-package is not the only part
       of Nixpkgs that fails to evaluate. You should not evaluate
       entire Nixpkgs without some special measures to handle failing
       packages, like using pkgs/top-level/release-attrpaths.nix.

nix-repl&gt; pkgs.gccWithoutTargetLibc
error:
       … while evaluating the attribute 'gccWithoutTargetLibc'
        15967|   gccWithoutTargetLibc = assert stdenv.targetPlatform != stdenv.hostPlatform; let
       error: assertion '((stdenv).targetPlatform != (stdenv).hostPlatform)' failed</code></pre>
<p>And sometimes entirely by accident:</p>
<pre><code>nix-repl&gt; pkgsLLVM.clang_6
error:
       … while evaluating the attribute 'clang_6'
       error: attribute 'clangUseLLVM' missing</code></pre>
<p>I just need to filter out all the problematic attributes and leave only
evaluatable ones. <code>nix</code> even provides a <code>builtins.tryEval</code> just for
this case:</p>
<pre><code>nix-repl&gt; builtins.tryEval pkgs.AAAAAASomeThingsFailToEvaluate
{ success = false; value = false; }

nix-repl&gt; builtins.tryEval pkgs.gccWithoutTargetLibc
{ success = false; value = false; }

nix-repl&gt; builtins.tryEval pkgs.gcc
{ success = true; value = «derivation /nix/store/y5vq20420rg2g6h03c8x7sxzjcxphg9w-gcc-wrapper-12.3.0.drv»; }</code></pre>
<p>Sounds easy, right? As always there is a catch:</p>
<pre><code>nix-repl&gt; builtins.tryEval pkgsLLVM.clang_6
error:
       error: attribute 'clangUseLLVM' missing

nix-repl&gt; builtins.tryEval pkgsMusl.adobe-reader
       error: evaluation aborted with the following error message: 'unsupported platform for the pure Linux stdenv'</code></pre>
<p>Not all error types can be caught by <code>builtins.tryEval</code>: only <code>throw</code>
and <code>aasert</code> calls (these are explicitly present in the call) are
catchable. The rest is considered a bug in <code>nix</code> expression and can’t be
caught. I guess it’s the way to signal invalid <code>.nix</code> programs.</p>
<p>Lack of error recovery means that I can’t do attribute filtering like
in a single <code>nix</code> expression! I had 2 options:</p>
<ol type="1">
<li><p>Write an external script that probes for problematic attributes and
somehow skips them.</p></li>
<li><p>Fix all the evaluation errors in <code>nixpkgs</code> to make the naive
filtering work.</p></li>
</ol>
<p><code>[1.]</code> would require use of <code>nix</code> as a library in one form or another.
I was lazy and tried <code>[2.]</code> first. My assumption that it was a small
list of easy to fix errors.</p>
<p>Here is my first version of a simple attribute lister:</p>
<pre class="nix"><code># Usage example:
# $ nix-instantiate --eval --strict ~/.config/nixpkgs/lib/all-attrs.nix -I nixpkgs=$PWD

{ nixpkgs ? import &lt;nixpkgs&gt; {
    config = {
    };
  }
, rootAttr ? &quot;pkgs&quot;
, verbose ? 1 # warn

# How to pick, resource usage for me as of 2023-12-28:
# 1 - 10 seconds, ~2GB of RAM
# 2 - 2 minutes, ~25GB of RAM (unfiltered attrs)
# 3 - 5+ minutes, ~70GB+ or RAM Fails on attributes like `pkgsCross.iphone32.ammonite`
# anything else: at your risk
, maxDepth
}:

let
  # simple variables:
  lib = nixpkgs.lib;

  # logging:
  err   = s: e: lib.trace &quot;ERROR: ${s}&quot; e;
  warn  = s: e: if verbose &gt;= 1 then lib.trace &quot;WARN: ${s}&quot; e else e;
  info  = s: e: if verbose &gt;= 2 then lib.trace &quot;INFO: ${s}&quot; e else e;
  debug = s: e: if verbose &gt;= 3 then lib.trace &quot;DEBUG: ${s}&quot; e else e;

  # root to start at
  root = lib.attrByPath (lib.splitString &quot;.&quot; rootAttr)
                        (warn &quot;did not find ${rootAttr}&quot; {})
                        nixpkgs;
  # other helpers:
  isPrimitive = v: lib.isFunction v
                || lib.isString v
                || lib.isBool v
                || lib.isList v
                || lib.isInt v
                || lib.isPath v
                || v == null;

  go = depth: ap: v:
    let
      a = lib.showAttrPath ap;
      e = builtins.tryEval v;
      maybe_go_deeper =
        if depth &gt;= maxDepth
        then info &quot;too deep (depth=${toString depth}) nesting of a=${a}, stop&quot; []
        else map (nv: go (depth + 1) (ap ++ [nv.name]) nv.value)
                 (lib.attrsToList v);
    in debug &quot;inspecting ${a}&quot; (
    if !e.success then info &quot;${a} fails to evaluate&quot; []
    else if lib.isDerivation v
    then [a]
    else if lib.isAttrs v then maybe_go_deeper
    else if isPrimitive v then []
    # should not get here
    else warn &quot;unhandled type of ${a}&quot; []);
in lib.flatten (go 0 [] root)</code></pre>
<p>It’s more than a page of code. It explores at most <code>maxDepth</code> attributes
deep.</p>
<p>Usage example:</p>
<pre><code>$ time nix-instantiate --eval --strict ~/.config/nixpkgs/lib/all-attrs.nix -I nixpkgs=$PWD --arg maxDepth 1
...
[ &quot;AMB-plugins&quot; &quot;ArchiSteamFarm&quot; ... &quot;zulu8&quot; &quot;zuo&quot; &quot;zwave-js-server&quot;
  &quot;zx&quot; &quot;zxcvbn-c&quot; &quot;zxfer&quot; &quot;zxing&quot; &quot;zxing-cpp&quot; &quot;zxpy&quot; &quot;zxtune&quot; &quot;zydis&quot;
  &quot;zyn-fusion&quot; &quot;zynaddsubfx&quot; &quot;zynaddsubfx-fltk&quot; &quot;zynaddsubfx-ntk&quot; &quot;zz&quot;
  &quot;zziplib&quot; &quot;zzuf&quot; ]

real    0m6,587s
user    0m5,963s
sys     0m0,608s</code></pre>
<p>Yay! It works! Note: this is just one depth level of attributes, like
<code>re2c</code>. It does not contain packages like <code>python3Packages.ninja</code>. The
run takes 2GB and 6 seconds to complete.</p>
<p>If we want one level deeper we can specify <code>--maxDepth 2</code>:</p>
<pre><code>$ time nix-instantiate --eval --strict ~/.config/nixpkgs/lib/all-attrs.nix -I nixpkgs=$PWD --arg maxDepth 2
...
[ &quot;AMB-plugins&quot; &quot;ArchiSteamFarm&quot; &quot;AusweisApp2&quot; &quot;BeatSaberModManager&quot;
  ...
  &quot;CuboCore.coreaction&quot; &quot;CuboCore.corearchiver&quot; &quot;CuboCore.corefm&quot;
  &quot;CuboCore.coregarage&quot;
  ...
  &quot;__splicedPackages.AMB-plugins&quot; &quot;__splicedPackages.ArchiSteamFarm&quot;
  ...
  &quot;pkgsLLVM.aaaaxy&quot; &quot;pkgsLLVM.aacgain&quot;
  ...
  &quot;pkgsHostTarget.zig_0_11&quot; &quot;pkgsHostTarget.zig_0_9&quot;
  ...
  &quot;zyn-fusion&quot; &quot;zynaddsubfx&quot; &quot;zynaddsubfx-fltk&quot; &quot;zynaddsubfx-ntk&quot; &quot;zz&quot;
  &quot;zziplib&quot; &quot;zzuf&quot; ]

real    1m4,845s
user    0m58,368s
sys     0m5,910s</code></pre>
<p>Second level also works! This time it took 25GB and a bit more than 1
minute to print the result. There are a few issues with it: some
attribute trees like <code>__splicedPackages</code> and <code>pkgsHostTarget</code> are
redundant. We already get attributes like <code>python3Packages.ninja</code>.
But are not quite at <code>pkgsCross.riscv64.re2c</code> yet.</p>
<h2 id="running-the-naive-lister-on-larger-depths">Running the naive lister on larger depths</h2>
<p>I ran the naive script above and derived the following fixes:</p>
<ul>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277117">PR 277117</a>:
<code>netbsd.libcurses</code> constructed invalid type of <code>NIX_CFLAGS_COMPILE</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/276984">PR 276984</a>:
<code>beam.packages.erlangR23</code> referred to non-existent <code>erlang_23</code>
attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/276985">PR 276985</a>:
<code>coq-kernel.launcher</code> used an alias instead of package name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/276995">PR 276995</a>:
<code>haskell.packages.ghc810.mod</code> used non-existent <code>mod_0_1_2_2</code> attribute
in it’s definition.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/276986">PR 276986</a>:
<code>dockerTools.tests.docker-tools</code> used an alias instead of actual name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277211">PR 277211</a>:
<code>nixosTests.nixops</code> had an unsatisfied function argument.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277355">PR 277355</a>:
<code>stdenv</code> used <code>abort</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277364">PR 277364</a>:
<code>python312Packages.array-record</code> accessed non-existent attribute.</li>
</ul>
<p>Getting 8 bugs just like that impressed me. I optimized lister a bit to
be able to descend into larger attribute depths and found a few more
bugs.</p>
<p>If you did not notice my lister script never attempted to explore any
attributes <strong>within</strong> derivations. If we pick a <code>re2c</code> example the
script would never get to <code>re2c.passthru.updateScript</code>.</p>
<p>And <code>passthru</code> are probably least tested attributes as they rarely used
by <code>hydra</code> CI. The <code>passthry.tests</code> in particular are <strong>not</strong> used by
<code>hydra</code> but are used by <code>ofborg</code> <code>GitHub</code> actions. And the caveat of
<code>ofborg</code> is that it rarely shows test failures as a red cross. Usually
it renders a failure as inconclusive gray. The assumption is that the
reviewer look at the underlying failure and makes a decision.</p>
<p>Thus I added a knob to descend into attributes of derivations
<a href="https://github.com/trofi/nixpkgs-overlays/commit/50ed200dc06ee1b6ec8ad8ca879a9948cc85135e">this way</a>:</p>
<pre class="diff"><code>--- a/lib/all-attrs.nix
+++ b/lib/all-attrs.nix
@@ -35,6 +35,11 @@
 , maxDepth

 , ignoreCross ? true
+
+# Whether to validate every attribute within derivations themselves.
+# Most intereting fields are `passthru.tests`, but sometimes there are
+# very unusual bugs lurking. Risky but very fun!
+, ignoreDrvAttrs ? true
 }:

 let
@@ -76,11 +81,9 @@ let
     in debug &quot;inspecting ${a}&quot; (
     if !e.success then info &quot;${a} fails to evaluate&quot; []
     else if lib.isDerivation v
-    # TODO: add an option to traverse into derivations as well.
-    # Mainly to test validity of `passthru.tests`, `metadata` and
-    # similar.
-    then [a] # TODO: &quot;++ maybe_go_deeper&quot;
+    then [a] ++ lib.optionals (!ignoreDrvAttrs) maybe_go_deeper
     # Skip &quot;foo = self;&quot; attributes like `pythonPackages.pythonPackages`
+    # TODO: might skip too much.
     else if lib.isAttrs v &amp;&amp; depth &gt; 0 &amp;&amp; lib.hasAttr (lib.last ap) v then info &quot;${a} is a repeated attribute, skipping&quot; []
     else if lib.isAttrs v then maybe_go_deeper
     else if isPrimitive v then []</code></pre>
<p>I also had to add a few ignored paths like <code>nixosTests</code> as they require
around <code>1GB</code> of extra <code>RAM</code> per test(!) and I had to skip <code>pkgsCross</code>
as it derives too many attributes for (still!) naive script to handle.</p>
<p>But even with such a limited lister I managed to get to these bugs:</p>
<ul>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277399">PR#277399</a>:
<code>bazel-watcher.bazel.tests</code> had a <code>optionalSttrs</code> typo instead of
<code>optionalAttrs</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277400">PR#277400</a>:
<code>bitcoind-knots</code> referred to non-existent test.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277402">PR#277402</a>:
<code>cargo</code> tried to pull tests for a package that does not define it.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277404">PR#277404)</a>:
<code>corosync</code> did not specify a test input argument that it used.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277408">PR#277408</a>:
<code>lua-wrapper</code> uses non-existent attributes to define paths.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277420">PR#277420</a>:
<code>displaylink</code> referred to non-existent test.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277434">PR#277434</a>:
<code>gnupg22</code> incorrectly refers to the test suite.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277435">PR#277435</a>:
<code>pisocsope.rules</code> looked <code>writeTextDir</code> in <code>lib</code> instead of <code>pkgs</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277473">PR#277473</a>:
<code>guacamole-client</code> was referring to deleted test.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277474">PR#277474</a>:
<code>mutmut</code> used <code>testers</code> attribute without use.
= <a href="https://github.com/NixOS/nixpkgs/pull/277494">PR#277494</a>:
<code>buildFHSEnv</code> did not fully handle <code>multiPaths = null</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277512">PR#277512</a>:
<code>owncast</code> referred to non-existent test.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277517">PR#277517</a>:
<code>python3Packages.pypaBuildHook.tests</code> test referred non-existent <code>.nix</code>
file.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277543">PR#277543</a>:
<code>pythonInterpreters.pypy39_prebuilt</code> referred to deleted <code>pypy38</code>
attribute, not <code>pypy39</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277580">PR#277580</a>:
<code>tigervnc.tests</code> referred to non-existent test.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277581">PR#277581</a>:
<code>wezterm.tests</code> referred to commented out tests.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277590">PR#277590</a>:
<code>devpod.tests</code> passed incorrect parameter to a test function.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277593">PR#277593</a>:
<code>fakeroot.tests</code> passed incorrect parameter to a test function.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277595">PR#277595</a>:
<code>findup.tests</code> passed incorrect parameter to a test function.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277600">PR#277600</a>:
<code>jellyfin-ffmpeg.tests</code> is missing <code>pkg-config</code> annotation.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277617">PR#277617</a>:
<code>build-support/go</code> code constructed inaccessible <code>vendorSha256</code>
attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277715">PR#277715</a>:
<code>octoprint</code> referred to non-existent attribute in <code>tests</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277741">PR#277741</a>:
<code>pypy2Packages.attrs</code> refers non-existent <code>.nix</code> file.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277751">PR#277751</a>:
<code>python3Packages.openllm</code>: fix <code>passthru</code> dependency references and
fix variable shadowing.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277777">PR#277777</a>:
<code>python3Packages.openllm-client</code>: fix <code>passthru</code> dependency references.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277788">PR#277788</a>:
<code>python3Packages.openllm-core</code>: fix <code>passthru</code> dependency references.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277880">PR#277880</a>:
<code>valhalla</code> was missing <code>pkgConfigModules</code> definition.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277899">PR#277899</a>:
<code>zammad.src.meta</code> failed to evaluate due to incorrect position
assumption: no metadata attributes were defined in the <code>.nix</code> files.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277973">PR#277973</a>:
<code>ruff.tests</code> referred <code>ruff-lsp</code> alias instead of direct name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/277982">PR#277982</a>:
<code>spark.tests</code>: referred to <code>nixosTest</code> alias.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278034">PR#278034</a>:
<code>nixosTests.kernel-generic</code> attempted to use <code>bool</code> value as a kernel
derivation.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278044">PR#278044</a>:
<code>aaxtomp3</code>: fix invalid reference to <code>glibc</code> for non-<code>glibc</code> targets.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278069">PR#278069</a>:
<code>haskell.packages.ghc810</code> refer to non-existent packages.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278074">PR#278074</a>:
<code>haskell.packages.ghc865Binary</code> refer to non-existent packages.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278076">PR#278076</a>:
<code>haskell.packages.ghc98</code> refer to non-existent packages.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278224">PR#278224</a>:
<code>haskell.packages.ghcjs</code> lacks <code>llvmPackages</code> attribute implied by
<code>ghc-8.10</code> packages.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278528">PR#278528</a>:
<code>python3Packages.paddlepaddle</code>: unhandled error in <code>src</code> attribute
dereference.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278915">PR#278915</a>:
<code>nvidia-x11</code> unconditionally refers to <code>/share/</code> even if libraries are
the only enabled bit.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/278950">PR#278950</a>:
<code>pythonInterpreters.pypy39_prebuilt</code> failed the <code>test</code> evaluation as
it exposed unhandled <code>pythonAttr = null</code> value. The test expected a
real object.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/279018">PR#279018</a>:
<code>systemd.tests.systemd-journal-upload</code> has invalid maintainer
specified.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/279404">PR#279404</a>:
<code>llvmPackages.bintools.bintools</code> did not define expected
<code>targetPackages</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/279463">PR#279463</a>:
<code>stdenv.adapters</code>: fix <code>overrideLibcxx</code> definition.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/280319">PR#280319</a>:
<code>rubyModules</code> defined <code>gemType</code> via non-existent sets.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/280470">PR#280470</a>:
<code>pkgsLLVM.dmd</code> accessed non-existent <code>libgcc</code> attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/283737">PR#283737</a>:
<code>tests.cross.sanity</code> referred non-existent <code>qt5.qutebrowser</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/289397">PR#289397</a>:
<code>nixosTests.keepalived</code> defined <code>maintainers</code> attribute in an
incorrect scope.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/292677">PR#292677</a>:
<code>distrobuilder.tests</code> referred renamed test attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/292762">PR#292762</a>:
<code>lxc.tests</code> referred renamed test attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/295431">PR#295431</a>:
<code>pypy27Packages.pulsar-client</code> dereferenced non-existent attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/295448">PR#295448</a>:
<code>ttyd.tests</code> referred unmentioned <code>nixosTests</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/296264">PR#296264</a>:
<code>python3.pkgs.openllm-core.optional-dependencies.full</code> referred
renamed attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/296497">PR#296497</a>:
<code>apptainer.gpuChecks.saxpy</code> refers the attribute from the wrong place.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/305811">PR#305811</a>:
<code>lxd.ui</code> is an export of non-=existent attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/305843">PR#305843</a>:
<code>pypy27Packages.pluthon</code> used invalid form of <code>lib.optionals</code> call.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/305925">PR#305925</a>:
<code>redlib.tests</code> referred non-existent <code>nixosTests.redlib</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/313791">PR#313791</a>:
<code>haskell.packages.ghc865Binary.exceptions</code> referred to missing package.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/313792">PR#313792</a>:
<code>haskell.packages.ghcjs.exceptions</code> referred to missing package.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/314092">PR#314092</a>:
<code>nextcloud-notify_push.tests</code> referred to missing package.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/314109">PR#314109</a>:
<code>githooks.tests</code> used invalid parameter to <code>testers.testVersion</code> helper.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/314196">PR#314196</a>:
<code>nixVersions.git.tests</code> used invalid attribute name when defined tests.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/317956">PR#317956</a>:
<code>lix.tests</code> failed to evaluate as it tried to use non-existent
attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/319518">PR#319518</a>:
<code>ollama.tests</code> used incorrect construct to merge attributes.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/325111">PR#325111</a>:
<code>nextcloud-notify_push.tests</code> referred already deleted attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/329253">PR#329253</a>:
<code>autoprefixer.tests</code> refers to renamed attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/329490">PR#329490</a>:
<code>pypy27Packages.corner.nativeBuildInputs</code> refers non-existent attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/329505">PR#329505</a>:
<code>pypy27Packages.ray.optional-dependencies</code> refers to non-existent
attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/329511">PR#329511</a>:
<code>python3Packages.pytorch-bin.tests</code> passes non-existent parameters.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/329512">PR#329512</a>:
<code>pypy27Packages.pyreqwest-impersonate</code> defines non-optional attributes
as optional.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/329515">PR#329515</a>:
<code>varnish60Packages.modules</code> used invalid <code>hash</code> format.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/331682">PR#331682</a>:
<code>nixosTests.bittorrent</code> used an alias in package inputs.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/332822">PR#332822</a>:
<code>octave.buildEnv</code> called the function with undefined attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/337406">PR#337406</a>:
<code>apacheKafka.tests</code> referred to a broken attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/337728">PR#337728</a>:
<code>tectonic.tests</code> referred to a non-existent attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/338559">PR#338559</a>:
<code>pypy27Packages.incremental</code> constructs incorrect derivation with an
associative array field.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/338596">PR#338596</a>:
<code>pypy2Packages.python-engineio-v3</code> constructs incorrect derivation with an
associative array field.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/338597">PR#338597</a>:
<code>pypy2Packages.python-socketio-v4</code> constructs incorrect derivation with an
associative array field.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/341497">PR#341497</a>:
<code>dotnet/build-dotnet-module</code> fails to handle missing <code>pname</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/341985">PR#341985</a>:
<code>perlInterpreters.perl536</code> requires already deleted attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/346336">PR#346336</a>:
<code>libtorrent</code> and <code>rtorrent</code> <code>updaterScript</code> passed non-existent
parameters.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/346689">PR#346689</a>:
<code>nix-plugin-pijul.tests</code> fix the invalid attribute reference.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/346746">PR#346746</a>:
<code>python3Packages.sshfs.optional-dependencies.pkcs11</code> fix incorrect
attribute name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/347172">PR#347172</a>:
<code>python3Packages.sshfs.optional-dependencies.pyopenssl</code>: fix incorrect
attribute name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/347439">PR#347439</a>:
<code>python3Packages.ifcopenshell.tests</code> did not pass enough parameters.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/348104">PR#348104</a>:
<code>faiss.passthru</code> attributes were dropped without removing references
to it.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/352825">PR#352825</a>:
<code>pyamlboot.tests</code> passed the parameter if incorrect type.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/355051">PR#355051</a>:
<code>pypy3Packages.home-assistant-chip-clusters</code> dereferenced <code>null</code>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/361669">PR#361669</a>:
<code>kubernetes-kcp.tests</code> was not passing a required parameter.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/367950">PR#367950</a>:
<code>darktable</code> update script was called with incorrect parameters.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/368853">PR#368853</a>:
<code>haskell.packages.ghc865Binary.exceptions</code> uses invalid attribute name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/368899">PR#368899</a>:
<code>haskell.packages.ghcjs.exceptions</code> uses invalid attribute name.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/372859">PR#372859</a>:
<code>pre-commit.tests</code> was not updated to use <code>gitMinimal</code> attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/374899">PR#374899</a>:
<code>redict.tests</code> definition uses non-existent test reference.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/377693">PR#377693</a>:
<code>python3Packages.langchain-ollama</code> used non-existent attribute names.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/384282">PR#384282</a>:
<code>matrix-synapse.tools</code> referred to already deleted attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/385653">PR#385653</a>:
<code>lego.tests</code> refers to non-existent test.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/389369">PR#389369</a>:
<code>nixosTests.floorp</code> referred to unavailable attribute</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/397002">PR#397002</a>:
<code>apacheKafka.tests</code> referred to wrong attribute</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/399997">PR#399997</a>:
<code>python3Packages.ray</code> built infinite recursion</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/400179">PR#400179</a>:
<code>zed-editor.tests</code> refers to non-existent attribute.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/400739">PR#400739</a>:
<code>darwin.moltenvk</code> dereferences <code>null</code> on some targets.</li>
</ul>
<p>Note: It’s not the full list of required fixes. For more complex cases I
filed a few bugs to get maintainers’ help:</p>
<ul>
<li><a href="https://github.com/NixOS/nixpkgs/issues/277285">Issue#277285</a>:
<code>pkgsStatic.php</code> enters infinite loop and exhausts all available
memory.</li>
<li><a href="https://github.com/NixOS/nixpkgs/issues/277628">Issue#277628</a>:
<code>godot3-mono.nugetSource.meta</code> detects infinite recursion on
evaluation.</li>
<li><a href="https://github.com/NixOS/nixpkgs/issues/277698">Issue#277698</a>:
<code>ocamlPackages.janeStreet_0_15</code> has unsatisfied attributes.</li>
<li><a href="https://github.com/NixOS/nixpkgs/issues/280377">Issue#280377</a>:
<code>tests.cuda</code> has an unsatisfied <code>backendStdenv</code> attribute.</li>
</ul>
<h2 id="did-i-get-the-list-package-for-autoconf">Did I get the list package for <code>autoconf</code>?</h2>
<p>Sort of: I managed to write the hack to get a list of packages using
<code>autoconf</code> in a few layers deep below top level. It’s good enough for
testing close to exhaustive.</p>
<p>But I did not get exhaustive at all. There are two main problems still:</p>
<ol type="1">
<li><p>The attribute sets are infinite in <code>nixpkgs</code>. An example a bit silly
but still valid attribute is:</p>
<pre><code>nix-repl&gt; pkgs.pkgs.pkgs.pkgsCross.riscv64.pkgsMusl.pkgsCross.riscv64.pythonPackages.pythonPackages.pythonPackages.ninja
«derivation /nix/store/4vnprl12q706s3ilb1g1c2v4bf9pjpc9-ninja-1.11.1.drv»`</code></pre>
<p><code>nix</code> the language does not provide the mechanism to compare
references to shortcut things like <code>pythonPackages.pythonPackages</code>
And each scope has those self-referential package structures.</p></li>
<li><p>Even if the attribute set was finite in <code>&lt;nixpkgs&gt;</code> the mere act of
listing them takes 100s of GB. It looks like it’s because <code>nix</code> does
not collect already evaluated garbage expressions that still have
references from other parts of the tree. The packages loops in
<code>nixpkgs</code> from <code>[1.]</code> do not help in that at all.</p></li>
</ol>
<p>I am still hopeful that I can get something decent soon. I can
workaround <code>[2.]</code> <code>RAM</code> exhaustion by declaring defeat on a single
<code>.nix</code> script and run it in incremental mode. Say, to process 100
packages at a time to avoid infinite memory growth.</p>
<p>Another option would be to write a separate tool using <code>nix</code> as a
library to parse and evaluate <code>.nix</code> code that does this job
specifically. But I’d prefer to try to fix <code>nix</code> <code>GC</code> behaviour first. I
think it’s tractable.</p>
<h2 id="parting-words">Parting words</h2>
<p>Traversing package attribute set in <code>nixpkgs</code> is surprisingly
challenging. I think it is fixable and should be fixed (at least for
non-<code>pkgsCross.*</code> part of the tree). Fetching metadata about the
packages is a frequent operation for many types of tree-wide changes.</p>
<p>I had a lot of fun writing debuggable <code>.nix</code> code to list available
<code>nixpkgs</code> attributes. So far my result is hiding at
<a href="https://github.com/trofi/nixpkgs-overlays/blob/main/lib/all-attrs.nix" class="uri">https://github.com/trofi/nixpkgs-overlays/blob/main/lib/all-attrs.nix</a>.</p>
<p>So far I managed to get to 4 levels of attribute depth using <code>60GB</code> of
<code>RAM</code>. This uncovered at least 27 bugs.</p>
<p>Some of the bugs are very scary:</p>
<ul>
<li><code>cargo</code> did not have tests: <a href="https://github.com/NixOS/nixpkgs/pull/277402" class="uri">https://github.com/NixOS/nixpkgs/pull/277402</a></li>
<li><code>lua-wrapper</code> did not expose correct paths: <a href="https://github.com/NixOS/nixpkgs/pull/277408" class="uri">https://github.com/NixOS/nixpkgs/pull/277408</a></li>
</ul>
<p><code>builtins.tryEval</code> does not catch all the failure types in attribute
evaluation: <code>throw</code> / <code>assert</code> are fine, but reference to non-existent
attribute (or <code>assert</code>) are not.</p>
<p><code>pkgs.nixosTests</code> attribute set is very slow and RAM hungry to evaluate:
<a href="https://github.com/NixOS/nix/issues/9671" class="uri">https://github.com/NixOS/nix/issues/9671</a></p>
<p>You can also fix a few <code>nixpkgs</code> bugs! Just run <code>all-attrs.nix</code> as:</p>
<pre><code>$ nix-instantiate --eval --strict ./all-attrs.nix \
    -I nixpkgs=~/path/to/nicpkgs \
    --arg maxDepth 2 --arg verbose 3 --arg ignoreDrvAttrs false</code></pre>
<p>And see what you get.</p>
<p>Next steps I’d like to take at some future point:</p>
<ul>
<li>batch package listing and package instantiation in smaller batches to
get RAM usage down to a few <code>GB</code>s.</li>
<li>explore <code>nix</code> and garbage collection mechanisms to make it friendlier
to large evaluations like <code>all-attrs.nix</code></li>
</ul>
<p>Have fun!</p>]]></description>
    <pubDate>Sat, 30 Dec 2023 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/309-listing-all-nixpkgs-packages.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>a breakage example in C variadic function</title>
    <link>http://trofi.github.io/posts/308-a-breakage-example-in-c-variadic-function.html</link>
    <description><![CDATA[<h2 id="intro">Intro</h2>
<p>This post is about <code>C</code> functions with ellipsis (<code>...</code>) in their
signatures. The most famous example of such is probably <code>printf()</code>:</p>
<pre class="c"><code>int printf(const char *format, ...);</code></pre>
<p>If you ever tried to use it you probably know that using wrong types
that don’t match format arguments might crash your program. A simple
faulty example could be:</p>
<pre class="c"><code>printf(&quot;%s&quot;, 42); // this will crash</code></pre>
<p>Luckily <code>gcc</code> and <code>clang</code> do have <code>-Wformat</code> warning that complains
about the mismatch between expected types by a format string and
actually passed types:</p>
<pre class="c"><code>// $ cat simple.c
#include &lt;stdio.h&gt;

int main(void) {
    printf(&quot;%s&quot;, 42);
}</code></pre>
<pre><code>$ gcc -Wformat -c simple.c

simple.c: In function 'main':
simple.c:5:14: warning: format '%s' expects argument of type 'char *', but argument 2 has type 'int' [-Wformat=]
    5 |     printf(&quot;%s&quot;, 42);
      |             ~^   ~~
      |              |   |
      |              |   int
      |              char *
      |             %d</code></pre>
<p>Many distributions turn these warnings into errors by default.</p>
<h2 id="argument-count">Argument count</h2>
<p>An ellipsis (<code>...</code>) means that the function accepts unknown count and
unknown type of parameters. There has to be a way to somehow signal
actual argument list in ellipsis. As <code>&lt;stdarg.h&gt;</code> does not provide a
standard way to do it code author has to come up with their own scheme
to solve the problem.</p>
<p>A few examples come to mind:</p>
<ul>
<li><code>int printf(const char *format, ...)</code> uses <code>format</code> parameter to pass
the argument count by interpreting the format string.</li>
<li><code>int open(const char *pathname, int flags, mode_t mode)</code> uses <code>flags</code>
to distinguish 3-argument form from 2-argument
<code>int open(const char *pathname, int flags)</code>.</li>
<li><code>glib</code>’s <code>gchar* g_strconcat (const gchar* string1, ...)</code> consumes
parameters until <code>NULL</code> parameter is encountered.</li>
</ul>
<p>Each of the examples above implements a different scheme.</p>
<p><code>g_strconcat</code> is especially scary as you might pass non-strings there
and get no warning from the compiler. Or forget to pass a <code>NULL</code> value
(<a href="https://github.com/proftpd/proftpd/pull/1028/files"><code>proftpd</code> example</a>
comes to mind). But at least all the arguments are expected to have the
same <code>const gchar*</code> type.</p>
<p>But the above is not an exhaustive list. You can bake any assumption
into ellipsis meaning.</p>
<h2 id="an-example-of-variadic-c-function">An example of variadic C function</h2>
<p>I’ll use yet another (arguably the simplest) form to pass argument count
to a variadic function: I’ll pass the number explicitly. Let’s explore
the following example:</p>
<pre class="c"><code>#include &lt;stdarg.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void foo(int n, ...) {
    va_list va;

    va_start(va, n);
    for (int i = 0; i &lt; n; i++) {
        size_t l = va_arg(va, size_t);
        printf(&quot;[%u]: %zu\n&quot;, i, l);
    }
    va_end(va);
}

int main(void) {
    foo(3, strlen(&quot;foo&quot;), strlen(&quot;barr&quot;), strlen(&quot;bazzz&quot;));
}</code></pre>
<p>Here we explicitly pass count of variadic arguments as the first <code>n</code>
parameter of the <code>foo()</code> function. The program should be correct.</p>
<p>Running it:</p>
<pre><code>$ gcc a.c -o a &amp;&amp;./a
[0]: 3
[1]: 4
[2]: 5</code></pre>
<p>All good.</p>
<p>Now I’ll change the above program slightly:</p>
<pre class="c"><code>#include &lt;stdarg.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void foo(int n, ...) {
    va_list va;

    va_start(va, n);
    for (int i = 0; i &lt; n; i++) {
        size_t l = va_arg(va, size_t);
        printf(&quot;[%u]: %zu\n&quot;, i, l);
    }
    va_end(va);
}

int main(void) {
    foo(3, 3, 4, 5);
}</code></pre>
<p>I inlined the results of <code>strlen()</code> calls to their literal values. Is it
still a correct program? Is it always expected to print <code>3 4 5</code>?</p>
<p>Let’s run it:</p>
<pre><code>$ gcc a.c -o a &amp;&amp;./a
[0]: 3
[1]: 4
[2]: 5</code></pre>
<p>Seems to work. Let’s throw more arguments just for fun:</p>
<pre class="c"><code>// $ cat a.c
#include &lt;stdarg.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void foo(int n, ...) {
    va_list va;

    va_start(va, n);
    for (int i = 0; i &lt; n; i++) {
        size_t l = va_arg(va, size_t);
        printf(&quot;[%u]: %zu\n&quot;, i, l);
    }
    va_end(va);
}

int main() {
    foo(16, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16);
}</code></pre>
<p>I increased argument count to <code>16</code>. Running it on <code>x86_64</code>:</p>
<pre><code>$ gcc a.c -o a &amp;&amp;./a
[0]: 1
[1]: 2
[2]: 3
[3]: 4
[4]: 5
[5]: 6
[6]: 7
[7]: 8
[8]: 9
[9]: 10
[10]: 11
[11]: 12
[12]: 13
[13]: 14
[14]: 15
[15]: 16</code></pre>
<p>Still all good!</p>
<p>Running on <code>aarch64-linux</code> just in case:</p>
<pre><code>$ aarch64-unknown-linux-gnu-gcc a.c -o a &amp;&amp;./a
[0]: 1
[1]: 2
[2]: 3
[3]: 4
[4]: 5
[5]: 6
[6]: 7
[7]: 70368744177672
[8]: 70368744177673
[9]: 70368744177674
[10]: 70368744177675
[11]: 70368744177676
[12]: 13
[13]: 70368744177678
[14]: 15
[15]: 70368744177680</code></pre>
<p>Uh-oh. It’s broken!</p>
<p>What is worse: first seven parameters look totally fine and degradation
start only <code>8th</code> one. Is it a coincidence? Some architecture-specific
property? Or maybe a compiler bug?</p>
<p>Or maybe you noticed a bug in the original program? How would you fix it
or work it around?</p>
<h2 id="argument-passing-mechanics">Argument passing mechanics</h2>
<p>Let’s have a look at the generated code and check how parameters are
passed across the call boundary. I’ll use the same <code>17</code>-argument example
above:</p>
<pre class="c"><code>#include &lt;stdarg.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void foo(int n, ...) {
    va_list va;

    va_start(va, n);
    for (int i = 0; i &lt; n; i++) {
        size_t l = va_arg(va, size_t);
        printf(&quot;[%u]: %zu\n&quot;, i, l);
    }
    va_end(va);
}

int main(void) {
    foo(16, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16);
}</code></pre>
<h2 id="x86_64"><code>x86_64</code></h2>
<p>Full <code>x86_64</code> code on <code>gcc</code> looks this way:</p>
<pre class="asm"><code>; gcc -O1 -S a.c -o -

main:
        subq    $16, %rsp
        ; push some of the arguments on stack:
        pushq   $16 ; va[15] = 16
        pushq   $15 ; va[14] = 15
        pushq   $14 ; va[13] = 14
        pushq   $13 ; va[12] = 13
        pushq   $12 ; va[11] = 12
        pushq   $11 ; va[10] = 11
        pushq   $10 ; va[9] = 10
        pushq   $9  ; va[8] = 9
        pushq   $8  ; va[7] = 8
        pushq   $7  ; va[6] = 7
        pushq   $6  ; va[5] = 6

        movl    $5, %r9d  ; va[4] = 5
        movl    $4, %r8d  ; va[3] = 4
        movl    $3, %ecx  ; va[2] = 3
        movl    $2, %edx  ; va[1] = 2
        movl    $1, %esi  ; va[0] = 1
        movl    $16, %edi ; n = 16

        movl    $0, %eax
        call    foo
        movl    $0, %eax
        addq    $104, %rsp
        ret

.LC0:
        .string &quot;[%u]: %zu\n&quot;

foo:
        pushq   %rbp
        pushq   %rbx
        subq    $88, %rsp
        movq    %rsi, 40(%rsp)
        movq    %rdx, 48(%rsp)
        movq    %rcx, 56(%rsp)
        movq    %r8, 64(%rsp)
        movq    %r9, 72(%rsp)
        movl    $8, 8(%rsp)
        leaq    112(%rsp), %rax
        movq    %rax, 16(%rsp)
        leaq    32(%rsp), %rax
        movq    %rax, 24(%rsp)
        testl   %edi, %edi
        jle     .L1
        movl    %edi, %ebp
        movl    $0, %ebx
        jmp     .L5
.L3:
        movq    16(%rsp), %rdx
        leaq    8(%rdx), %rax
        movq    %rax, 16(%rsp)
.L4:
        movq    (%rdx), %rdx  ; size_t l = va_arg(va, size_t);
        movl    %ebx, %esi    ; int i (loop variable)
        movl    $.LC0, %edi   ; format = &quot;%[u]: %zu\n&quot;
        movl    $0, %eax
        call    printf
        addl    $1, %ebx
        cmpl    %ebx, %ebp
        je      .L1
.L5:
        movl    8(%rsp), %eax
        cmpl    $47, %eax
        ja      .L3
        movl    %eax, %edx
        addq    24(%rsp), %rdx
        addl    $8, %eax
        movl    %eax, 8(%rsp)
        jmp     .L4
.L1:
        addq    $88, %rsp
        popq    %rbx
        popq    %rbp
        ret</code></pre>
<p>It’s a lot of text! We can ignore most of it and focus on the following
few lines to get to the argument passing mechanics:</p>
<pre class="asm"><code>main:
        ; ...
        pushq   $6  ; va[5] = 6
        movl    $5, %r9d  ; va[4] = 5
        ; ...

foo:
        ; ...
        movq    (%rdx), %rdx  ; size_t l = va_arg(va, size_t);
        movl    %ebx, %esi    ; int i (loop variable)
        movl    $.LC0, %edi   ; format = &quot;%[u]: %zu\n&quot;
        movl    $0, %eax
        call    printf
        ; ...</code></pre>
<p>The <code>main</code> function is trivial: it shows us that first 6 arguments are
passed in registers alone (<code>%edi = 16</code>, <code>%esi = 1</code>, <code>%edx = 2</code>,
<code>%ecx = 3</code>, <code>%r8d = 4</code> <code>%r9d = 5</code>). And starting from <code>7</code>th argument
they are passed via stack (<code>pushq $6</code>). This is a standard
<code>x86_64-linux</code> calling convention.</p>
<p>The <code>foo</code> is more complicated. The gist of it is that our <code>va_arg</code>
always gets fetched from stack as a 64-bit value via <code>movq (%rdx), %rdx</code>
instruction. To make it work <code>foo</code> stores all register-passed arguments
on stack. The fetch result gets passed later as a third argument to
<code>printf("%[u]: %zu\n", i, l)</code> call in <code>%rdx</code> register.</p>
<p>A few notes before we continue:</p>
<p>Instructions like <code>movl $1, %esi</code> tell the CPU to store <code>$1</code> to
32-bit <code>esi</code> register (lower half of <code>rsi</code> register). <code>movl</code> (or any
other write instruction that works on 32-bit registers) also zeroes out
upper 64-bits of <code>rsi</code> register. Thus it’s a functional equivalent of
<code>movq $1, %rsi</code>. But the encoding might be more efficient as it does not
need a <code>REX</code> prefix.</p>
<p>Instructions like <code>pushq $6</code> write full 64-bit constant on stack as if
we pushed full <code>size_t</code> value instead of <code>int</code>.</p>
<p>In both register store and memory store cases <code>int</code> literals are stored
as 64-bit values. This means that on <code>x86_64</code> it’s not too bad to mix
these two types as the example does.</p>
<h2 id="aarch64"><code>aarch64</code></h2>
<p>Now let’s do the same exercise for <code>aarch64</code> target:</p>
<pre class="asm"><code>; aarch64-unknown-linux-gnu-gcc -O1 -S a.c -o -
main:
        sub     sp, sp, #96
        stp     x29, x30, [sp, 80]
        add     x29, sp, 80
        mov     w0, 16 ; n = 16
        str     w0, [sp, 64] ; va[15] = 16
        mov     w1, 15
        str     w1, [sp, 56] ; va[14] = 15
        mov     w1, 14
        str     w1, [sp, 48] ; va[13] = 14
        mov     w1, 13
        str     w1, [sp, 40] ; va[12] = 13
        mov     w1, 12
        str     w1, [sp, 32] ; va[11] = 12
        mov     w1, 11
        str     w1, [sp, 24] ; va[10] = 11
        mov     w1, 10
        str     w1, [sp, 16] ; va[9]  = 10
        mov     w1, 9
        str     w1, [sp, 8]  ; va[8]  = 9
        mov     w1, 8
        str     w1, [sp]     ; va[7]  = 8
        mov     w7, 7        ; va[6]  = 7
        mov     w6, 6        ; va[5]  = 6
        mov     w5, 5        ; va[4]  = 5
        mov     w4, 4        ; va[3]  = 4
        mov     w3, 3        ; va[2]  = 3
        mov     w2, 2        ; va[1]  = 2
        mov     w1, 1        ; va[0]  = 1
        bl      foo
        mov     w0, 0
        ldp     x29, x30, [sp, 80]
        add     sp, sp, 96
        ret

.LC0:
        .string &quot;[%u]: %zu\n&quot;

foo:
        stp     x29, x30, [sp, -144]!
        mov     x29, sp
        stp     x19, x20, [sp, 16]
        mov     w20, w0
        str     x1, [sp, 88]
        str     x2, [sp, 96]
        str     x3, [sp, 104]
        str     x4, [sp, 112]
        str     x5, [sp, 120]
        str     x6, [sp, 128]
        str     x7, [sp, 136]
        add     x0, sp, 144
        str     x0, [sp, 48]
        str     x0, [sp, 56]
        add     x0, sp, 80
        str     x0, [sp, 64]
        mov     w0, -56
        str     w0, [sp, 72]
        str     wzr, [sp, 76]
        cmp     w20, 0
        ble     .L1
        str     x21, [sp, 32]
        mov     w19, 0
        adrp    x21, .LC0
        add     x21, x21, :lo12:.LC0
        b       .L6
.L3:
        add     w0, w2, 8
        str     w0, [sp, 72]
        cmp     w0, 0
        ble     .L5
        add     x0, x1, 15
        and     x0, x0, -8
        str     x0, [sp, 48]
.L4:
        ldr     x2, [x1] ; size_t l = va_arg(va, size_t);
        mov     w1, w19  ; int i (loop variable)
        mov     x0, x21  ; format = &quot;%[u]: %zu\n&quot;
        bl      printf
        add     w19, w19, 1
        cmp     w20, w19
        beq     .L9
.L6:
        ldr     w2, [sp, 72]
        ldr     x1, [sp, 48]
        tbnz    w2, #31, .L3
        add     x2, x1, 15
        and     x2, x2, -8
        str     x2, [sp, 48]
        b       .L4
.L5:
        ldr     x1, [sp, 56]
        add     x1, x1, w2, sxtw
        b       .L4
.L9:
        ldr     x21, [sp, 32]
.L1:
        ldp     x19, x20, [sp, 16]
        ldp     x29, x30, [sp], 144
        ret</code></pre>
<p>Again, it’s a lot of repetitive text. We can ignore most of it and focus
on arguments passed over call boundary:</p>
<pre class="asm"><code>main:
        ; ...
        mov     w1, 8
        str     w1, [sp]     ; va[7]  = 8
        mov     w7, 7        ; va[6]  = 7
        mov     w6, 6        ; va[5]  = 6

foo:
        ; ...
        ldr     x2, [x1] ; size_t l = va_arg(va, size_t);
        mov     w1, w19  ; int i (loop variable)
        mov     x0, x21  ; format = &quot;%[u]: %zu\n&quot;
        bl      printf</code></pre>
<p>The <code>main</code> structure is very similar to <code>x86_64</code>: first few parameters
(<code>8</code> this time) get passed via registers: <code>w0 = 16</code>, <code>w1 = 1</code>, <code>w2 = 2</code>,
…. <code>w7 = 7</code>. The rest goes to stack: <code>mov w1, 8</code> / <code>str w1, [sp]</code>,
<code>mov w1, 9</code> / <code>str w1, [sp, 8]</code>, and so on.</p>
<p>Similarly to <code>x86_64</code> the instruction <code>mov w1, 1</code> sets lower 32-bit part
of 64-bit <code>x1</code> register to an immediate value. Higher 32-bit part is
zeroed out. This makes it equivalent to <code>mov x1, 1</code> instruction.</p>
<p>The difference starts in the way stack variables are stored: while
<code>mov w1, 8</code> initializes both <code>w1</code> and <code>x1</code> to value <code>8</code> the
<code>str w1, [sp]</code> instruction writes only 32 bits of value on stack. Upper
32 bits of stack value contain existing value (some garbage). If we
wanted to fix it then <code>str x1, [sp]</code> would place all <code>64</code> bits as. In
theory <code>gcc</code> could have used that instruction even for your unmodified
case. But it does not have to.</p>
<p>This is our corruption mechanic: we store 32 bits on stack for
parammeters <code>8</code> and above and then read 64-bit values from store
locations in <code>C</code> pseudo-code:</p>
<pre class="c"><code>// main():
    // ...
    int val;
    size_t location = uninitialized();
    // ...
    *(int*)(&amp;location) = val; // store 32 initialized bits
// foo():
    // ...
    size_t result = *(size_t*)(&amp;location); // load 64 bits</code></pre>
<h2 id="possible-fix">Possible fix</h2>
<p>Once the breakage is clear the fix is simple: use exact expected type
at call site. In this case <code>size_t</code> instead of <code>int</code>:</p>
<pre class="diff"><code>--- a.c
+++ a.fixed.c
@@ -16,3 +16,3 @@
 int main() {
-    foo(16, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16);
+    foo(16, (size_t)1,(size_t)2,(size_t)3,(size_t)4,(size_t)5,(size_t)6,(size_t)7,(size_t)8,(size_t)9,(size_t)10,(size_t)11,(size_t)12,(size_t)13,(size_t)14,(size_t)15,(size_t)16);
 }</code></pre>
<p>Not the prettiest change, but it gets the job done:</p>
<pre><code>$ aarch64-unknown-linux-gnu-gcc -O1 a.fixed.c -o a &amp;&amp; ./a
[0]: 1
[1]: 2
[2]: 3
[3]: 4
[4]: 5
[5]: 6
[6]: 7
[7]: 8
[8]: 9
[9]: 10
[10]: 11
[11]: 12
[12]: 13
[13]: 14
[14]: 15
[15]: 16</code></pre>
<p>The code change looks as expected:</p>
<pre class="diff"><code>diff -U0 a.S a.fixed.S
--- a.S 2023-12-17 23:51:24.749893552 +0000
+++ a.fixed.S   2023-12-17 23:51:29.687979158 +0000
@@ -2 +2 @@
-       .file   &quot;a.c&quot;
+       .file   &quot;a.fixed.c&quot;
@@ -102,13 +102,13 @@
-       mov     w0, 16
-       str     w0, [sp, 64]
-       mov     w1, 15
-       str     w1, [sp, 56]
-       mov     w1, 14
-       str     w1, [sp, 48]
-       mov     w1, 13
-       str     w1, [sp, 40]
-       mov     w1, 12
-       str     w1, [sp, 32]
-       mov     w1, 11
-       str     w1, [sp, 24]
-       mov     w1, 10
-       str     w1, [sp, 16]
-       mov     w1, 9
-       str     w1, [sp, 8]
-       mov     w1, 8
-       str     w1, [sp]
+       mov     x0, 16
+       str     x0, [sp, 64]
+       mov     x1, 15
+       str     x1, [sp, 56]
+       mov     x1, 14
+       str     x1, [sp, 48]
+       mov     x1, 13
+       str     x1, [sp, 40]
+       mov     x1, 12
+       str     x1, [sp, 32]
+       mov     x1, 11
+       str     x1, [sp, 24]
+       mov     x1, 10
+       str     x1, [sp, 16]
+       mov     x1, 9
+       str     x1, [sp, 8]
+       mov     x1, 8
+       str     x1, [sp]
@@ -119,7 +119,7 @@
-       mov     w7, 7
-       mov     w6, 6
-       mov     w5, 5
-       mov     w4, 4
-       mov     w3, 3
-       mov     w2, 2
-       mov     w1, 1
+       mov     x7, 7
+       mov     x6, 6
+       mov     x5, 5
+       mov     x4, 4
+       mov     x3, 3
+       mov     x2, 2
+       mov     x1, 1</code></pre>
<p>Only <code>main</code> saw the change. The change is shift from 32-bit to 64-bit
registers in value assignments and value stores.</p>
<h2 id="is-this-bug-real">Is this bug real?</h2>
<p>The main takeaway from the above is that on <code>aarch64</code> arguments <code>9</code> and
above must not mix <code>int</code> / <code>size_t</code> and pass exact type if those
arguments are present in variadic template.</p>
<p>Could such bug happen on real code or 9 arguments are too much to be
seen in the wild? Guess how I found this obscurity!</p>
<p>Here is the <a href="https://git.kernel.org/pub/scm/network/wireless/iwd.git/tree/src/dpp-util.c?h=2.11#n1379"><code>iwd-0.11</code></a> code:</p>
<pre class="c"><code>bool prf_plus(enum l_checksum_type type, const void *key, size_t key_len,
              void *out, size_t out_len,
              size_t n_extra, ...)
{
    // ...
    struct iovec iov[n_extra + 2];
    va_list va;
    size_t i;

    va_start(va, n_extra);

    for (i = 0; i &lt; n_extra; i++) {
        iov[i + 1].iov_base = va_arg(va, void *);
        iov[i + 1].iov_len  = va_arg(va, size_t);
    }
    // ...
}
// ...
bool dpp_derive_z(const uint8_t *mac_i, more params, void *z_out, size_t *z_len)
{
    // ...
    prf_plus(sha, prk, bytes, z_out, bytes,
             5,
             mac_i, 6,
             mac_r, 6,
             m_x, bytes,
             n_x, bytes,
             key, strlen(key));</code></pre>
<p>Do you see where the thing breaks?</p>
<p>Here <code>prf_plus()</code> expects <code>n_extra</code> pairs of <code>void *</code> / <code>size_t</code> in the
variadic arguments. But <code>dpp_derive_z()</code> passes <code>void *</code> / <code>int</code> as
first two pairs.</p>
<p>I would never notice it if not for mysteriously failing <code>iwd</code> test on
<code>aarch64</code> platform:</p>
<pre><code>    $ unit/test-dpp
    TEST: DPP test responder-only key derivation
    TEST: DPP test mutual key derivation
    TEST: DPP test PKEX key derivation
    test-dpp: unit/test-dpp.c:514: test_pkex_key_derivation: Assertion `!memcmp(tmp, __tmp, 32)' failed.</code></pre>
<p><code>strace</code> shown the smoking gun this way:</p>
<pre><code>$ strace unit/test-dpp
...
sendmsg(4, {
    msg_name=NULL,
    msg_namelen=0,
    msg_iov=[
        {iov_base=&quot;&quot;, iov_len=0},
        {iov_base=&quot;\254d\221\364R\7&quot;, iov_len=6},
        {iov_base=&quot;n^\316n\363\335\0\0\0\0&quot;..., iov_len=281470681743366},
        {iov_base=&quot;\274\312\216#\345\300P2&quot;..., iov_len=32},
        {iov_base=&quot;\n\221\340r\210\t\273\2&quot;..., iov_len=32},
        {iov_base=&quot;thisisreallysecret&quot;, iov_len=18},
        {iov_base=&quot;\1&quot;, iov_len=1}],
    msg_iovlen=7, msg_controllen=0, msg_flags=0}, MSG_MORE) = 3136</code></pre>
<p>See anything suspicious?</p>
<p>Length of the third element of <code>msg_iov</code> array is <code>281470681743366</code> (or
<code>0xffff00000006</code> in hex). It should have been <code>6</code> if not for higher
<code>0xffff</code> garbage bits.</p>
<p>While we are at it: <code>sendmsg()</code> did not fail with an <code>-EINVAL</code> error and
consumed <code>3K</code> of data. At best it will fail at the key derivation. At
worst it might send your unrelated process memory over the network.</p>
<p>A nasty kind of bug.</p>
<h2 id="bonus-section">Bonus section</h2>
<p>If we go back to our original broken example are there any other 64-bit
architectures where <code>size_t</code> / <code>int</code> mismatch is as problematic as on
<code>aarch64</code>?</p>
<p>I’ll show the result for the following list of <code>8</code> <code>64</code>-bit
architectures I could remember:</p>
<ul>
<li><code>alpha</code></li>
<li><code>mips64 -mabi=64</code></li>
<li><code>loongarch64</code></li>
<li><code>s390x</code></li>
<li><code>powerpc64</code></li>
<li><code>sparc64</code></li>
<li><code>riscv64</code></li>
<li><code>ia64</code></li>
</ul>
<p>What is your guess? Is <code>aarch64</code> the unique one being broken here, or
maybe <code>x86_64</code> is unique in that it happens to work anyway? Will it be
endianness-specific? Or it’s closer to <code>50/50</code>?</p>
<p>Let’s see:</p>
<ul>
<li><p><code>alpha</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    lda t0,6
    stq t0,0(sp)</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ldq a3,0(t0)</code></pre>
<p>The target passes first <code>6</code> arguments in registers.</p></li>
<li><p><code>mips64 -mabi=64</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    li v0,8
    sd v0,0(sp)</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ld a3,-8(s1)</code></pre>
<p>The target passes first <code>8</code> arguments in registers.</p></li>
<li><p><code>loongarch64</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    addi.w $t0, $zero, 9(0x9)
    st.d $t0, $sp, 8(0x8)</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ld.d $a3, $s1, -8(0xff8)</code></pre>
<p>The target passes first <code>8</code> arguments in registers.</p></li>
<li><p><code>s390x</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    lghi %r1,5
    stg %r1,160(%r15)</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    lg %r5,0(%r1)</code></pre>
<p>The target passes first <code>5</code> arguments in registers.</p></li>
<li><p><code>powerpc64</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    li r7,8
    std r7,112(r1)</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ldu r6,8(r29)</code></pre>
<p>The target passes first <code>8</code> arguments in registers.</p></li>
<li><p><code>sparc64</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    mov  6, %g1
    stx  %g1, [ %sp + 0x8af ]</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ldx  [ %i5 ], %o3</code></pre>
<p>The target passes first <code>6</code> arguments in registers.</p></li>
<li><p><code>riscv64</code>: no corruption. Stores 64-bit values on stack:</p>
<pre class="asm"><code>main:
    ; ...
    li a5
    sd a5,0(sp)</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ld a3,-8(s1)</code></pre>
<p>The target passes first <code>8</code> arguments in registers.</p></li>
<li><p><code>ia64</code>: has corruption:</p>
<pre><code>$ ./a
[0]: 1
[1]: 2
[2]: 3
[3]: 4
[4]: 5
[5]: 6
[6]: 7
[7]: 8
[8]: 2305843009213693961
[9]: 2305843009213693962
[10]: 11
[11]: 12
[12]: 13
[13]: 14
[14]: 15
[15]: 16</code></pre>
<p><code>ia64</code> stores only 32-bit value on stack (just like <code>aarch64</code>):</p>
<pre class="asm"><code>main:
    ; ...
    mov r15=8
    ;;
    st4 [r14]=r15</code></pre>
<p>and loads it as 64-bit value:</p>
<pre class="asm"><code>foo:
    ; ...
    ld8 r47=[r14]</code></pre>
<p>The target passes first <code>8</code> arguments in registers.</p></li>
</ul>
<p>Final table:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">target</th>
<th style="text-align: center;">Is affected</th>
<th style="text-align: center;">In registers</th>
<th style="text-align: center;">First on stack</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>alpha</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>mips64</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>loongarch64</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>s390x</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>powerpc64</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>sparc64</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>riscv64</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong><code>ia64</code></strong></td>
<td style="text-align: center;"><strong>yes</strong></td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>x86_64</code></td>
<td style="text-align: center;">no</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong><code>aarch64</code></strong></td>
<td style="text-align: center;"><strong>yes</strong></td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">9</td>
</tr>
</tbody>
</table>
<p>Thus <code>aarch64</code> is not unique, but very close to it :)</p>
<h2 id="parting-words">Parting words</h2>
<p>One has to be careful at specifying exact types expected by variadic
functions. Integral type conversion rules do not apply the same way you
would expect for a non-variadic function call.</p>
<p>If you are writing your function with variadic parameters and it’s not
a <code>printf()</code>-style function then compiler will not be able to help you
with warnings. Make sure you have a way to validate passed types via
other means.</p>
<p>Sometimes breakages are very subtle: first <code>8</code> parameters would work
just fine and <code>9</code>-th one will eat all your data. And it will happen only
on small set of architectures: <code>aarch64</code> and <code>ia64</code> :)</p>
<p><code>iwd</code> fix went upstream as
<a href="https://git.kernel.org/pub/scm/network/wireless/iwd.git/commit/?id=688d27700833258a139a6fbd5661334bd2c9fa98">this patch</a>.</p>
<p>Have fun!</p>
<h2 id="is-amd64-actually-immune-to-this">Is AMD64 actually immune to this?</h2>
<p><a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines">No</a>.
GCC’s use of <code>push</code> instructions is controlled by two options,
<code>-mpush-args</code> and <code>-mno-accumulate-outgoing-args</code>:</p>
<pre class="c"><code>static bool
ix86_push_argument (unsigned int npush)
{
  /* If SSE2 is available, use vector move to put large argument onto
     stack.  NB:  In 32-bit mode, use 8-byte vector move.  */
  return ((!TARGET_SSE2 || npush &lt; (TARGET_64BIT ? 16 : 8))
          &amp;&amp; TARGET_PUSH_ARGS
          &amp;&amp; !ACCUMULATE_OUTGOING_ARGS);
}</code></pre>
<p>The latter option is automatically adjusted depending on which CPU
family GCC should tune for:</p>
<pre class="c"><code>/* X86_TUNE_ACCUMULATE_OUTGOING_ARGS: Allocate stack space for outgoing
   arguments in prologue/epilogue instead of separately for each call
   by push/pop instructions.
   This increase code size by about 5% in 32bit mode, less so in 64bit mode
   because parameters are passed in registers.  It is considerable
   win for targets without stack engine that prevents multple push operations
   to happen in parallel.  */

DEF_TUNE (X86_TUNE_ACCUMULATE_OUTGOING_ARGS, &quot;accumulate_outgoing_args&quot;,
          m_PPRO | m_P4_NOCONA | m_BONNELL | m_SILVERMONT | m_KNL | m_KNM | m_INTEL
          | m_GOLDMONT | m_GOLDMONT_PLUS | m_ATHLON_K8 | m_LUJIAZUI)</code></pre>
<p>So the use of <code>push</code> vs. <code>mov</code> is a tuning choice, which makes this bug
even more subtle: it can surface depending on which CPU is specified via
the <code>-march=</code> or <code>-mtune</code> option.</p>]]></description>
    <pubDate>Wed, 20 Dec 2023 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/308-a-breakage-example-in-c-variadic-function.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>upgrading an ssd</title>
    <link>http://trofi.github.io/posts/307-upgrading-an-ssd.html</link>
    <description><![CDATA[<p>In search of bugs I build a lot of software locally. About ~20000
packages per day. I usually keep all builds around to speed up
regression debugging.</p>
<p>That way (and with help of filesystem compression, <code>duperemove</code> and
identical file hardlinking) I manage to fill up my <code>512G</code> SSD with build
results within 2-3 weeks.</p>
<p>Once the disk is full I have to trigger garbage collection that frees
all that space and start over.</p>
<p>I decided to switch to a larger <code>2T</code> SSD to expand the time budget to
1-2 months.</p>
<p>This is my boot disk on <code>btrfs</code> and I would like to preserve most of
it’s properties without too much of mountpoint juggling or machine
downtime. AFAIU <code>rsync</code> does not handle advanced filesystem features
like subvolume layouts and already deduplicated data.</p>
<p>I ended up plugging in a new device and did two commands to transfer all
the data live from one device to another:</p>
<pre><code>$ btrfs device add    /dev/nvme1n1p2 /
$ btrfs device remove /dev/nvme0n1p3 /</code></pre>
<p>15 minutes later all the data was on the new <code>SSD</code>! Magic!</p>
<h2 id="the-actual-procedure">The actual procedure</h2>
<p>It required a tiny bit of extra work to handle partitioning on a new
device and <code>EFI</code> <code>vfat</code> partition move.</p>
<p>Here is the sequence I used:</p>
<ol type="1">
<li><p>Plug a new device in, it detected as <code>/dev/nvme1n1</code>.</p></li>
<li><p>Partition new device:</p>
<pre><code># fdisk /dev/nvme1n1
g; n; 1; 2048 (default); +4G; t; 1 (EFI); n; 2; w</code></pre>
<p>Here we create 2 partitions: 4G <code>EFI</code> and the rest on Linux.</p></li>
<li><p>Format <code>EFI</code> partition:</p>
<pre><code># mkfs.fat -F 32 /dev/nvme1n1p1</code></pre></li>
<li><p>Sync <code>EFI</code> data to the new partition:</p>
<pre><code># mkdir /new-boot
# mount /dev/nvme1n1p1 /new-boot
# rsync -av /boot/ /new-boot/
# umount /new-boot
# rmdir /new-boot</code></pre></li>
<li><p>Update <code>/etc/nixos/hardware-configuration.nix</code> to point <code>EFI</code>
partition to the new <code>device = "/dev/disk/by-uuid/ABCD-1234";</code></p></li>
<li><p><strong>Migrate the root filesystem</strong>:</p>
<pre><code># btrfs device add    /dev/nvme1n1p2 /
# btrfs device remove /dev/nvme0n1p3 /</code></pre></li>
<li><p>Rebuild boot loader configuration and reinstall it:</p>
<pre><code># nixops-rebuild switch --install-bootloader</code></pre></li>
<li><p>Reboot the machine.</p></li>
</ol>
<p>Done!</p>
<p>It took 15 minutes to remove the device and evacuate all the data out.</p>
<p>A snapshot of migration state somewhere in the middle of the process:</p>
<pre><code># btrfs fi show /
Label: none  uuid: abcdef12-...
        Total devices 2 FS bytes used 201.63GiB
        devid    1 size 0.00B used 64.03GiB path /dev/nvme0n1p3
        devid    2 size 1.86TiB used 141.00GiB path /dev/nvme1n1p2</code></pre>
<p>Note how to-be-removed device had <code>size 0.00B</code> while it still had to
drain <code>64G</code> of data.</p>
<h2 id="parting-words">Parting words</h2>
<p><code>btrfs</code> device handling is magic! It does not matter if the new device
is smaller or larger than existing one: you add bytes to the pool and
new block groups get allocated there. Deleting old devices is also
straightforward: evacuated device stops being used for new object
allocation and existing block groups are evacuated to other devices.</p>
<p><code>btrfs device remove</code> wipes filesystem superblock and removes the device
from device tree of filesystem once data is fully drained. There is no
easy way to access data on the old device after the move. It is slightly
scary but has it’s charm as well: there is no chance to accidentally
mount old device and use it as new for a while.</p>
<p>By default <code>NixOS</code> uses <code>/dv/disk/by-uuid/...</code> device paths:</p>
<pre><code>$ cat /etc/fstab
/dev/disk/by-uuid/abcdef12-1dbb-... / btrfs x-initrd.mount,subvol=nixos,noatime,compress=zstd 0 0
/dev/disk/by-uuid/ABCD-1234 /boot vfat umask=1022,quiet,codepage=866,iocharset=utf8,dmask=1022,fmask=1133 0 2</code></pre>
<p>That means device rename and move on <code>btrfs</code> is transparent to the
configuration as <code>UUID</code> gets preserved on new device addition.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Fri, 15 Dec 2023 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/307-upgrading-an-ssd.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>gcc-14 bugs, pile 3</title>
    <link>http://trofi.github.io/posts/306-gcc-14-bug-pile-3.html</link>
    <description><![CDATA[<p>This week <a href="https://gcc.gnu.org/pipermail/gcc/2023-November/242898.html">GCC 14 entered stage 3</a>.
Most major features are already pushed to <code>master</code> branch and the main
focus now is to stabilize the result.</p>
<p>It’s a good time to look at bugs I noticed over past two months. This
time I saw <code>19</code> of those. That almost twice as much than over
<a href="https://trofi.github.io/posts/296-gcc-14-bugs-pile-2.html">previous 2 months</a>.</p>
<h2 id="summary">summary</h2>
<p>Bugs (or patches) in the order I observed them:</p>
<ul>
<li><a href="https://gcc.gnu.org/PR111435">tree-optimization/111435</a>: <code>ICE</code> on
<code>gcc</code> code (<code>-m32</code>) due to infinite recursion in type conversion
rule</li>
<li><a href="https://gcc.gnu.org/PR111527">driver/111527</a>: <code>gcc</code> hits environment
size limit early due to an internal <code>COLLECT_GCC_OPTIONS</code> variable</li>
<li><a href="https://gcc.gnu.org/PR111619">rtl-optimization/111619</a>:
<code>make profiledbootstrap</code> is very slow to build in unoptimized builds</li>
<li><a href="https://gcc.gnu.org/PR111629">other/111629</a>: <code>make profiledbootstrap</code>
<code>SIGSEGV</code>s <code>gcc</code> on shutdown due to a <code>ggc</code> bug</li>
<li><a href="https://gcc.gnu.org/PR111642">bootstrap/111642</a>:
<code>make profiledbootstrap</code> fails to type check <code>gcc</code>’s own <code>poly_int64</code> constructor</li>
<li><a href="https://gcc.gnu.org/PR111647">c++/111647</a>: <code>-fchecking=0/2</code> disagree
on validity of <code>IFNDR</code> <code>c++</code> handling</li>
<li><a href="https://gcc.gnu.org/PR111653">bootstrap/111653</a>: <code>-fchecking=0/2</code>
generate different code on the same input</li>
<li><a href="https://gcc.gnu.org/pipermail/gcc-patches/2023-October/633948.html"><code>libgcc</code> trampoline build fix</a>:
<code>libgcc</code> build failure in <code>libc</code>-less mode</li>
<li><a href="https://gcc.gnu.org/PR112107">rtl-optimization/112107</a>: bootstrap
failure on <code>i686-linux</code>: enabling debug changed register allocator output</li>
<li><a href="https://gcc.gnu.org/PR112321">middle-end/112321</a>: <code>gcc</code> <code>SIGSEGV</code> in
<code>debug</code> mode as it generated invalid objects</li>
<li><a href="https://gcc.gnu.org/PR112332">target/112332</a>: <code>ICE</code> in <code>gcc</code> when it
attempted to use <code>SIMD</code> instruction for stack access</li>
<li><a href="https://gcc.gnu.org/PR112347">c/112347</a>: <code>ICE</code> on <code>jemalloc</code> in newly
added <code>-Walloc-size</code> analysis</li>
<li><a href="https://gcc.gnu.org/PR112379">bootstrap/112379</a>: bootstrap builds
failure: unused function when asserts are disabled (code under <code>#ifdef</code>)</li>
<li><a href="https://gcc.gnu.org/PR112467">libstdc++/112467</a>: <code>__assume__</code> in
<code>libstdc++</code> broke <code>clang</code> usage of that library</li>
<li><a href="https://gcc.gnu.org/PR112523">target/112523</a>: <code>mpfr</code>, <code>libsodium</code> and
<code>unbound</code> tests were failing for an invalid <code>shrd</code> instruction use</li>
<li><a href="https://gcc.gnu.org/PR112540">target/112540</a>: <code>gstreamer</code> <code>ICE</code> in
<code>RTL</code> (invalid addressing mode for <code>SIMD</code>)</li>
<li><a href="https://gcc.gnu.org/PR112567">target/112567</a>: <code>linux</code> ICE on <code>RTL</code>
due to <code>gcc</code> generating invalid objects</li>
<li><a href="https://gcc.gnu.org/PR112601">ipa/112601</a>: <code>ICE</code> on <code>llvm-17.0.5</code>
code in <code>-fchecking=2</code> mode related to function attribute inference</li>
<li><a href="https://gcc.gnu.org/PR112613">target/112613</a>: bad code in comparison
code when <code>AVX2</code> registers are present in generated code</li>
</ul>
<h2 id="fun-discovery">fun discovery</h2>
<p>I found a few new things as part of poking at those bugs:</p>
<p><a href="https://en.cppreference.com/w/cpp/language/acronyms">IFNDR</a> “Ill-Formed,
No Diagnostic Required” is the known invalid code from type checking
standpoint that is allowed to be compiled. In this case the whole
program has an undefined behaviour.</p>
<p><code>-Walloc-size</code> added in <a href="https://gcc.gnu.org/PR71219">PR71219</a> detects
interesting cases of <code>T * p = malloc(sz)</code> calls when it’s clear that <code>sz</code>
is smaller than <code>sizeof(T)</code>. It also works on <code>calloc()</code> and already
found a few benign instances in
<a href="https://sourceware.org/git/?p=elfutils.git;a=commitdiff;h=fb232b56ca4dc37a70fd4e581a0fc2c56dda5e0a">elfutils</a>,
<a href="https://gitlab.freedesktop.org/mstoeckl/waypipe/-/merge_requests/19">waypipe</a>,
<a href="https://github.com/swaywm/sway/commit/020a572ed615b8fe272c7566a27ee0abe73a58d7">sway</a>
and
<a href="https://github.com/swaywm/swaybg/commit/435be14610a4b4538adc6a926160ed434ff630fa">swaybg</a>.</p>
<h1 id="histograms">histograms</h1>
<p>Looking at the bug categories:</p>
<ul>
<li><code>target</code>: 5</li>
<li><code>bootstrap</code>: 3</li>
<li><code>rtl-optimization</code>: 2</li>
<li><code>tree-optimization</code>: 1</li>
<li><code>driver</code>: 1</li>
<li><code>other</code>: 1</li>
<li><code>c++</code>: 1</li>
<li><code>middle-end</code>: 1</li>
<li><code>ipa</code>: 1</li>
<li><code>c</code>: 1</li>
<li><code>libstdc++</code>: 1</li>
<li><code>libgcc</code>: 1</li>
</ul>
<p>This cycle was very unusual: it has more bugs than I expected, it spans
over 12 categories of compiler components, most of bugs are in <code>i386</code>
target.</p>
<h1 id="parting-words">parting words</h1>
<p>This cycle felt very busy: about 2-3 bugs per week.</p>
<p>I had a lot of joy fixing <a href="https://trofi.github.io/posts/301-another-gcc-profiling-bug.html"><code>PGO</code> bootstrap</a>
and submitting a few trivial fixes upstream.</p>
<p>I encountered only two bugs related to wrong code generated by <code>gcc</code>.
Most of the bugs were compiler crashes which are a lot easier to detect,
report and fix. Chances are I did not get to running enough test suites
as there were so many obvious bugs that required some attention.</p>
<p>Let’s see what stage 3 will bring us.</p>
<p>Have fun!</p>]]></description>
    <pubDate>Wed, 22 Nov 2023 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/306-gcc-14-bug-pile-3.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>
<item>
    <title>fuzzing duperemove</title>
    <link>http://trofi.github.io/posts/305-fuzzing-duperemove.html</link>
    <description><![CDATA[<p><a href="https://github.com/markfasheh/duperemove/releases/tag/v0.14"><code>duperemove-0.14</code></a>
was released yesterday and included a few small fixes I wrote about
<a href="https://trofi.github.io/posts/304-duperemove-speedups.html">before</a>.</p>
<p>On top of that the new release contains an overhauled parallel file
scanner and database handler that scale a lot better on large files.</p>
<h2 id="new-crashes">new crashes</h2>
<p>Unfortunately recent changes also increased complexity of handling
deduplication queue in a way that caused occasional crashes like
asserts in <code>dedupe_extent_list()</code> at
<a href="https://github.com/markfasheh/duperemove/issues/329"><code>run_dedupe.c:448</code></a>.</p>
<p>In that case my typical dedupe run started crashing as:</p>
<pre><code># duperemove -q --batchsize=0 --dedupe-options=partial,same -rd --hashfile=/run/duperemove/root-dupes.db /
...
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
ERROR: run_dedupe.c:287
[stack trace follows]
/nix/store/528cmbj5wnz37llwkfwxjxj3j41ng0gi-duperemove-0.14/bin/duperemove(print_stack_trace+0x2e) [0x409aee]
/nix/store/528cmbj5wnz37llwkfwxjxj3j41ng0gi-duperemove-0.14/bin/duperemove() [0x40d2dc]
/nix/store/7wkspba8d5i28bw0jfxyi3c70wrw2512-glib-2.76.4/lib/libglib-2.0.so.0(+0x8b06a) [0x7f906e45006a]
/nix/store/7wkspba8d5i28bw0jfxyi3c70wrw2512-glib-2.76.4/lib/libglib-2.0.so.0(+0x8a71d) [0x7f906e44f71d]
/nix/store/qn3ggz5sf3hkjs2c797xf7nan3amdxmp-glibc-2.38-27/lib/libc.so.6(+0x8b084) [0x7f906e038084]
/nix/store/qn3ggz5sf3hkjs2c797xf7nan3amdxmp-glibc-2.38-27/lib/libc.so.6(+0x10d60c) [0x7f906e0ba60c]

/nix/store/b86jv7hh4656xf60mby91w7a93wi4h03-remove-dupes.bash: line 12: 405268 Aborted                 (core dumped) SQLITE_TMPDIR=/run/duperemove /nix/store/528cmbj5wnz37llwkfwxjxj3j41ng0gi-duperemove-0.14/bin/duperemove -q --batchsize=0 --dedupe-options=partial,same -rd --hashfile=/run/duperemove/root-dupes.db /

duperemove-root.service: Main process exited, code=exited, status=134/n/a
duperemove-root.service: Failed with result 'exit-code'.
Failed to start duperemove-root.service.
duperemove-root.service: Consumed 34min 12.755s CPU time, no IP traffic.</code></pre>
<p>It took 30 minutes of CPU time (and about 10 minutes of real time) to
only crash later.</p>
<h2 id="crash-location">crash location</h2>
<p>I poked a bit around the crash in <code>gdb</code> to find that failure happens
somewhere in the middle of <a href="https://github.com/markfasheh/duperemove/blob/v0.14/run_dedupe.c#L274"><code>dedupe_extent_list()</code></a>.
It’s a seemingly simple but big function:</p>
<pre class="c"><code>static int dedupe_extent_list(struct dupe_extents *dext, uint64_t *fiemap_bytes,
                              uint64_t *kern_bytes, unsigned long long passno)
{
    int last = 0;
    struct dedupe_ctxt *ctxt = NULL;
    // ...
    list_for_each_entry(extent, &amp;dext-&gt;de_extents, e_list) {
        if (list_is_last(&amp;extent-&gt;e_list, &amp;dext-&gt;de_extents))
            last = 1;
        // ...
        if (...) {
            // ...
            if (ctxt &amp;&amp; last)
                goto run_dedupe;
            continue;
        }
        if (ctxt == NULL) {
            ctxt = new_dedupe_ctxt(dext-&gt;de_num_dupes,
                                   tgt_extent-&gt;e_loff, len,
                                   tgt_extent-&gt;e_file);
            // ...
            if (tgt_extent == extent)
                continue;
            // ...
        }
        // ...
        if (...) {
            // ...
            if (!last)
                continue;
        // ...
run_dedupe:
        // ...
close_files:
        filerec_close_open_list(&amp;open_files);
        free_dedupe_ctxt(ctxt);
        ctxt = NULL;
        // ...
    }
    // ...
    abort_on(ctxt != NULL); // we fail here
    // ...
}</code></pre>
<p><code>duperemove</code> fails at <code>abort_on(ctxt != NULL);</code> assertion. The intent
of the assert seems straightforward: <code>ctxt</code> is expected to be created
within <code>list_for_each_entry()</code> loop and is destroyed before we exit the
loop.</p>
<p>There is a bit of logic that tries to track if we are in the last
element of the loop to make sure we clean up properly.</p>
<p>From a quick glance I was not able to figure out why <code>duperemove</code> crashes
on my input. What is worse: running <code>duperemove</code> with
<code>--io-threads=1 --cpu-threads=1</code> options to decrease parallelism and to
simplify deduplication sequence started triggering an unrelated
<code>abort_on()</code> in the same function.</p>
<p>That means there not just one but a few different cases that manage to
break <code>duperemove</code>.</p>
<h2 id="building-a-reproducer">building a reproducer</h2>
<p>As the scan takes at least 10 minutes on my input data I wondered if I
could extract a smaller example to present for upstream.</p>
<p>At first I though of crafting the files on the file system in a
particular way to match the way <code>duperemove</code> breaks for me. But I also
felt it would be a tedious task.</p>
<p>Before actually trying to extract the first crash example I got an idea
of fuzzing <code>duperemove</code>. In theory a simple sequence of random
actions against a file system to create interesting enough file state
would be able to create a lot more interesting scenarios than I have.
Maybe I’ll get something that crashes <code>duperemove</code> faster?</p>
<p>I though if the following operations for the fuzzer:</p>
<ol type="1">
<li>create a brand new file with a few (<code>4</code>) unique non-dedupable blocks</li>
<li>copy full existing file contents with or without reflinking into a new file</li>
<li>copy one random block from one random file to another random file</li>
<li>run <code>duperemove</code> on the current state</li>
</ol>
<p><strong>Quick quiz</strong>: If we execute these actions at random, how long would it
take to crash <code>duperemove</code>? A second, a minute, a day or never?</p>
<p>Here is the direct <code>bash</code> implementation of the fuzzer described above:</p>
<pre class="bash"><code>#!/usr/bin/env bash

duperemove_binary=$1
target_dir=$2

shift; shift

if [[ -z $duperemove_binary ]] || [[ -z $target_dir ]]; then
    echo &quot;Usage: $0 &lt;/abs/path/to/duperemove&gt; &lt;directory&gt; [duperemove opts]&quot;
    exit 1
fi

# fail on any error
set -e

mkdir &quot;$target_dir&quot;
cd &quot;$target_dir&quot;

shopt -s nullglob

while :; do
    sync
    files=(*)
    f_count=${#files[@]}
    dst=$f_count

    case $((RANDOM % 4)) in
        0)  # copy existing file
            [[ $f_count -eq 0 ]] &amp;&amp; continue

            cp_arg=&quot;&quot;
            case $((RANDOM % 2)) in
                0) cp_arg=--reflink=always;;
                1) cp_arg=--reflink=never;;
            esac
            src=$((RANDOM % f_count))
            cp -v &quot;$cp_arg&quot; &quot;$src&quot; &quot;$dst&quot;
            ;;
        1) # create new file of 4x4KB distinct blocks
            printf &quot;0%*d&quot; 4095 &quot;$dst&quot;  &gt; &quot;$dst&quot;
            printf &quot;1%*d&quot; 4095 &quot;$dst&quot; &gt;&gt; &quot;$dst&quot;
            printf &quot;2%*d&quot; 4095 &quot;$dst&quot; &gt;&gt; &quot;$dst&quot;
            printf &quot;3%*d&quot; 4095 &quot;$dst&quot; &gt;&gt; &quot;$dst&quot;
            ;;
        2) # run duperemove
            &quot;$duperemove_binary&quot; &quot;$@&quot; -rd -b 4096 &quot;$target_dir&quot;
            ;;
        3) # dd 4KB of one file into another
            [[ $f_count -eq 0 ]] &amp;&amp; continue

            src=$((RANDOM % f_count))
            dst=$((RANDOM % f_count))
            [[ $src = $dst ]] &amp;&amp; continue

            src_block=$((RANDOM % 3))
            dst_block=$((RANDOM % 3))
            dd &quot;if=$src&quot; &quot;iseek=$src_block&quot; &quot;of=$dst&quot; &quot;oseek=$dst_block&quot; bs=4096 count=1
            ;;
    esac
done</code></pre>
<p>Specifically we always create <code>16KB</code> files and move <code>4KB</code> blocks around
to make sure <code>duperemove</code> considers them as a whole. We also pass
<code>-b 4096</code> block size as default block size is <code>128KB</code>.</p>
<p>And now goes the quiz answer:</p>
<pre><code>$ time { rm -rfv ~/tmp/dr/ &amp;&amp; bash ./duperemove-fuzz.bash $PWD/duperemove/duperemove ~/tmp/dr -q; }
...
Simple read and compare of file data found 12 instances of files that might benefit from deduplication.
ERROR: run_dedupe.c:287
[stack trace follows]
/home/slyfox/dev/git/duperemove/duperemove(print_stack_trace+0x29) [0x409b39]
/home/slyfox/dev/git/duperemove/duperemove() [0x40d844]
/nix/store/6bpc4sc5apc2ryxhjyij43n3wi169hfn-glib-2.76.4/lib/libglib-2.0.so.0(+0x8ad72) [0x7f8da7b47d72]
/nix/store/6bpc4sc5apc2ryxhjyij43n3wi169hfn-glib-2.76.4/lib/libglib-2.0.so.0(+0x8a41d) [0x7f8da7b4741d]
/nix/store/znf2bj54q3qj4pyk0xbp7pk12xbxq07b-glibc-2.38-27/lib/libc.so.6(+0x908b1) [0x7f8da77278b1]
/nix/store/znf2bj54q3qj4pyk0xbp7pk12xbxq07b-glibc-2.38-27/lib/libc.so.6(+0x114e6c) [0x7f8da77abe6c]
./duperemove-fuzz.bash: line 27: 264572 Aborted                 (core dumped) &quot;$duperemove_binary&quot; &quot;$@&quot; -rd -b 4096 &quot;$target_dir&quot;

real    0m3.354s
user    0m0.530s
sys     0m1.500s</code></pre>
<p>3 seconds!</p>
<p>I’m not always as lucky: sometimes it takes 2 seconds, sometimes as much
as 8 seconds. It feels like a very good result for such a dumb script.</p>
<h2 id="parting-words">parting words</h2>
<p><code>duperemove</code> has a non-trivial state machine to track extent state to
avoid multiple deduplication attempts. It clearly has a few bugs like
<a href="https://github.com/markfasheh/duperemove/issues/329">issue #329</a>.</p>
<p>Fuzzing works great for a small set of well defined operations. I picked
a minimal subset of operations to trigger the failures.</p>
<p>The fuzzer does not exercise other interesting operations like hardlinks
creation, file removal or larger files with more interesting extent
sharing structure. There is still more room for improvement to get into
darker corners of state tracking in <code>duperemove</code>.</p>
<p>I will not have much time debugging specifics of these <code>duperemove</code>
crashes in the following days. Try to fix these crashes yourself!</p>
<p>Have fun!</p>]]></description>
    <pubDate>Tue, 21 Nov 2023 00:00:00 UT</pubDate>
    <guid>http://trofi.github.io/posts/305-fuzzing-duperemove.html</guid>
    <dc:creator>Sergei Trofimovich</dc:creator>
</item>

    </channel>
</rss>
